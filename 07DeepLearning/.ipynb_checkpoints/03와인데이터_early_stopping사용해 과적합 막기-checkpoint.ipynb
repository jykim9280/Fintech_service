{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcc0e3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8b584d",
   "metadata": {},
   "source": [
    "1) Alcohol\n",
    "2) Malic acid\n",
    "3) Ash\n",
    "4) Alcalinity of ash  \n",
    "5) Magnesium\n",
    "6) Total phenols\n",
    "7) Flavanoids\n",
    "8) Nonflavanoid phenols\n",
    "9) Proanthocyanins\n",
    "10) Color intensity\n",
    "11) Hue\n",
    "12) OD280/OD315 of diluted wines\n",
    "13) Proline            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fffd01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"https://raw.githubusercontent.com/haram4th/ADsP/main/wine.csv\", header=None)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb8d625",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864d5747",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data.iloc[:,0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f29150f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[12].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1fe001",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(12, axis=1)\n",
    "y = data[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15029dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5996e7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = RobustScaler()\n",
    "X_scaled = rs.fit_transform(X)\n",
    "X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f688b5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bb04ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e693adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X_scaled, y, test_size=0.4, stratify=y, random_state=10)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_valid, y_valid, test_size=0.5, stratify=y_valid, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce0b51b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f026a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d715f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfeb8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=500, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab09803e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_test)\n",
    "pred = pd.DataFrame(pred)\n",
    "pred = pred[0].apply(lambda x: 1 if x > 0.5 else 0)\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ad6447",
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786dafa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend(['train', 'valid'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da023ad7",
   "metadata": {},
   "source": [
    "# EarlyStopping으로 학습 조기 중단 및 저장하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c95e43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b8d40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd4b0bf",
   "metadata": {},
   "source": [
    "# ModelCheckpoint\n",
    "* 모델을 중간에 저장하는 옵션"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc53574e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists(\"./model\"):\n",
    "    os.makedirs(\"./model\")\n",
    "    print(f\"Directory /model created.\")\n",
    "else:\n",
    "    print(f\"Directory /model already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a04dae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelpath = \"./model/{epoch:03d}--{val_loss:.4f}.keras\"\n",
    "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=0, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ab4eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, epochs=1000, batch_size=500, validation_data=(X_valid, y_valid), \n",
    "                   callbacks=[early_stopping_callback, checkpointer])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b7790f",
   "metadata": {},
   "source": [
    "# 저장된 베스트 모델을 불러와서 테스트 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33e4706",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3120afa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = load_model(\"./model/001--0.0356.keras\")  # .h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe24fdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_pred = best_model.predict(X_test)\n",
    "best_pred = pd.DataFrame(best_pred)\n",
    "best_pred = best_pred[0].apply(lambda x: 1 if x > 0.5 else 0)\n",
    "print(classification_report(y_test, best_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "0f09593e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.0010</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.0              0.27         0.36            20.7      0.045   \n",
       "1            6.3              0.30         0.34             1.6      0.049   \n",
       "2            8.1              0.28         0.40             6.9      0.050   \n",
       "3            7.2              0.23         0.32             8.5      0.058   \n",
       "4            7.2              0.23         0.32             8.5      0.058   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 45.0                 170.0   1.0010  3.00       0.45   \n",
       "1                 14.0                 132.0   0.9940  3.30       0.49   \n",
       "2                 30.0                  97.0   0.9951  3.26       0.44   \n",
       "3                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "4                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      8.8        6  \n",
       "1      9.5        6  \n",
       "2     10.1        6  \n",
       "3      9.9        6  \n",
       "4      9.9        6  "
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine = pd.read_csv(\"../06machine_learning/data/winequality-white.csv\", sep=\";\")\n",
    "wine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "b3361084",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "quality\n",
       "6    2198\n",
       "5    1457\n",
       "7     880\n",
       "8     175\n",
       "4     163\n",
       "3      20\n",
       "9       5\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine['quality'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "0e4c612e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine['quality'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "f316f41a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4898 entries, 0 to 4897\n",
      "Data columns (total 12 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   fixed acidity         4898 non-null   float64\n",
      " 1   volatile acidity      4898 non-null   float64\n",
      " 2   citric acid           4898 non-null   float64\n",
      " 3   residual sugar        4898 non-null   float64\n",
      " 4   chlorides             4898 non-null   float64\n",
      " 5   free sulfur dioxide   4898 non-null   float64\n",
      " 6   total sulfur dioxide  4898 non-null   float64\n",
      " 7   density               4898 non-null   float64\n",
      " 8   pH                    4898 non-null   float64\n",
      " 9   sulphates             4898 non-null   float64\n",
      " 10  alcohol               4898 non-null   float64\n",
      " 11  quality               4898 non-null   int64  \n",
      "dtypes: float64(11), int64(1)\n",
      "memory usage: 459.3 KB\n"
     ]
    }
   ],
   "source": [
    "wine.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "2110f494",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(wine.iloc[:,2:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "d7a1902f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "2dea8133",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = wine.drop('quality', axis=1).copy()\n",
    "y = wine['quality'].copy()\n",
    "y2 = wine['quality'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "42d0e8e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.0010</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.0              0.27         0.36            20.7      0.045   \n",
       "1            6.3              0.30         0.34             1.6      0.049   \n",
       "2            8.1              0.28         0.40             6.9      0.050   \n",
       "3            7.2              0.23         0.32             8.5      0.058   \n",
       "4            7.2              0.23         0.32             8.5      0.058   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 45.0                 170.0   1.0010  3.00       0.45   \n",
       "1                 14.0                 132.0   0.9940  3.30       0.49   \n",
       "2                 30.0                  97.0   0.9951  3.26       0.44   \n",
       "3                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "4                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "\n",
       "   alcohol  \n",
       "0      8.8  \n",
       "1      9.5  \n",
       "2     10.1  \n",
       "3      9.9  \n",
       "4      9.9  "
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "9d4bc6e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    6\n",
       "1    6\n",
       "2    6\n",
       "3    6\n",
       "4    6\n",
       "Name: quality, dtype: int64"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "441fdadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "rbs = RobustScaler()\n",
    "X_scaled = rbs.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "2fdee19c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4893</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4894</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4895</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4896</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4897</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4898 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          3      4      5      6      7      8      9\n",
       "0     False  False  False   True  False  False  False\n",
       "1     False  False  False   True  False  False  False\n",
       "2     False  False  False   True  False  False  False\n",
       "3     False  False  False   True  False  False  False\n",
       "4     False  False  False   True  False  False  False\n",
       "...     ...    ...    ...    ...    ...    ...    ...\n",
       "4893  False  False  False   True  False  False  False\n",
       "4894  False  False   True  False  False  False  False\n",
       "4895  False  False  False   True  False  False  False\n",
       "4896  False  False  False  False   True  False  False\n",
       "4897  False  False  False   True  False  False  False\n",
       "\n",
       "[4898 rows x 7 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y = pd.get_dummies(y)\n",
    "# y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "dac84769",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "dbdd39ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X_scaled, y, test_size=0.4, stratify=y, random_state=10)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_valid, y_valid, test_size=0.5, stratify=y_valid, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "2ece8259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2938, 11) (980, 11) (980, 11)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_valid.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "ebc4e59a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       6\n",
       "1       6\n",
       "2       6\n",
       "3       6\n",
       "4       6\n",
       "       ..\n",
       "4893    6\n",
       "4894    5\n",
       "4895    6\n",
       "4896    7\n",
       "4897    6\n",
       "Name: quality, Length: 4898, dtype: int64"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "730f0f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "f8d7fd91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "ca1c93eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniforge3/envs/dml/lib/python3.9/site-packages/imblearn/over_sampling/_adasyn.py:156: FutureWarning: The parameter `n_jobs` has been deprecated in 0.10 and will be removed in 0.12. You can pass an nearest neighbors estimator where `n_jobs` is already set instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "adasyn = ADASYN(random_state=10, n_neighbors=2, n_jobs=-1)\n",
    "X_train_adasyn, y_train_adasyn = adasyn.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "5704d53d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.400000</td>\n",
       "      <td>-0.181818</td>\n",
       "      <td>-1.166667</td>\n",
       "      <td>-0.353659</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.521739</td>\n",
       "      <td>0.186441</td>\n",
       "      <td>-0.381496</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>-0.071429</td>\n",
       "      <td>-0.052632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.300000</td>\n",
       "      <td>-0.727273</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>1.134146</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.372881</td>\n",
       "      <td>1.308966</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>2.214286</td>\n",
       "      <td>-0.684211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.727273</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.560976</td>\n",
       "      <td>-0.285714</td>\n",
       "      <td>-0.217391</td>\n",
       "      <td>-0.355932</td>\n",
       "      <td>0.073101</td>\n",
       "      <td>-0.368421</td>\n",
       "      <td>-0.142857</td>\n",
       "      <td>0.263158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.300000</td>\n",
       "      <td>-0.454545</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>-0.341463</td>\n",
       "      <td>-1.214286</td>\n",
       "      <td>-0.478261</td>\n",
       "      <td>-0.576271</td>\n",
       "      <td>-0.785837</td>\n",
       "      <td>-0.157895</td>\n",
       "      <td>-0.642857</td>\n",
       "      <td>0.526316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.916667</td>\n",
       "      <td>-0.280488</td>\n",
       "      <td>-1.214286</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>-0.135593</td>\n",
       "      <td>-0.651057</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>-0.642857</td>\n",
       "      <td>0.473684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9290</th>\n",
       "      <td>1.437013</td>\n",
       "      <td>-0.047538</td>\n",
       "      <td>0.702604</td>\n",
       "      <td>0.126134</td>\n",
       "      <td>-0.716468</td>\n",
       "      <td>-0.282941</td>\n",
       "      <td>-0.040431</td>\n",
       "      <td>-0.003261</td>\n",
       "      <td>0.319006</td>\n",
       "      <td>0.001091</td>\n",
       "      <td>0.561075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9291</th>\n",
       "      <td>1.727996</td>\n",
       "      <td>-0.000856</td>\n",
       "      <td>0.830979</td>\n",
       "      <td>0.305650</td>\n",
       "      <td>-0.667564</td>\n",
       "      <td>-0.275499</td>\n",
       "      <td>-0.083948</td>\n",
       "      <td>0.248944</td>\n",
       "      <td>0.246936</td>\n",
       "      <td>-0.023361</td>\n",
       "      <td>0.371891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9292</th>\n",
       "      <td>0.523141</td>\n",
       "      <td>-0.135237</td>\n",
       "      <td>0.610880</td>\n",
       "      <td>-0.383995</td>\n",
       "      <td>-0.838843</td>\n",
       "      <td>-0.259792</td>\n",
       "      <td>-0.028155</td>\n",
       "      <td>-0.743358</td>\n",
       "      <td>0.647672</td>\n",
       "      <td>-0.038370</td>\n",
       "      <td>1.159199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9293</th>\n",
       "      <td>0.487635</td>\n",
       "      <td>-0.113718</td>\n",
       "      <td>0.739095</td>\n",
       "      <td>-0.381109</td>\n",
       "      <td>-0.830389</td>\n",
       "      <td>-0.239209</td>\n",
       "      <td>-0.080310</td>\n",
       "      <td>-0.750117</td>\n",
       "      <td>0.703734</td>\n",
       "      <td>-0.089093</td>\n",
       "      <td>1.184116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9294</th>\n",
       "      <td>1.154337</td>\n",
       "      <td>-0.092887</td>\n",
       "      <td>0.577894</td>\n",
       "      <td>-0.048257</td>\n",
       "      <td>-0.763977</td>\n",
       "      <td>-0.290170</td>\n",
       "      <td>0.001844</td>\n",
       "      <td>-0.248265</td>\n",
       "      <td>0.389019</td>\n",
       "      <td>0.024846</td>\n",
       "      <td>0.744859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9295 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0         -1.400000         -0.181818    -1.166667       -0.353659   0.500000   \n",
       "1          0.300000         -0.727273     0.583333        1.134146   0.571429   \n",
       "2          0.000000         -0.727273    -0.333333        0.560976  -0.285714   \n",
       "3          0.300000         -0.454545     0.416667       -0.341463  -1.214286   \n",
       "4         -0.200000          0.000000    -0.916667       -0.280488  -1.214286   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "9290       1.437013         -0.047538     0.702604        0.126134  -0.716468   \n",
       "9291       1.727996         -0.000856     0.830979        0.305650  -0.667564   \n",
       "9292       0.523141         -0.135237     0.610880       -0.383995  -0.838843   \n",
       "9293       0.487635         -0.113718     0.739095       -0.381109  -0.830389   \n",
       "9294       1.154337         -0.092887     0.577894       -0.048257  -0.763977   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide   density        pH  \\\n",
       "0               -0.521739              0.186441 -0.381496  0.315789   \n",
       "1                0.608696              0.372881  1.308966  0.894737   \n",
       "2               -0.217391             -0.355932  0.073101 -0.368421   \n",
       "3               -0.478261             -0.576271 -0.785837 -0.157895   \n",
       "4                0.608696             -0.135593 -0.651057  0.210526   \n",
       "...                   ...                   ...       ...       ...   \n",
       "9290            -0.282941             -0.040431 -0.003261  0.319006   \n",
       "9291            -0.275499             -0.083948  0.248944  0.246936   \n",
       "9292            -0.259792             -0.028155 -0.743358  0.647672   \n",
       "9293            -0.239209             -0.080310 -0.750117  0.703734   \n",
       "9294            -0.290170              0.001844 -0.248265  0.389019   \n",
       "\n",
       "      sulphates   alcohol  \n",
       "0     -0.071429 -0.052632  \n",
       "1      2.214286 -0.684211  \n",
       "2     -0.142857  0.263158  \n",
       "3     -0.642857  0.526316  \n",
       "4     -0.642857  0.473684  \n",
       "...         ...       ...  \n",
       "9290   0.001091  0.561075  \n",
       "9291  -0.023361  0.371891  \n",
       "9292  -0.038370  1.159199  \n",
       "9293  -0.089093  1.184116  \n",
       "9294   0.024846  0.744859  \n",
       "\n",
       "[9295 rows x 11 columns]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_adasyn = pd.DataFrame(X_train_adasyn, columns=X.columns)\n",
    "X_train_adasyn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "52920ce2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "quality\n",
       "5    1410\n",
       "4    1346\n",
       "8    1345\n",
       "3    1320\n",
       "6    1318\n",
       "9    1317\n",
       "7    1239\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_adasyn.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "99d6327d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9290</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9291</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9292</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9293</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9294</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9295 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          3      4      5      6      7      8      9\n",
       "0     False  False   True  False  False  False  False\n",
       "1     False  False   True  False  False  False  False\n",
       "2     False  False  False  False   True  False  False\n",
       "3     False  False  False  False   True  False  False\n",
       "4     False  False  False  False   True  False  False\n",
       "...     ...    ...    ...    ...    ...    ...    ...\n",
       "9290  False  False  False  False  False  False   True\n",
       "9291  False  False  False  False  False  False   True\n",
       "9292  False  False  False  False  False  False   True\n",
       "9293  False  False  False  False  False  False   True\n",
       "9294  False  False  False  False  False  False   True\n",
       "\n",
       "[9295 rows x 7 columns]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_adasyn = pd.get_dummies(y_train_adasyn)\n",
    "y_train_adasyn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "4bb7a743",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4331</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2323</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1557</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2731</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3438</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>786</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>980 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          3      4      5      6      7      8      9\n",
       "4331  False  False   True  False  False  False  False\n",
       "438   False  False  False  False   True  False  False\n",
       "198   False  False   True  False  False  False  False\n",
       "2323  False  False  False   True  False  False  False\n",
       "1557  False  False  False   True  False  False  False\n",
       "...     ...    ...    ...    ...    ...    ...    ...\n",
       "456   False  False  False  False   True  False  False\n",
       "2731  False  False   True  False  False  False  False\n",
       "3438  False  False   True  False  False  False  False\n",
       "60    False  False  False   True  False  False  False\n",
       "786   False  False  False   True  False  False  False\n",
       "\n",
       "[980 rows x 7 columns]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid = pd.get_dummies(y_valid)\n",
    "y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "b4fb2518",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3107</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1049</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2806</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3650</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4362</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2129</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4804</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2380</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1052</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>980 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          3      4      5      6      7      8      9\n",
       "3107  False  False  False   True  False  False  False\n",
       "1049  False  False  False   True  False  False  False\n",
       "2806  False  False   True  False  False  False  False\n",
       "3650  False   True  False  False  False  False  False\n",
       "4362  False  False  False   True  False  False  False\n",
       "...     ...    ...    ...    ...    ...    ...    ...\n",
       "2129  False  False   True  False  False  False  False\n",
       "479   False  False  False   True  False  False  False\n",
       "4804  False   True  False  False  False  False  False\n",
       "2380  False   True  False  False  False  False  False\n",
       "1052  False  False   True  False  False  False  False\n",
       "\n",
       "[980 rows x 7 columns]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = pd.get_dummies(y_test)\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "2d30503e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "9e7b77fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_23 (Dense)            (None, 32)                384       \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 64)                2112      \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,223\n",
      "Trainable params: 5,223\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "f5033d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      " 9/19 [=============>................] - ETA: 0s - loss: 1.9396 - accuracy: 0.1647"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 15:25:03.517132: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-09-10 15:25:03.587031: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-09-10 15:25:03.587118: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15603 MB memory) -> physical PluggableDevice (device: 0, name: DML, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 1s 35ms/step - loss: 1.9120 - accuracy: 0.2122 - val_loss: 1.8553 - val_accuracy: 0.3112\n",
      "Epoch 2/10000\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 1.8578 - accuracy: 0.3200"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 15:25:04.104426: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-09-10 15:25:04.137226: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-09-10 15:25:04.137293: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15603 MB memory) -> physical PluggableDevice (device: 0, name: DML, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 25ms/step - loss: 1.7984 - accuracy: 0.3144 - val_loss: 1.8057 - val_accuracy: 0.2735\n",
      "Epoch 3/10000\n",
      "19/19 [==============================] - 0s 25ms/step - loss: 1.6225 - accuracy: 0.3803 - val_loss: 1.7947 - val_accuracy: 0.2367\n",
      "Epoch 4/10000\n",
      "19/19 [==============================] - 0s 25ms/step - loss: 1.4247 - accuracy: 0.4401 - val_loss: 1.7058 - val_accuracy: 0.2316\n",
      "Epoch 5/10000\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 1.2843 - accuracy: 0.4821 - val_loss: 1.5927 - val_accuracy: 0.2786\n",
      "Epoch 6/10000\n",
      "19/19 [==============================] - 0s 24ms/step - loss: 1.1787 - accuracy: 0.5275 - val_loss: 1.5327 - val_accuracy: 0.3133\n",
      "Epoch 7/10000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1.0899 - accuracy: 0.5686 - val_loss: 1.4532 - val_accuracy: 0.3408\n",
      "Epoch 8/10000\n",
      "19/19 [==============================] - 1s 27ms/step - loss: 1.0195 - accuracy: 0.5998 - val_loss: 1.4468 - val_accuracy: 0.3398\n",
      "Epoch 9/10000\n",
      "19/19 [==============================] - 0s 24ms/step - loss: 0.9616 - accuracy: 0.6283 - val_loss: 1.4259 - val_accuracy: 0.3531\n",
      "Epoch 10/10000\n",
      "19/19 [==============================] - 0s 23ms/step - loss: 0.9183 - accuracy: 0.6378 - val_loss: 1.3953 - val_accuracy: 0.3459\n",
      "Epoch 11/10000\n",
      "19/19 [==============================] - 0s 24ms/step - loss: 0.8796 - accuracy: 0.6460 - val_loss: 1.3704 - val_accuracy: 0.3571\n",
      "Epoch 12/10000\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.8499 - accuracy: 0.6591 - val_loss: 1.3813 - val_accuracy: 0.3612\n",
      "Epoch 13/10000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.8262 - accuracy: 0.6683 - val_loss: 1.3735 - val_accuracy: 0.3633\n",
      "Epoch 14/10000\n",
      "19/19 [==============================] - 0s 23ms/step - loss: 0.8016 - accuracy: 0.6746 - val_loss: 1.3509 - val_accuracy: 0.3643\n",
      "Epoch 15/10000\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.7827 - accuracy: 0.6790 - val_loss: 1.3576 - val_accuracy: 0.3663\n",
      "Epoch 16/10000\n",
      "19/19 [==============================] - 0s 23ms/step - loss: 0.7638 - accuracy: 0.6902 - val_loss: 1.2970 - val_accuracy: 0.4153\n",
      "Epoch 17/10000\n",
      "19/19 [==============================] - 0s 17ms/step - loss: 0.7482 - accuracy: 0.6998 - val_loss: 1.3019 - val_accuracy: 0.4000\n",
      "Epoch 18/10000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.7340 - accuracy: 0.7010 - val_loss: 1.3150 - val_accuracy: 0.3980\n",
      "Epoch 19/10000\n",
      "19/19 [==============================] - 1s 27ms/step - loss: 0.7156 - accuracy: 0.7148 - val_loss: 1.3114 - val_accuracy: 0.4000\n",
      "Epoch 20/10000\n",
      "19/19 [==============================] - 0s 17ms/step - loss: 0.7004 - accuracy: 0.7204 - val_loss: 1.3260 - val_accuracy: 0.4041\n",
      "Epoch 21/10000\n",
      "19/19 [==============================] - 0s 23ms/step - loss: 0.6909 - accuracy: 0.7257 - val_loss: 1.2764 - val_accuracy: 0.4214\n",
      "Epoch 22/10000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.6756 - accuracy: 0.7286 - val_loss: 1.2796 - val_accuracy: 0.4133\n",
      "Epoch 23/10000\n",
      "19/19 [==============================] - 0s 17ms/step - loss: 0.6647 - accuracy: 0.7315 - val_loss: 1.2908 - val_accuracy: 0.4082\n",
      "Epoch 24/10000\n",
      "19/19 [==============================] - 0s 23ms/step - loss: 0.6538 - accuracy: 0.7351 - val_loss: 1.2391 - val_accuracy: 0.4418\n",
      "Epoch 25/10000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.6418 - accuracy: 0.7422 - val_loss: 1.2493 - val_accuracy: 0.4347\n",
      "Epoch 26/10000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.6346 - accuracy: 0.7443 - val_loss: 1.2987 - val_accuracy: 0.4051\n",
      "Epoch 27/10000\n",
      "19/19 [==============================] - 1s 27ms/step - loss: 0.6221 - accuracy: 0.7481 - val_loss: 1.2501 - val_accuracy: 0.4255\n",
      "Epoch 28/10000\n",
      "19/19 [==============================] - 0s 26ms/step - loss: 0.6107 - accuracy: 0.7504 - val_loss: 1.2675 - val_accuracy: 0.4276\n",
      "Epoch 29/10000\n",
      "19/19 [==============================] - 0s 26ms/step - loss: 0.6013 - accuracy: 0.7569 - val_loss: 1.2594 - val_accuracy: 0.4255\n",
      "Epoch 30/10000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.5922 - accuracy: 0.7575 - val_loss: 1.2507 - val_accuracy: 0.4316\n",
      "Epoch 31/10000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.5821 - accuracy: 0.7641 - val_loss: 1.2722 - val_accuracy: 0.4224\n",
      "Epoch 32/10000\n",
      "19/19 [==============================] - 0s 22ms/step - loss: 0.5751 - accuracy: 0.7675 - val_loss: 1.2257 - val_accuracy: 0.4459\n",
      "Epoch 33/10000\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.5661 - accuracy: 0.7703 - val_loss: 1.2592 - val_accuracy: 0.4367\n",
      "Epoch 34/10000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.5596 - accuracy: 0.7719 - val_loss: 1.2601 - val_accuracy: 0.4367\n",
      "Epoch 35/10000\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.5526 - accuracy: 0.7791 - val_loss: 1.2736 - val_accuracy: 0.4265\n",
      "Epoch 36/10000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 0.5437 - accuracy: 0.7802 - val_loss: 1.2779 - val_accuracy: 0.4286\n",
      "Epoch 37/10000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.5364 - accuracy: 0.7853 - val_loss: 1.2560 - val_accuracy: 0.4398\n",
      "Epoch 38/10000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.5297 - accuracy: 0.7871 - val_loss: 1.2853 - val_accuracy: 0.4327\n",
      "Epoch 39/10000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.5212 - accuracy: 0.7891 - val_loss: 1.2664 - val_accuracy: 0.4357\n",
      "Epoch 40/10000\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.5212 - accuracy: 0.7905 - val_loss: 1.3082 - val_accuracy: 0.4214\n",
      "Epoch 41/10000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.5077 - accuracy: 0.7987 - val_loss: 1.2609 - val_accuracy: 0.4469\n",
      "Epoch 42/10000\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.5032 - accuracy: 0.8003 - val_loss: 1.2356 - val_accuracy: 0.4765\n",
      "Epoch 43/10000\n",
      "19/19 [==============================] - 0s 17ms/step - loss: 0.4976 - accuracy: 0.8017 - val_loss: 1.2955 - val_accuracy: 0.4316\n",
      "Epoch 44/10000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.4924 - accuracy: 0.8054 - val_loss: 1.2929 - val_accuracy: 0.4439\n",
      "Epoch 45/10000\n",
      "19/19 [==============================] - 0s 17ms/step - loss: 0.4854 - accuracy: 0.8110 - val_loss: 1.2907 - val_accuracy: 0.4418\n",
      "Epoch 46/10000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.4802 - accuracy: 0.8081 - val_loss: 1.2458 - val_accuracy: 0.4714\n",
      "Epoch 47/10000\n",
      "19/19 [==============================] - 0s 23ms/step - loss: 0.4774 - accuracy: 0.8095 - val_loss: 1.3043 - val_accuracy: 0.4327\n",
      "Epoch 48/10000\n",
      "19/19 [==============================] - 1s 28ms/step - loss: 0.4722 - accuracy: 0.8098 - val_loss: 1.2760 - val_accuracy: 0.4500\n",
      "Epoch 49/10000\n",
      "19/19 [==============================] - 1s 28ms/step - loss: 0.4679 - accuracy: 0.8103 - val_loss: 1.3068 - val_accuracy: 0.4449\n",
      "Epoch 50/10000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 0.4646 - accuracy: 0.8129 - val_loss: 1.2525 - val_accuracy: 0.4755\n",
      "Epoch 51/10000\n",
      "19/19 [==============================] - 0s 23ms/step - loss: 0.4594 - accuracy: 0.8184 - val_loss: 1.2962 - val_accuracy: 0.4653\n",
      "Epoch 52/10000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 0.4534 - accuracy: 0.8166 - val_loss: 1.3039 - val_accuracy: 0.4612\n",
      "Epoch 53/10000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 0.4492 - accuracy: 0.8186 - val_loss: 1.2738 - val_accuracy: 0.4633\n",
      "Epoch 54/10000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 0.4455 - accuracy: 0.8207 - val_loss: 1.3063 - val_accuracy: 0.4531\n",
      "Epoch 55/10000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.4411 - accuracy: 0.8207 - val_loss: 1.2839 - val_accuracy: 0.4796\n",
      "Epoch 56/10000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.4376 - accuracy: 0.8255 - val_loss: 1.3277 - val_accuracy: 0.4602\n",
      "Epoch 57/10000\n",
      "19/19 [==============================] - 0s 22ms/step - loss: 0.4338 - accuracy: 0.8252 - val_loss: 1.3028 - val_accuracy: 0.4724\n",
      "Epoch 58/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 22ms/step - loss: 0.4283 - accuracy: 0.8256 - val_loss: 1.3108 - val_accuracy: 0.4765\n",
      "Epoch 59/10000\n",
      "19/19 [==============================] - 1s 27ms/step - loss: 0.4253 - accuracy: 0.8281 - val_loss: 1.3113 - val_accuracy: 0.4796\n",
      "Epoch 60/10000\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.4231 - accuracy: 0.8272 - val_loss: 1.3093 - val_accuracy: 0.4724\n",
      "Epoch 61/10000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 0.4197 - accuracy: 0.8322 - val_loss: 1.3251 - val_accuracy: 0.4714\n",
      "Epoch 62/10000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.4178 - accuracy: 0.8337 - val_loss: 1.3297 - val_accuracy: 0.4816\n",
      "Epoch 63/10000\n",
      "19/19 [==============================] - 0s 25ms/step - loss: 0.4145 - accuracy: 0.8326 - val_loss: 1.3103 - val_accuracy: 0.4867\n",
      "Epoch 64/10000\n",
      "19/19 [==============================] - 0s 17ms/step - loss: 0.4104 - accuracy: 0.8327 - val_loss: 1.2927 - val_accuracy: 0.4980\n",
      "Epoch 65/10000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 0.4056 - accuracy: 0.8361 - val_loss: 1.3466 - val_accuracy: 0.4796\n",
      "Epoch 66/10000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.4018 - accuracy: 0.8384 - val_loss: 1.3357 - val_accuracy: 0.4745\n",
      "Epoch 67/10000\n",
      "19/19 [==============================] - 0s 25ms/step - loss: 0.4005 - accuracy: 0.8405 - val_loss: 1.3569 - val_accuracy: 0.4735\n",
      "Epoch 68/10000\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.3982 - accuracy: 0.8392 - val_loss: 1.3255 - val_accuracy: 0.5051\n",
      "Epoch 69/10000\n",
      "19/19 [==============================] - 0s 17ms/step - loss: 0.3940 - accuracy: 0.8397 - val_loss: 1.3568 - val_accuracy: 0.4847\n",
      "Epoch 70/10000\n",
      "19/19 [==============================] - 0s 17ms/step - loss: 0.3917 - accuracy: 0.8408 - val_loss: 1.3592 - val_accuracy: 0.4918\n",
      "Epoch 71/10000\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.3890 - accuracy: 0.8417 - val_loss: 1.3343 - val_accuracy: 0.4929\n",
      "Epoch 72/10000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.3848 - accuracy: 0.8452 - val_loss: 1.3610 - val_accuracy: 0.4867\n",
      "Epoch 73/10000\n",
      "19/19 [==============================] - 0s 22ms/step - loss: 0.3841 - accuracy: 0.8440 - val_loss: 1.3328 - val_accuracy: 0.4969\n",
      "Epoch 74/10000\n",
      "19/19 [==============================] - 0s 24ms/step - loss: 0.3812 - accuracy: 0.8460 - val_loss: 1.3488 - val_accuracy: 0.5010\n",
      "Epoch 75/10000\n",
      "19/19 [==============================] - 1s 27ms/step - loss: 0.3793 - accuracy: 0.8465 - val_loss: 1.3809 - val_accuracy: 0.4949\n",
      "Epoch 76/10000\n",
      "19/19 [==============================] - 0s 22ms/step - loss: 0.3765 - accuracy: 0.8450 - val_loss: 1.4125 - val_accuracy: 0.4673\n",
      "Epoch 77/10000\n",
      "19/19 [==============================] - 0s 26ms/step - loss: 0.3744 - accuracy: 0.8440 - val_loss: 1.3436 - val_accuracy: 0.4980\n",
      "Epoch 78/10000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.3710 - accuracy: 0.8465 - val_loss: 1.3708 - val_accuracy: 0.5020\n",
      "Epoch 79/10000\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.3672 - accuracy: 0.8497 - val_loss: 1.3772 - val_accuracy: 0.5000\n",
      "Epoch 80/10000\n",
      "19/19 [==============================] - 0s 24ms/step - loss: 0.3664 - accuracy: 0.8506 - val_loss: 1.4105 - val_accuracy: 0.4837\n",
      "Epoch 81/10000\n",
      "19/19 [==============================] - 0s 26ms/step - loss: 0.3633 - accuracy: 0.8515 - val_loss: 1.3784 - val_accuracy: 0.5061\n",
      "Epoch 82/10000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 0.3616 - accuracy: 0.8506 - val_loss: 1.3691 - val_accuracy: 0.5031\n",
      "Epoch 83/10000\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.3613 - accuracy: 0.8524 - val_loss: 1.3993 - val_accuracy: 0.5041\n",
      "Epoch 84/10000\n",
      "19/19 [==============================] - 0s 17ms/step - loss: 0.3606 - accuracy: 0.8517 - val_loss: 1.4206 - val_accuracy: 0.4939\n",
      "Epoch 85/10000\n",
      "19/19 [==============================] - 0s 25ms/step - loss: 0.3576 - accuracy: 0.8502 - val_loss: 1.3988 - val_accuracy: 0.5031\n",
      "Epoch 86/10000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.3541 - accuracy: 0.8545 - val_loss: 1.4222 - val_accuracy: 0.4980\n",
      "Epoch 87/10000\n",
      "19/19 [==============================] - 0s 25ms/step - loss: 0.3541 - accuracy: 0.8513 - val_loss: 1.4674 - val_accuracy: 0.4765\n",
      "Epoch 88/10000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.3523 - accuracy: 0.8535 - val_loss: 1.3728 - val_accuracy: 0.5184\n",
      "Epoch 89/10000\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.3524 - accuracy: 0.8497 - val_loss: 1.4212 - val_accuracy: 0.5010\n",
      "Epoch 90/10000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.3508 - accuracy: 0.8529 - val_loss: 1.4449 - val_accuracy: 0.4898\n",
      "Epoch 91/10000\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.3518 - accuracy: 0.8522 - val_loss: 1.4144 - val_accuracy: 0.5082\n",
      "Epoch 92/10000\n",
      "19/19 [==============================] - 0s 17ms/step - loss: 0.3490 - accuracy: 0.8534 - val_loss: 1.4244 - val_accuracy: 0.5061\n",
      "Epoch 93/10000\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.3433 - accuracy: 0.8577 - val_loss: 1.4436 - val_accuracy: 0.5031\n",
      "Epoch 94/10000\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.3398 - accuracy: 0.8592 - val_loss: 1.4582 - val_accuracy: 0.4990\n",
      "Epoch 95/10000\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.3375 - accuracy: 0.8606 - val_loss: 1.4307 - val_accuracy: 0.5122\n",
      "Epoch 96/10000\n",
      "19/19 [==============================] - 0s 17ms/step - loss: 0.3345 - accuracy: 0.8611 - val_loss: 1.4626 - val_accuracy: 0.5122\n",
      "Epoch 97/10000\n",
      "19/19 [==============================] - 0s 17ms/step - loss: 0.3359 - accuracy: 0.8595 - val_loss: 1.4494 - val_accuracy: 0.5184\n",
      "Epoch 98/10000\n",
      "19/19 [==============================] - 0s 27ms/step - loss: 0.3357 - accuracy: 0.8615 - val_loss: 1.4545 - val_accuracy: 0.5092\n",
      "Epoch 99/10000\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.3331 - accuracy: 0.8606 - val_loss: 1.4703 - val_accuracy: 0.5061\n",
      "Epoch 100/10000\n",
      "19/19 [==============================] - 0s 24ms/step - loss: 0.3323 - accuracy: 0.8608 - val_loss: 1.4696 - val_accuracy: 0.5133\n",
      "Epoch 101/10000\n",
      "19/19 [==============================] - 0s 22ms/step - loss: 0.3297 - accuracy: 0.8646 - val_loss: 1.4711 - val_accuracy: 0.5153\n",
      "Epoch 102/10000\n",
      "19/19 [==============================] - 0s 17ms/step - loss: 0.3282 - accuracy: 0.8642 - val_loss: 1.4905 - val_accuracy: 0.5163\n",
      "Epoch 103/10000\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.3266 - accuracy: 0.8636 - val_loss: 1.5110 - val_accuracy: 0.5112\n",
      "Epoch 104/10000\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.3238 - accuracy: 0.8648 - val_loss: 1.4992 - val_accuracy: 0.5082\n",
      "Epoch 105/10000\n",
      "19/19 [==============================] - 0s 17ms/step - loss: 0.3215 - accuracy: 0.8648 - val_loss: 1.4789 - val_accuracy: 0.5184\n",
      "Epoch 106/10000\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.3240 - accuracy: 0.8663 - val_loss: 1.4820 - val_accuracy: 0.5235\n",
      "Epoch 107/10000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 0.3234 - accuracy: 0.8651 - val_loss: 1.5222 - val_accuracy: 0.5051\n",
      "Epoch 108/10000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.3204 - accuracy: 0.8647 - val_loss: 1.5111 - val_accuracy: 0.5255\n",
      "Epoch 109/10000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.3186 - accuracy: 0.8666 - val_loss: 1.4971 - val_accuracy: 0.5306\n",
      "Epoch 110/10000\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.3163 - accuracy: 0.8681 - val_loss: 1.5172 - val_accuracy: 0.5224\n",
      "Epoch 111/10000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.3153 - accuracy: 0.8677 - val_loss: 1.5102 - val_accuracy: 0.5194\n",
      "Epoch 112/10000\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.3168 - accuracy: 0.8683 - val_loss: 1.5193 - val_accuracy: 0.5255\n",
      "Epoch 113/10000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 0.3128 - accuracy: 0.8696 - val_loss: 1.5167 - val_accuracy: 0.5214\n",
      "Epoch 114/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 18ms/step - loss: 0.3108 - accuracy: 0.8694 - val_loss: 1.5555 - val_accuracy: 0.5082\n",
      "Epoch 115/10000\n",
      "19/19 [==============================] - 0s 17ms/step - loss: 0.3094 - accuracy: 0.8689 - val_loss: 1.5295 - val_accuracy: 0.5153\n",
      "Epoch 116/10000\n",
      "19/19 [==============================] - 0s 17ms/step - loss: 0.3099 - accuracy: 0.8715 - val_loss: 1.5294 - val_accuracy: 0.5245\n",
      "Epoch 117/10000\n",
      "19/19 [==============================] - 0s 17ms/step - loss: 0.3071 - accuracy: 0.8707 - val_loss: 1.5968 - val_accuracy: 0.5051\n",
      "Epoch 118/10000\n",
      "19/19 [==============================] - 0s 17ms/step - loss: 0.3087 - accuracy: 0.8703 - val_loss: 1.5509 - val_accuracy: 0.5194\n",
      "Epoch 119/10000\n",
      "19/19 [==============================] - 0s 17ms/step - loss: 0.3045 - accuracy: 0.8719 - val_loss: 1.5665 - val_accuracy: 0.5255\n",
      "Epoch 120/10000\n",
      "19/19 [==============================] - 0s 17ms/step - loss: 0.3025 - accuracy: 0.8747 - val_loss: 1.5694 - val_accuracy: 0.5133\n",
      "Epoch 121/10000\n",
      "19/19 [==============================] - 0s 17ms/step - loss: 0.3016 - accuracy: 0.8736 - val_loss: 1.6196 - val_accuracy: 0.5133\n",
      "Epoch 122/10000\n",
      "19/19 [==============================] - 0s 17ms/step - loss: 0.3009 - accuracy: 0.8733 - val_loss: 1.5417 - val_accuracy: 0.5367\n",
      "Epoch 123/10000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.3014 - accuracy: 0.8729 - val_loss: 1.6272 - val_accuracy: 0.4959\n",
      "Epoch 124/10000\n",
      "19/19 [==============================] - 0s 27ms/step - loss: 0.3003 - accuracy: 0.8727 - val_loss: 1.6071 - val_accuracy: 0.5204\n",
      "Epoch 125/10000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 0.2970 - accuracy: 0.8740 - val_loss: 1.5811 - val_accuracy: 0.5337\n",
      "Epoch 126/10000\n",
      "19/19 [==============================] - 0s 17ms/step - loss: 0.2958 - accuracy: 0.8768 - val_loss: 1.6068 - val_accuracy: 0.5214\n",
      "Epoch 127/10000\n",
      "19/19 [==============================] - 0s 17ms/step - loss: 0.2955 - accuracy: 0.8771 - val_loss: 1.5952 - val_accuracy: 0.5357\n",
      "Epoch 128/10000\n",
      "19/19 [==============================] - 0s 17ms/step - loss: 0.2936 - accuracy: 0.8769 - val_loss: 1.6209 - val_accuracy: 0.5286\n",
      "Epoch 129/10000\n",
      "19/19 [==============================] - 0s 22ms/step - loss: 0.2964 - accuracy: 0.8763 - val_loss: 1.6471 - val_accuracy: 0.5265\n",
      "Epoch 130/10000\n",
      "19/19 [==============================] - 0s 23ms/step - loss: 0.2942 - accuracy: 0.8766 - val_loss: 1.6416 - val_accuracy: 0.5082\n",
      "Epoch 131/10000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.2911 - accuracy: 0.8775 - val_loss: 1.6644 - val_accuracy: 0.5092\n",
      "Epoch 132/10000\n",
      "19/19 [==============================] - 0s 26ms/step - loss: 0.2931 - accuracy: 0.8766 - val_loss: 1.6314 - val_accuracy: 0.5347\n",
      "Epoch 133/10000\n",
      "19/19 [==============================] - 0s 24ms/step - loss: 0.2911 - accuracy: 0.8782 - val_loss: 1.6794 - val_accuracy: 0.5143\n",
      "Epoch 134/10000\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.2862 - accuracy: 0.8805 - val_loss: 1.6599 - val_accuracy: 0.5265\n",
      "Epoch 135/10000\n",
      "19/19 [==============================] - 1s 27ms/step - loss: 0.2894 - accuracy: 0.8778 - val_loss: 1.6335 - val_accuracy: 0.5429\n",
      "Epoch 136/10000\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.2859 - accuracy: 0.8807 - val_loss: 1.6765 - val_accuracy: 0.5173\n",
      "Epoch 137/10000\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.2836 - accuracy: 0.8827 - val_loss: 1.6844 - val_accuracy: 0.5276\n",
      "Epoch 138/10000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 0.2864 - accuracy: 0.8812 - val_loss: 1.6582 - val_accuracy: 0.5316\n",
      "Epoch 139/10000\n",
      "19/19 [==============================] - 0s 23ms/step - loss: 0.2837 - accuracy: 0.8797 - val_loss: 1.6841 - val_accuracy: 0.5296\n",
      "Epoch 140/10000\n",
      "19/19 [==============================] - 0s 17ms/step - loss: 0.2817 - accuracy: 0.8839 - val_loss: 1.6901 - val_accuracy: 0.5265\n",
      "Epoch 141/10000\n",
      "19/19 [==============================] - 0s 22ms/step - loss: 0.2801 - accuracy: 0.8818 - val_loss: 1.6779 - val_accuracy: 0.5235\n",
      "Epoch 142/10000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 0.2786 - accuracy: 0.8835 - val_loss: 1.6920 - val_accuracy: 0.5357\n",
      "Epoch 143/10000\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.2801 - accuracy: 0.8820 - val_loss: 1.7163 - val_accuracy: 0.5194\n",
      "Epoch 144/10000\n",
      "19/19 [==============================] - 0s 25ms/step - loss: 0.2744 - accuracy: 0.8866 - val_loss: 1.6999 - val_accuracy: 0.5429\n",
      "Epoch 145/10000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.2787 - accuracy: 0.8843 - val_loss: 1.6933 - val_accuracy: 0.5367\n",
      "Epoch 146/10000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.2762 - accuracy: 0.8852 - val_loss: 1.7006 - val_accuracy: 0.5469\n",
      "Epoch 147/10000\n",
      "19/19 [==============================] - 0s 26ms/step - loss: 0.2769 - accuracy: 0.8838 - val_loss: 1.7015 - val_accuracy: 0.5418\n",
      "Epoch 148/10000\n",
      "19/19 [==============================] - 0s 26ms/step - loss: 0.2737 - accuracy: 0.8894 - val_loss: 1.7283 - val_accuracy: 0.5398\n",
      "Epoch 149/10000\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.2714 - accuracy: 0.8893 - val_loss: 1.7052 - val_accuracy: 0.5449\n",
      "Epoch 150/10000\n",
      "19/19 [==============================] - 0s 17ms/step - loss: 0.2714 - accuracy: 0.8871 - val_loss: 1.7805 - val_accuracy: 0.5235\n",
      "Epoch 151/10000\n",
      "19/19 [==============================] - 0s 25ms/step - loss: 0.2700 - accuracy: 0.8873 - val_loss: 1.7574 - val_accuracy: 0.5418\n",
      "Epoch 152/10000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.2679 - accuracy: 0.8882 - val_loss: 1.7402 - val_accuracy: 0.5541\n",
      "Epoch 153/10000\n",
      "19/19 [==============================] - 0s 25ms/step - loss: 0.2682 - accuracy: 0.8892 - val_loss: 1.7717 - val_accuracy: 0.5378\n",
      "Epoch 154/10000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.2683 - accuracy: 0.8886 - val_loss: 1.7838 - val_accuracy: 0.5316\n",
      "Epoch 155/10000\n",
      "19/19 [==============================] - 0s 25ms/step - loss: 0.2675 - accuracy: 0.8911 - val_loss: 1.7847 - val_accuracy: 0.5265\n",
      "Epoch 156/10000\n",
      "19/19 [==============================] - 0s 22ms/step - loss: 0.2654 - accuracy: 0.8922 - val_loss: 1.7686 - val_accuracy: 0.5388\n",
      "Epoch 157/10000\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.2637 - accuracy: 0.8917 - val_loss: 1.8102 - val_accuracy: 0.5306\n",
      "Epoch 158/10000\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.2648 - accuracy: 0.8912 - val_loss: 1.7929 - val_accuracy: 0.5469\n",
      "Epoch 159/10000\n",
      "19/19 [==============================] - 1s 28ms/step - loss: 0.2624 - accuracy: 0.8925 - val_loss: 1.8002 - val_accuracy: 0.5327\n",
      "Epoch 160/10000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.2635 - accuracy: 0.8903 - val_loss: 1.7958 - val_accuracy: 0.5378\n",
      "Epoch 161/10000\n",
      "19/19 [==============================] - 0s 25ms/step - loss: 0.2608 - accuracy: 0.8939 - val_loss: 1.8189 - val_accuracy: 0.5337\n",
      "Epoch 162/10000\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.2596 - accuracy: 0.8969 - val_loss: 1.8025 - val_accuracy: 0.5469\n",
      "Epoch 163/10000\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.2564 - accuracy: 0.8966 - val_loss: 1.8130 - val_accuracy: 0.5378\n",
      "Epoch 164/10000\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.2544 - accuracy: 0.8983 - val_loss: 1.8583 - val_accuracy: 0.5367\n",
      "Epoch 165/10000\n",
      "19/19 [==============================] - 1s 27ms/step - loss: 0.2583 - accuracy: 0.8963 - val_loss: 1.8401 - val_accuracy: 0.5347\n",
      "Epoch 166/10000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.2566 - accuracy: 0.8959 - val_loss: 1.8646 - val_accuracy: 0.5214\n",
      "Epoch 167/10000\n",
      "19/19 [==============================] - 0s 24ms/step - loss: 0.2559 - accuracy: 0.8969 - val_loss: 1.8459 - val_accuracy: 0.5398\n",
      "Epoch 168/10000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.2516 - accuracy: 0.8973 - val_loss: 1.8366 - val_accuracy: 0.5439\n",
      "Epoch 169/10000\n",
      "19/19 [==============================] - 0s 26ms/step - loss: 0.2504 - accuracy: 0.8996 - val_loss: 1.8474 - val_accuracy: 0.5418\n",
      "Epoch 170/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 19ms/step - loss: 0.2519 - accuracy: 0.8980 - val_loss: 1.8567 - val_accuracy: 0.5347\n",
      "Epoch 171/10000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.2528 - accuracy: 0.8965 - val_loss: 1.8860 - val_accuracy: 0.5224\n",
      "Epoch 172/10000\n",
      "19/19 [==============================] - 0s 24ms/step - loss: 0.2491 - accuracy: 0.9005 - val_loss: 1.8445 - val_accuracy: 0.5418\n",
      "Epoch 173/10000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.2470 - accuracy: 0.9022 - val_loss: 1.8843 - val_accuracy: 0.5398\n",
      "Epoch 174/10000\n",
      "19/19 [==============================] - 0s 24ms/step - loss: 0.2450 - accuracy: 0.9031 - val_loss: 1.8896 - val_accuracy: 0.5429\n",
      "Epoch 175/10000\n",
      "19/19 [==============================] - 0s 17ms/step - loss: 0.2453 - accuracy: 0.9020 - val_loss: 1.8926 - val_accuracy: 0.5357\n",
      "Epoch 176/10000\n",
      "19/19 [==============================] - 0s 17ms/step - loss: 0.2467 - accuracy: 0.9013 - val_loss: 1.9069 - val_accuracy: 0.5398\n",
      "Epoch 177/10000\n",
      "19/19 [==============================] - 0s 26ms/step - loss: 0.2449 - accuracy: 0.9015 - val_loss: 1.8719 - val_accuracy: 0.5531\n",
      "Epoch 178/10000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.2430 - accuracy: 0.9053 - val_loss: 1.8891 - val_accuracy: 0.5531\n",
      "Epoch 179/10000\n",
      "19/19 [==============================] - 0s 17ms/step - loss: 0.2444 - accuracy: 0.9011 - val_loss: 1.9599 - val_accuracy: 0.5306\n",
      "Epoch 180/10000\n",
      "19/19 [==============================] - 0s 17ms/step - loss: 0.2510 - accuracy: 0.8963 - val_loss: 1.9279 - val_accuracy: 0.5439\n",
      "Epoch 181/10000\n",
      "19/19 [==============================] - 0s 22ms/step - loss: 0.2478 - accuracy: 0.9005 - val_loss: 1.9108 - val_accuracy: 0.5520\n",
      "Epoch 182/10000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.2442 - accuracy: 0.9021 - val_loss: 1.9663 - val_accuracy: 0.5398\n",
      "Epoch 183/10000\n",
      "19/19 [==============================] - 0s 26ms/step - loss: 0.2408 - accuracy: 0.9039 - val_loss: 1.9978 - val_accuracy: 0.5173\n",
      "Epoch 184/10000\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.2396 - accuracy: 0.9053 - val_loss: 1.9613 - val_accuracy: 0.5388\n",
      "Epoch 185/10000\n",
      "19/19 [==============================] - 0s 25ms/step - loss: 0.2374 - accuracy: 0.9066 - val_loss: 1.9402 - val_accuracy: 0.5500\n",
      "Epoch 186/10000\n",
      "19/19 [==============================] - 0s 17ms/step - loss: 0.2374 - accuracy: 0.9060 - val_loss: 1.9829 - val_accuracy: 0.5296\n",
      "Epoch 187/10000\n",
      "19/19 [==============================] - 0s 24ms/step - loss: 0.2376 - accuracy: 0.9054 - val_loss: 1.9511 - val_accuracy: 0.5439\n",
      "Epoch 188/10000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.2357 - accuracy: 0.9064 - val_loss: 1.9510 - val_accuracy: 0.5459\n",
      "Epoch 189/10000\n",
      "19/19 [==============================] - 0s 25ms/step - loss: 0.2322 - accuracy: 0.9077 - val_loss: 1.9864 - val_accuracy: 0.5418\n",
      "Epoch 190/10000\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.2331 - accuracy: 0.9088 - val_loss: 1.9857 - val_accuracy: 0.5520\n",
      "Epoch 191/10000\n",
      "19/19 [==============================] - 0s 25ms/step - loss: 0.2355 - accuracy: 0.9072 - val_loss: 2.0035 - val_accuracy: 0.5418\n",
      "Epoch 192/10000\n",
      "19/19 [==============================] - 0s 22ms/step - loss: 0.2363 - accuracy: 0.9047 - val_loss: 1.9536 - val_accuracy: 0.5592\n",
      "Epoch 193/10000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.2333 - accuracy: 0.9086 - val_loss: 2.0053 - val_accuracy: 0.5449\n",
      "Epoch 194/10000\n",
      "19/19 [==============================] - 0s 25ms/step - loss: 0.2310 - accuracy: 0.9082 - val_loss: 2.0406 - val_accuracy: 0.5327\n",
      "Epoch 195/10000\n",
      "19/19 [==============================] - 0s 24ms/step - loss: 0.2395 - accuracy: 0.9058 - val_loss: 1.9916 - val_accuracy: 0.5500\n",
      "Epoch 196/10000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.2330 - accuracy: 0.9087 - val_loss: 2.0894 - val_accuracy: 0.5296\n",
      "Epoch 197/10000\n",
      "19/19 [==============================] - 1s 27ms/step - loss: 0.2365 - accuracy: 0.9052 - val_loss: 2.0583 - val_accuracy: 0.5357\n",
      "Epoch 198/10000\n",
      "19/19 [==============================] - 0s 26ms/step - loss: 0.2381 - accuracy: 0.9050 - val_loss: 2.0709 - val_accuracy: 0.5469\n",
      "Epoch 199/10000\n",
      "19/19 [==============================] - 0s 17ms/step - loss: 0.2288 - accuracy: 0.9108 - val_loss: 2.0666 - val_accuracy: 0.5306\n",
      "Epoch 200/10000\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.2259 - accuracy: 0.9127 - val_loss: 2.0858 - val_accuracy: 0.5357\n",
      "Epoch 201/10000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.2274 - accuracy: 0.9094 - val_loss: 2.0493 - val_accuracy: 0.5429\n",
      "Epoch 202/10000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.2236 - accuracy: 0.9126 - val_loss: 2.0476 - val_accuracy: 0.5561\n",
      "Epoch 203/10000\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.2233 - accuracy: 0.9131 - val_loss: 2.0650 - val_accuracy: 0.5480\n",
      "Epoch 204/10000\n",
      "19/19 [==============================] - 0s 26ms/step - loss: 0.2219 - accuracy: 0.9136 - val_loss: 2.0579 - val_accuracy: 0.5500\n",
      "Epoch 205/10000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.2211 - accuracy: 0.9123 - val_loss: 2.0515 - val_accuracy: 0.5541\n",
      "Epoch 206/10000\n",
      "19/19 [==============================] - 0s 23ms/step - loss: 0.2233 - accuracy: 0.9125 - val_loss: 2.0554 - val_accuracy: 0.5592\n",
      "Epoch 207/10000\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.2207 - accuracy: 0.9129 - val_loss: 2.0685 - val_accuracy: 0.5531\n",
      "Epoch 208/10000\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.2228 - accuracy: 0.9130 - val_loss: 2.0930 - val_accuracy: 0.5286\n",
      "Epoch 209/10000\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.2185 - accuracy: 0.9119 - val_loss: 2.0968 - val_accuracy: 0.5500\n",
      "Epoch 210/10000\n",
      "19/19 [==============================] - 0s 27ms/step - loss: 0.2177 - accuracy: 0.9144 - val_loss: 2.0937 - val_accuracy: 0.5561\n",
      "Epoch 211/10000\n",
      "19/19 [==============================] - 0s 17ms/step - loss: 0.2211 - accuracy: 0.9130 - val_loss: 2.1130 - val_accuracy: 0.5469\n",
      "Epoch 212/10000\n",
      "19/19 [==============================] - 0s 24ms/step - loss: 0.2173 - accuracy: 0.9150 - val_loss: 2.1743 - val_accuracy: 0.5316\n",
      "Epoch 213/10000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.2212 - accuracy: 0.9137 - val_loss: 2.1391 - val_accuracy: 0.5490\n",
      "Epoch 214/10000\n",
      "19/19 [==============================] - 0s 17ms/step - loss: 0.2204 - accuracy: 0.9121 - val_loss: 2.1139 - val_accuracy: 0.5398\n",
      "Epoch 215/10000\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.2154 - accuracy: 0.9162 - val_loss: 2.1284 - val_accuracy: 0.5551\n",
      "Epoch 216/10000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.2128 - accuracy: 0.9157 - val_loss: 2.1140 - val_accuracy: 0.5551\n",
      "Epoch 217/10000\n",
      "19/19 [==============================] - 0s 25ms/step - loss: 0.2144 - accuracy: 0.9158 - val_loss: 2.1356 - val_accuracy: 0.5531\n",
      "Epoch 218/10000\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.2143 - accuracy: 0.9176 - val_loss: 2.1706 - val_accuracy: 0.5480\n",
      "Epoch 219/10000\n",
      "19/19 [==============================] - 0s 22ms/step - loss: 0.2161 - accuracy: 0.9144 - val_loss: 2.1175 - val_accuracy: 0.5480\n",
      "Epoch 220/10000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.2127 - accuracy: 0.9177 - val_loss: 2.1658 - val_accuracy: 0.5510\n",
      "Epoch 221/10000\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.2117 - accuracy: 0.9147 - val_loss: 2.1511 - val_accuracy: 0.5582\n",
      "Epoch 222/10000\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.2148 - accuracy: 0.9160 - val_loss: 2.1785 - val_accuracy: 0.5561\n",
      "Epoch 223/10000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.2153 - accuracy: 0.9140 - val_loss: 2.2055 - val_accuracy: 0.5408\n",
      "Epoch 224/10000\n",
      "19/19 [==============================] - 0s 17ms/step - loss: 0.2117 - accuracy: 0.9186 - val_loss: 2.1549 - val_accuracy: 0.5633\n",
      "Epoch 225/10000\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.2101 - accuracy: 0.9183 - val_loss: 2.1721 - val_accuracy: 0.5633\n",
      "Epoch 226/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 1s 29ms/step - loss: 0.2096 - accuracy: 0.9180 - val_loss: 2.2006 - val_accuracy: 0.5582\n",
      "Epoch 227/10000\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.2073 - accuracy: 0.9179 - val_loss: 2.2341 - val_accuracy: 0.5357\n",
      "Epoch 228/10000\n",
      "19/19 [==============================] - 0s 24ms/step - loss: 0.2066 - accuracy: 0.9209 - val_loss: 2.2090 - val_accuracy: 0.5571\n",
      "Epoch 229/10000\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.2062 - accuracy: 0.9200 - val_loss: 2.2056 - val_accuracy: 0.5643\n",
      "Epoch 230/10000\n",
      "19/19 [==============================] - 0s 17ms/step - loss: 0.2092 - accuracy: 0.9174 - val_loss: 2.2089 - val_accuracy: 0.5469\n",
      "Epoch 231/10000\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.2028 - accuracy: 0.9224 - val_loss: 2.2406 - val_accuracy: 0.5500\n",
      "Epoch 232/10000\n",
      "19/19 [==============================] - 0s 22ms/step - loss: 0.2028 - accuracy: 0.9215 - val_loss: 2.2365 - val_accuracy: 0.5510\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer='adam', metrics=['accuracy'])\n",
    "early_stop = EarlyStopping(patience=200) \n",
    "filepath = \"./model/white_wine{epoch:04d}__{val_loss:.4f}.keras\"\n",
    "model_save = ModelCheckpoint(filepath=filepath, save_best_only=True)\n",
    "history = model.fit(X_train_adasyn, y_train_adasyn, epochs=10000, batch_size=500, validation_data=(X_valid, y_valid),\n",
    "                   callbacks=[early_stop, model_save])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "467b2741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4331</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2323</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1557</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2731</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3438</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>786</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>980 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          3      4      5      6      7      8      9\n",
       "4331  False  False   True  False  False  False  False\n",
       "438   False  False  False  False   True  False  False\n",
       "198   False  False   True  False  False  False  False\n",
       "2323  False  False  False   True  False  False  False\n",
       "1557  False  False  False   True  False  False  False\n",
       "...     ...    ...    ...    ...    ...    ...    ...\n",
       "456   False  False  False  False   True  False  False\n",
       "2731  False  False   True  False  False  False  False\n",
       "3438  False  False   True  False  False  False  False\n",
       "60    False  False  False   True  False  False  False\n",
       "786   False  False  False   True  False  False  False\n",
       "\n",
       "[980 rows x 7 columns]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "c8985709",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 15:29:21.262548: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "wine_best_model = load_model(\"./model/white_wine0032__1.2257.keras\")\n",
    "wine_pred = wine_best_model.predict(X_test)\n",
    "wine_pred = pd.DataFrame(wine_pred, columns=y_valid.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "eedd45a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.787430e-06</td>\n",
       "      <td>0.323064</td>\n",
       "      <td>0.238568</td>\n",
       "      <td>0.299787</td>\n",
       "      <td>0.138471</td>\n",
       "      <td>1.057107e-04</td>\n",
       "      <td>7.054573e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.297148e-06</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.002891</td>\n",
       "      <td>0.081570</td>\n",
       "      <td>0.341317</td>\n",
       "      <td>5.741845e-01</td>\n",
       "      <td>1.723967e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.422047e-08</td>\n",
       "      <td>0.015389</td>\n",
       "      <td>0.540318</td>\n",
       "      <td>0.387200</td>\n",
       "      <td>0.057090</td>\n",
       "      <td>3.441946e-06</td>\n",
       "      <td>1.173062e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.363896e-07</td>\n",
       "      <td>0.042890</td>\n",
       "      <td>0.544707</td>\n",
       "      <td>0.275783</td>\n",
       "      <td>0.136594</td>\n",
       "      <td>2.560246e-05</td>\n",
       "      <td>1.144879e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.377284e-08</td>\n",
       "      <td>0.001069</td>\n",
       "      <td>0.010333</td>\n",
       "      <td>0.257113</td>\n",
       "      <td>0.587828</td>\n",
       "      <td>1.436569e-01</td>\n",
       "      <td>1.238069e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>8.633584e-08</td>\n",
       "      <td>0.388208</td>\n",
       "      <td>0.069424</td>\n",
       "      <td>0.135844</td>\n",
       "      <td>0.227480</td>\n",
       "      <td>1.790447e-01</td>\n",
       "      <td>2.416760e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>1.238788e-01</td>\n",
       "      <td>0.000373</td>\n",
       "      <td>0.201254</td>\n",
       "      <td>0.170278</td>\n",
       "      <td>0.357444</td>\n",
       "      <td>1.461935e-01</td>\n",
       "      <td>5.791647e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>7.931296e-04</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>0.150577</td>\n",
       "      <td>0.541969</td>\n",
       "      <td>0.277148</td>\n",
       "      <td>2.929746e-02</td>\n",
       "      <td>6.766827e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>6.334407e-14</td>\n",
       "      <td>0.631184</td>\n",
       "      <td>0.201823</td>\n",
       "      <td>0.163198</td>\n",
       "      <td>0.003795</td>\n",
       "      <td>2.136742e-08</td>\n",
       "      <td>8.654434e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>1.557601e-04</td>\n",
       "      <td>0.354448</td>\n",
       "      <td>0.260442</td>\n",
       "      <td>0.220301</td>\n",
       "      <td>0.127878</td>\n",
       "      <td>3.677411e-02</td>\n",
       "      <td>1.532565e-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>980 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                3         4         5         6         7             8  \\\n",
       "0    4.787430e-06  0.323064  0.238568  0.299787  0.138471  1.057107e-04   \n",
       "1    1.297148e-06  0.000035  0.002891  0.081570  0.341317  5.741845e-01   \n",
       "2    1.422047e-08  0.015389  0.540318  0.387200  0.057090  3.441946e-06   \n",
       "3    8.363896e-07  0.042890  0.544707  0.275783  0.136594  2.560246e-05   \n",
       "4    3.377284e-08  0.001069  0.010333  0.257113  0.587828  1.436569e-01   \n",
       "..            ...       ...       ...       ...       ...           ...   \n",
       "975  8.633584e-08  0.388208  0.069424  0.135844  0.227480  1.790447e-01   \n",
       "976  1.238788e-01  0.000373  0.201254  0.170278  0.357444  1.461935e-01   \n",
       "977  7.931296e-04  0.000209  0.150577  0.541969  0.277148  2.929746e-02   \n",
       "978  6.334407e-14  0.631184  0.201823  0.163198  0.003795  2.136742e-08   \n",
       "979  1.557601e-04  0.354448  0.260442  0.220301  0.127878  3.677411e-02   \n",
       "\n",
       "                9  \n",
       "0    7.054573e-07  \n",
       "1    1.723967e-06  \n",
       "2    1.173062e-10  \n",
       "3    1.144879e-08  \n",
       "4    1.238069e-07  \n",
       "..            ...  \n",
       "975  2.416760e-08  \n",
       "976  5.791647e-04  \n",
       "977  6.766827e-06  \n",
       "978  8.654434e-16  \n",
       "979  1.532565e-06  \n",
       "\n",
       "[980 rows x 7 columns]"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "5d94df4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      6\n",
       "1      6\n",
       "2      5\n",
       "3      4\n",
       "4      6\n",
       "      ..\n",
       "975    5\n",
       "976    6\n",
       "977    4\n",
       "978    4\n",
       "979    5\n",
       "Length: 980, dtype: int64"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_class = y_test.idxmax(axis=1)\n",
    "y_test_class = y_test_class.reset_index(drop=True)\n",
    "y_test_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "5a2c8723",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      4\n",
       "1      8\n",
       "2      5\n",
       "3      5\n",
       "4      7\n",
       "      ..\n",
       "975    4\n",
       "976    7\n",
       "977    6\n",
       "978    4\n",
       "979    4\n",
       "Length: 980, dtype: int64"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_pred_class = wine_pred.idxmax(axis=1)\n",
    "wine_pred_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "b9f7e3bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "quality\n",
       "6    2198\n",
       "5    1457\n",
       "7     880\n",
       "8     175\n",
       "4     163\n",
       "3      20\n",
       "9       5\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "6aa3cd66",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         4\n",
      "           4       0.10      0.28      0.15        32\n",
      "           5       0.55      0.58      0.56       292\n",
      "           6       0.58      0.35      0.43       440\n",
      "           7       0.35      0.39      0.37       176\n",
      "           8       0.17      0.54      0.26        35\n",
      "           9       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.43       980\n",
      "   macro avg       0.25      0.30      0.25       980\n",
      "weighted avg       0.50      0.43      0.44       980\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniforge3/envs/dml/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/user/miniforge3/envs/dml/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/user/miniforge3/envs/dml/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_class, wine_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "ae909a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "339801f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 3, ..., 3, 4, 3])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "y2_labeled = le.fit_transform(y2)\n",
    "y2_labeled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74aa7541",
   "metadata": {},
   "source": [
    "XGB로 비교분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "4599382c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2, X_valid2, y_train2, y_valid2 = train_test_split(X_scaled, y2_labeled, test_size=0.4, stratify=y2_labeled, random_state=10)\n",
    "X_valid2, X_test2, y_valid2, y_test2 = train_test_split(X_valid2, y_valid2, test_size=0.5, stratify=y_valid2, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "41ce8aea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniforge3/envs/dml/lib/python3.9/site-packages/imblearn/over_sampling/_adasyn.py:156: FutureWarning: The parameter `n_jobs` has been deprecated in 0.10 and will be removed in 0.12. You can pass an nearest neighbors estimator where `n_jobs` is already set instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "adasyn = ADASYN(random_state=10, n_neighbors=2, n_jobs=-1)\n",
    "X_train2_adasyn, y_train2_adasyn = adasyn.fit_resample(X_train2, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "cdad0bf4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.400000</td>\n",
       "      <td>-0.181818</td>\n",
       "      <td>-1.166667</td>\n",
       "      <td>-0.353659</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.521739</td>\n",
       "      <td>0.186441</td>\n",
       "      <td>-0.381496</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>-0.071429</td>\n",
       "      <td>-0.052632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.300000</td>\n",
       "      <td>-0.727273</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>1.134146</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.372881</td>\n",
       "      <td>1.308966</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>2.214286</td>\n",
       "      <td>-0.684211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.727273</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.560976</td>\n",
       "      <td>-0.285714</td>\n",
       "      <td>-0.217391</td>\n",
       "      <td>-0.355932</td>\n",
       "      <td>0.073101</td>\n",
       "      <td>-0.368421</td>\n",
       "      <td>-0.142857</td>\n",
       "      <td>0.263158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.300000</td>\n",
       "      <td>-0.454545</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>-0.341463</td>\n",
       "      <td>-1.214286</td>\n",
       "      <td>-0.478261</td>\n",
       "      <td>-0.576271</td>\n",
       "      <td>-0.785837</td>\n",
       "      <td>-0.157895</td>\n",
       "      <td>-0.642857</td>\n",
       "      <td>0.526316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.916667</td>\n",
       "      <td>-0.280488</td>\n",
       "      <td>-1.214286</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>-0.135593</td>\n",
       "      <td>-0.651057</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>-0.642857</td>\n",
       "      <td>0.473684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9290</th>\n",
       "      <td>1.437013</td>\n",
       "      <td>-0.047538</td>\n",
       "      <td>0.702604</td>\n",
       "      <td>0.126134</td>\n",
       "      <td>-0.716468</td>\n",
       "      <td>-0.282941</td>\n",
       "      <td>-0.040431</td>\n",
       "      <td>-0.003261</td>\n",
       "      <td>0.319006</td>\n",
       "      <td>0.001091</td>\n",
       "      <td>0.561075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9291</th>\n",
       "      <td>1.727996</td>\n",
       "      <td>-0.000856</td>\n",
       "      <td>0.830979</td>\n",
       "      <td>0.305650</td>\n",
       "      <td>-0.667564</td>\n",
       "      <td>-0.275499</td>\n",
       "      <td>-0.083948</td>\n",
       "      <td>0.248944</td>\n",
       "      <td>0.246936</td>\n",
       "      <td>-0.023361</td>\n",
       "      <td>0.371891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9292</th>\n",
       "      <td>0.523141</td>\n",
       "      <td>-0.135237</td>\n",
       "      <td>0.610880</td>\n",
       "      <td>-0.383995</td>\n",
       "      <td>-0.838843</td>\n",
       "      <td>-0.259792</td>\n",
       "      <td>-0.028155</td>\n",
       "      <td>-0.743358</td>\n",
       "      <td>0.647672</td>\n",
       "      <td>-0.038370</td>\n",
       "      <td>1.159199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9293</th>\n",
       "      <td>0.487635</td>\n",
       "      <td>-0.113718</td>\n",
       "      <td>0.739095</td>\n",
       "      <td>-0.381109</td>\n",
       "      <td>-0.830389</td>\n",
       "      <td>-0.239209</td>\n",
       "      <td>-0.080310</td>\n",
       "      <td>-0.750117</td>\n",
       "      <td>0.703734</td>\n",
       "      <td>-0.089093</td>\n",
       "      <td>1.184116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9294</th>\n",
       "      <td>1.154337</td>\n",
       "      <td>-0.092887</td>\n",
       "      <td>0.577894</td>\n",
       "      <td>-0.048257</td>\n",
       "      <td>-0.763977</td>\n",
       "      <td>-0.290170</td>\n",
       "      <td>0.001844</td>\n",
       "      <td>-0.248265</td>\n",
       "      <td>0.389019</td>\n",
       "      <td>0.024846</td>\n",
       "      <td>0.744859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9295 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0         -1.400000         -0.181818    -1.166667       -0.353659   0.500000   \n",
       "1          0.300000         -0.727273     0.583333        1.134146   0.571429   \n",
       "2          0.000000         -0.727273    -0.333333        0.560976  -0.285714   \n",
       "3          0.300000         -0.454545     0.416667       -0.341463  -1.214286   \n",
       "4         -0.200000          0.000000    -0.916667       -0.280488  -1.214286   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "9290       1.437013         -0.047538     0.702604        0.126134  -0.716468   \n",
       "9291       1.727996         -0.000856     0.830979        0.305650  -0.667564   \n",
       "9292       0.523141         -0.135237     0.610880       -0.383995  -0.838843   \n",
       "9293       0.487635         -0.113718     0.739095       -0.381109  -0.830389   \n",
       "9294       1.154337         -0.092887     0.577894       -0.048257  -0.763977   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide   density        pH  \\\n",
       "0               -0.521739              0.186441 -0.381496  0.315789   \n",
       "1                0.608696              0.372881  1.308966  0.894737   \n",
       "2               -0.217391             -0.355932  0.073101 -0.368421   \n",
       "3               -0.478261             -0.576271 -0.785837 -0.157895   \n",
       "4                0.608696             -0.135593 -0.651057  0.210526   \n",
       "...                   ...                   ...       ...       ...   \n",
       "9290            -0.282941             -0.040431 -0.003261  0.319006   \n",
       "9291            -0.275499             -0.083948  0.248944  0.246936   \n",
       "9292            -0.259792             -0.028155 -0.743358  0.647672   \n",
       "9293            -0.239209             -0.080310 -0.750117  0.703734   \n",
       "9294            -0.290170              0.001844 -0.248265  0.389019   \n",
       "\n",
       "      sulphates   alcohol  \n",
       "0     -0.071429 -0.052632  \n",
       "1      2.214286 -0.684211  \n",
       "2     -0.142857  0.263158  \n",
       "3     -0.642857  0.526316  \n",
       "4     -0.642857  0.473684  \n",
       "...         ...       ...  \n",
       "9290   0.001091  0.561075  \n",
       "9291  -0.023361  0.371891  \n",
       "9292  -0.038370  1.159199  \n",
       "9293  -0.089093  1.184116  \n",
       "9294   0.024846  0.744859  \n",
       "\n",
       "[9295 rows x 11 columns]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train2_adasyn = pd.DataFrame(X_train2_adasyn, columns=X.columns)\n",
    "X_train2_adasyn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "a072eb5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    1410\n",
       "1    1346\n",
       "5    1345\n",
       "0    1320\n",
       "3    1318\n",
       "6    1317\n",
       "4    1239\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train2_adasyn = pd.Series(y_train2_adasyn)\n",
    "y_train2_adasyn.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506df56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "58ab6927",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cd0297",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "26cd5b67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.14      0.25      0.18         4\n",
      "           4       0.46      0.39      0.43        33\n",
      "           5       0.66      0.62      0.64       291\n",
      "           6       0.64      0.64      0.64       440\n",
      "           7       0.55      0.61      0.58       176\n",
      "           8       0.43      0.46      0.44        35\n",
      "           9       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.61       980\n",
      "   macro avg       0.41      0.42      0.41       980\n",
      "weighted avg       0.61      0.61      0.61       980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(max_depth= 5, n_estimators=1000, random_state=10, n_jobs=-1)\n",
    "xgb.fit(X_train2_adasyn, y_train2_adasyn)\n",
    "xgb_pred = xgb.predict(X_valid2)\n",
    "print(classification_report(le.inverse_transform(y_valid2), le.inverse_transform(xgb_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdfbcd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a5a7fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807a2ef2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1bd2e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6aa7c419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4898 entries, 0 to 4897\n",
      "Data columns (total 12 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   fixed acidity         4898 non-null   float64\n",
      " 1   volatile acidity      4898 non-null   float64\n",
      " 2   citric acid           4898 non-null   float64\n",
      " 3   residual sugar        4898 non-null   float64\n",
      " 4   chlorides             4898 non-null   float64\n",
      " 5   free sulfur dioxide   4898 non-null   float64\n",
      " 6   total sulfur dioxide  4898 non-null   float64\n",
      " 7   density               4898 non-null   float64\n",
      " 8   pH                    4898 non-null   float64\n",
      " 9   sulphates             4898 non-null   float64\n",
      " 10  alcohol               4898 non-null   float64\n",
      " 11  quality               4898 non-null   int64  \n",
      "dtypes: float64(11), int64(1)\n",
      "memory usage: 459.3 KB\n"
     ]
    }
   ],
   "source": [
    "wine.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c9c720bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = wine.drop('quality', axis=1).copy()\n",
    "y = wine['quality'].copy()\n",
    "y2 = wine['quality'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2917b8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.get_dummies(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f52d6467",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4893</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4894</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4895</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4896</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4897</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4898 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          3      4      5      6      7      8      9\n",
       "0     False  False  False   True  False  False  False\n",
       "1     False  False  False   True  False  False  False\n",
       "2     False  False  False   True  False  False  False\n",
       "3     False  False  False   True  False  False  False\n",
       "4     False  False  False   True  False  False  False\n",
       "...     ...    ...    ...    ...    ...    ...    ...\n",
       "4893  False  False  False   True  False  False  False\n",
       "4894  False  False   True  False  False  False  False\n",
       "4895  False  False  False   True  False  False  False\n",
       "4896  False  False  False  False   True  False  False\n",
       "4897  False  False  False   True  False  False  False\n",
       "\n",
       "[4898 rows x 7 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1ceababf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ffccb7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = RobustScaler()\n",
    "X_scaled = rs.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "92ccf6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bcd4e768",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X_scaled, y, test_size=0.4, stratify=y ,random_state=10)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_valid, y_valid, test_size=0.5, stratify=y_valid, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4e54f012",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7fab3f85",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2938, 11) (980, 11) (980, 11)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_valid.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ac86ea0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3df4f0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(Dense(64, input_dim=11, activation='relu'))\n",
    "model1.add(Dense(32, activation='relu'))\n",
    "model1.add(Dense(64, activation='relu'))\n",
    "model1.add(Dense(32, activation='relu'))\n",
    "model1.add(Dense(16, activation='relu'))\n",
    "model1.add(Dense(7, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "31235ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (None, 64)                768       \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 64)                2112      \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,687\n",
      "Trainable params: 7,687\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7a7582cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2938, 11) (2938, 7)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d029f0c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.6961 - accuracy: 0.7264"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 13:25:53.871275: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-09-10 13:25:53.958331: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-09-10 13:25:53.958403: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15603 MB memory) -> physical PluggableDevice (device: 0, name: DML, pci bus id: <undefined>)\n",
      "2024-09-10 13:25:54.220448: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-09-10 13:25:54.263323: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-09-10 13:25:54.263456: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15603 MB memory) -> physical PluggableDevice (device: 0, name: DML, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 1s 112ms/step - loss: 0.6953 - accuracy: 0.7267 - val_loss: 1.0956 - val_accuracy: 0.5704\n",
      "Epoch 2/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.6792 - accuracy: 0.7291 - val_loss: 1.1067 - val_accuracy: 0.5724\n",
      "Epoch 3/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.6700 - accuracy: 0.7338 - val_loss: 1.1088 - val_accuracy: 0.5776\n",
      "Epoch 4/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.6666 - accuracy: 0.7410 - val_loss: 1.1085 - val_accuracy: 0.5816\n",
      "Epoch 5/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.6607 - accuracy: 0.7471 - val_loss: 1.1134 - val_accuracy: 0.5827\n",
      "Epoch 6/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.6562 - accuracy: 0.7495 - val_loss: 1.1138 - val_accuracy: 0.5837\n",
      "Epoch 7/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.6513 - accuracy: 0.7488 - val_loss: 1.1176 - val_accuracy: 0.5867\n",
      "Epoch 8/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.6497 - accuracy: 0.7526 - val_loss: 1.1186 - val_accuracy: 0.5918\n",
      "Epoch 9/10000\n",
      "6/6 [==============================] - 0s 54ms/step - loss: 0.6454 - accuracy: 0.7570 - val_loss: 1.1258 - val_accuracy: 0.5827\n",
      "Epoch 10/10000\n",
      "6/6 [==============================] - 0s 61ms/step - loss: 0.6437 - accuracy: 0.7543 - val_loss: 1.1324 - val_accuracy: 0.5776\n",
      "Epoch 11/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.6399 - accuracy: 0.7549 - val_loss: 1.1368 - val_accuracy: 0.5816\n",
      "Epoch 12/10000\n",
      "6/6 [==============================] - 0s 63ms/step - loss: 0.6364 - accuracy: 0.7583 - val_loss: 1.1352 - val_accuracy: 0.5847\n",
      "Epoch 13/10000\n",
      "6/6 [==============================] - 0s 57ms/step - loss: 0.6337 - accuracy: 0.7573 - val_loss: 1.1404 - val_accuracy: 0.5816\n",
      "Epoch 14/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.6293 - accuracy: 0.7645 - val_loss: 1.1492 - val_accuracy: 0.5796\n",
      "Epoch 15/10000\n",
      "6/6 [==============================] - 0s 83ms/step - loss: 0.6277 - accuracy: 0.7641 - val_loss: 1.1456 - val_accuracy: 0.5786\n",
      "Epoch 16/10000\n",
      "6/6 [==============================] - 0s 71ms/step - loss: 0.6241 - accuracy: 0.7638 - val_loss: 1.1547 - val_accuracy: 0.5765\n",
      "Epoch 17/10000\n",
      "6/6 [==============================] - 0s 53ms/step - loss: 0.6202 - accuracy: 0.7655 - val_loss: 1.1590 - val_accuracy: 0.5796\n",
      "Epoch 18/10000\n",
      "6/6 [==============================] - 0s 52ms/step - loss: 0.6186 - accuracy: 0.7662 - val_loss: 1.1582 - val_accuracy: 0.5857\n",
      "Epoch 19/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.6162 - accuracy: 0.7675 - val_loss: 1.1730 - val_accuracy: 0.5796\n",
      "Epoch 20/10000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.6159 - accuracy: 0.7692 - val_loss: 1.1623 - val_accuracy: 0.5806\n",
      "Epoch 21/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.6093 - accuracy: 0.7733 - val_loss: 1.1763 - val_accuracy: 0.5745\n",
      "Epoch 22/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.6075 - accuracy: 0.7754 - val_loss: 1.1785 - val_accuracy: 0.5776\n",
      "Epoch 23/10000\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.6053 - accuracy: 0.7675 - val_loss: 1.1753 - val_accuracy: 0.5857\n",
      "Epoch 24/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.6022 - accuracy: 0.7740 - val_loss: 1.1810 - val_accuracy: 0.5704\n",
      "Epoch 25/10000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.6000 - accuracy: 0.7754 - val_loss: 1.1858 - val_accuracy: 0.5796\n",
      "Epoch 26/10000\n",
      "6/6 [==============================] - 0s 52ms/step - loss: 0.5950 - accuracy: 0.7774 - val_loss: 1.1869 - val_accuracy: 0.5837\n",
      "Epoch 27/10000\n",
      "6/6 [==============================] - 0s 69ms/step - loss: 0.5936 - accuracy: 0.7774 - val_loss: 1.1945 - val_accuracy: 0.5724\n",
      "Epoch 28/10000\n",
      "6/6 [==============================] - 0s 71ms/step - loss: 0.5909 - accuracy: 0.7791 - val_loss: 1.1923 - val_accuracy: 0.5745\n",
      "Epoch 29/10000\n",
      "6/6 [==============================] - 0s 54ms/step - loss: 0.5918 - accuracy: 0.7798 - val_loss: 1.1974 - val_accuracy: 0.5755\n",
      "Epoch 30/10000\n",
      "6/6 [==============================] - 0s 72ms/step - loss: 0.5819 - accuracy: 0.7832 - val_loss: 1.1995 - val_accuracy: 0.5765\n",
      "Epoch 31/10000\n",
      "6/6 [==============================] - 0s 68ms/step - loss: 0.5792 - accuracy: 0.7866 - val_loss: 1.2013 - val_accuracy: 0.5745\n",
      "Epoch 32/10000\n",
      "6/6 [==============================] - 0s 65ms/step - loss: 0.5799 - accuracy: 0.7866 - val_loss: 1.2114 - val_accuracy: 0.5806\n",
      "Epoch 33/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.5735 - accuracy: 0.7890 - val_loss: 1.2056 - val_accuracy: 0.5867\n",
      "Epoch 34/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.5702 - accuracy: 0.7859 - val_loss: 1.2117 - val_accuracy: 0.5714\n",
      "Epoch 35/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.5670 - accuracy: 0.7903 - val_loss: 1.2301 - val_accuracy: 0.5724\n",
      "Epoch 36/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.5687 - accuracy: 0.7832 - val_loss: 1.2214 - val_accuracy: 0.5827\n",
      "Epoch 37/10000\n",
      "6/6 [==============================] - 0s 52ms/step - loss: 0.5647 - accuracy: 0.7903 - val_loss: 1.2258 - val_accuracy: 0.5765\n",
      "Epoch 38/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.5633 - accuracy: 0.7897 - val_loss: 1.2378 - val_accuracy: 0.5806\n",
      "Epoch 39/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.5588 - accuracy: 0.7914 - val_loss: 1.2363 - val_accuracy: 0.5786\n",
      "Epoch 40/10000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.5560 - accuracy: 0.7937 - val_loss: 1.2380 - val_accuracy: 0.5776\n",
      "Epoch 41/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.5551 - accuracy: 0.7931 - val_loss: 1.2516 - val_accuracy: 0.5714\n",
      "Epoch 42/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.5601 - accuracy: 0.7856 - val_loss: 1.2524 - val_accuracy: 0.5796\n",
      "Epoch 43/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.5500 - accuracy: 0.7965 - val_loss: 1.2550 - val_accuracy: 0.5776\n",
      "Epoch 44/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.5446 - accuracy: 0.7951 - val_loss: 1.2512 - val_accuracy: 0.5765\n",
      "Epoch 45/10000\n",
      "6/6 [==============================] - 0s 54ms/step - loss: 0.5411 - accuracy: 0.7961 - val_loss: 1.2608 - val_accuracy: 0.5745\n",
      "Epoch 46/10000\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.5400 - accuracy: 0.7988 - val_loss: 1.2651 - val_accuracy: 0.5806\n",
      "Epoch 47/10000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.5372 - accuracy: 0.7971 - val_loss: 1.2811 - val_accuracy: 0.5755\n",
      "Epoch 48/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.5368 - accuracy: 0.7944 - val_loss: 1.2678 - val_accuracy: 0.5755\n",
      "Epoch 49/10000\n",
      "6/6 [==============================] - 0s 54ms/step - loss: 0.5312 - accuracy: 0.8039 - val_loss: 1.2724 - val_accuracy: 0.5724\n",
      "Epoch 50/10000\n",
      "6/6 [==============================] - 0s 69ms/step - loss: 0.5301 - accuracy: 0.7999 - val_loss: 1.2810 - val_accuracy: 0.5765\n",
      "Epoch 51/10000\n",
      "6/6 [==============================] - 0s 62ms/step - loss: 0.5244 - accuracy: 0.8016 - val_loss: 1.2834 - val_accuracy: 0.5755\n",
      "Epoch 52/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.5254 - accuracy: 0.8029 - val_loss: 1.2911 - val_accuracy: 0.5735\n",
      "Epoch 53/10000\n",
      "6/6 [==============================] - 0s 60ms/step - loss: 0.5205 - accuracy: 0.8087 - val_loss: 1.2895 - val_accuracy: 0.5776\n",
      "Epoch 54/10000\n",
      "6/6 [==============================] - 0s 52ms/step - loss: 0.5203 - accuracy: 0.8067 - val_loss: 1.3032 - val_accuracy: 0.5704\n",
      "Epoch 55/10000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.5177 - accuracy: 0.8074 - val_loss: 1.3012 - val_accuracy: 0.5724\n",
      "Epoch 56/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.5148 - accuracy: 0.8131 - val_loss: 1.3035 - val_accuracy: 0.5694\n",
      "Epoch 57/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.5106 - accuracy: 0.8111 - val_loss: 1.3102 - val_accuracy: 0.5694\n",
      "Epoch 58/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 50ms/step - loss: 0.5052 - accuracy: 0.8111 - val_loss: 1.3158 - val_accuracy: 0.5765\n",
      "Epoch 59/10000\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.5043 - accuracy: 0.8118 - val_loss: 1.3200 - val_accuracy: 0.5745\n",
      "Epoch 60/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.5006 - accuracy: 0.8142 - val_loss: 1.3282 - val_accuracy: 0.5653\n",
      "Epoch 61/10000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.4983 - accuracy: 0.8182 - val_loss: 1.3253 - val_accuracy: 0.5796\n",
      "Epoch 62/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.4966 - accuracy: 0.8196 - val_loss: 1.3376 - val_accuracy: 0.5694\n",
      "Epoch 63/10000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.4926 - accuracy: 0.8159 - val_loss: 1.3374 - val_accuracy: 0.5765\n",
      "Epoch 64/10000\n",
      "6/6 [==============================] - 0s 52ms/step - loss: 0.4914 - accuracy: 0.8206 - val_loss: 1.3432 - val_accuracy: 0.5745\n",
      "Epoch 65/10000\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.4881 - accuracy: 0.8203 - val_loss: 1.3543 - val_accuracy: 0.5704\n",
      "Epoch 66/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.4870 - accuracy: 0.8206 - val_loss: 1.3499 - val_accuracy: 0.5714\n",
      "Epoch 67/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.4842 - accuracy: 0.8172 - val_loss: 1.3560 - val_accuracy: 0.5786\n",
      "Epoch 68/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.4801 - accuracy: 0.8295 - val_loss: 1.3624 - val_accuracy: 0.5806\n",
      "Epoch 69/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.4843 - accuracy: 0.8216 - val_loss: 1.3699 - val_accuracy: 0.5724\n",
      "Epoch 70/10000\n",
      "6/6 [==============================] - 0s 57ms/step - loss: 0.4757 - accuracy: 0.8220 - val_loss: 1.3695 - val_accuracy: 0.5776\n",
      "Epoch 71/10000\n",
      "6/6 [==============================] - 0s 75ms/step - loss: 0.4785 - accuracy: 0.8216 - val_loss: 1.3789 - val_accuracy: 0.5755\n",
      "Epoch 72/10000\n",
      "6/6 [==============================] - 0s 57ms/step - loss: 0.4737 - accuracy: 0.8240 - val_loss: 1.3742 - val_accuracy: 0.5745\n",
      "Epoch 73/10000\n",
      "6/6 [==============================] - 0s 52ms/step - loss: 0.4731 - accuracy: 0.8237 - val_loss: 1.3832 - val_accuracy: 0.5735\n",
      "Epoch 74/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.4699 - accuracy: 0.8285 - val_loss: 1.3949 - val_accuracy: 0.5714\n",
      "Epoch 75/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.4661 - accuracy: 0.8315 - val_loss: 1.3969 - val_accuracy: 0.5694\n",
      "Epoch 76/10000\n",
      "6/6 [==============================] - 0s 61ms/step - loss: 0.4634 - accuracy: 0.8308 - val_loss: 1.3998 - val_accuracy: 0.5765\n",
      "Epoch 77/10000\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.4644 - accuracy: 0.8336 - val_loss: 1.4096 - val_accuracy: 0.5745\n",
      "Epoch 78/10000\n",
      "6/6 [==============================] - 0s 58ms/step - loss: 0.4641 - accuracy: 0.8271 - val_loss: 1.4158 - val_accuracy: 0.5684\n",
      "Epoch 79/10000\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.4574 - accuracy: 0.8336 - val_loss: 1.4287 - val_accuracy: 0.5663\n",
      "Epoch 80/10000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.4600 - accuracy: 0.8288 - val_loss: 1.4142 - val_accuracy: 0.5816\n",
      "Epoch 81/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.4534 - accuracy: 0.8380 - val_loss: 1.4252 - val_accuracy: 0.5786\n",
      "Epoch 82/10000\n",
      "6/6 [==============================] - 0s 58ms/step - loss: 0.4537 - accuracy: 0.8424 - val_loss: 1.4198 - val_accuracy: 0.5755\n",
      "Epoch 83/10000\n",
      "6/6 [==============================] - 0s 63ms/step - loss: 0.4491 - accuracy: 0.8373 - val_loss: 1.4506 - val_accuracy: 0.5643\n",
      "Epoch 84/10000\n",
      "6/6 [==============================] - 0s 59ms/step - loss: 0.4450 - accuracy: 0.8397 - val_loss: 1.4563 - val_accuracy: 0.5776\n",
      "Epoch 85/10000\n",
      "6/6 [==============================] - 0s 56ms/step - loss: 0.4464 - accuracy: 0.8414 - val_loss: 1.4455 - val_accuracy: 0.5684\n",
      "Epoch 86/10000\n",
      "6/6 [==============================] - 0s 55ms/step - loss: 0.4423 - accuracy: 0.8434 - val_loss: 1.4435 - val_accuracy: 0.5796\n",
      "Epoch 87/10000\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.4347 - accuracy: 0.8472 - val_loss: 1.4703 - val_accuracy: 0.5663\n",
      "Epoch 88/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.4380 - accuracy: 0.8465 - val_loss: 1.4643 - val_accuracy: 0.5724\n",
      "Epoch 89/10000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.4334 - accuracy: 0.8509 - val_loss: 1.4662 - val_accuracy: 0.5776\n",
      "Epoch 90/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.4317 - accuracy: 0.8462 - val_loss: 1.4762 - val_accuracy: 0.5684\n",
      "Epoch 91/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.4285 - accuracy: 0.8489 - val_loss: 1.4785 - val_accuracy: 0.5694\n",
      "Epoch 92/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.4248 - accuracy: 0.8536 - val_loss: 1.4793 - val_accuracy: 0.5755\n",
      "Epoch 93/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.4254 - accuracy: 0.8492 - val_loss: 1.5008 - val_accuracy: 0.5755\n",
      "Epoch 94/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.4248 - accuracy: 0.8513 - val_loss: 1.4801 - val_accuracy: 0.5765\n",
      "Epoch 95/10000\n",
      "6/6 [==============================] - 0s 53ms/step - loss: 0.4243 - accuracy: 0.8475 - val_loss: 1.4966 - val_accuracy: 0.5776\n",
      "Epoch 96/10000\n",
      "6/6 [==============================] - 0s 54ms/step - loss: 0.4213 - accuracy: 0.8523 - val_loss: 1.5162 - val_accuracy: 0.5714\n",
      "Epoch 97/10000\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 0.4192 - accuracy: 0.8533 - val_loss: 1.5254 - val_accuracy: 0.5735\n",
      "Epoch 98/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.4146 - accuracy: 0.8499 - val_loss: 1.5130 - val_accuracy: 0.5755\n",
      "Epoch 99/10000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.4096 - accuracy: 0.8577 - val_loss: 1.5108 - val_accuracy: 0.5704\n",
      "Epoch 100/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.4073 - accuracy: 0.8584 - val_loss: 1.5171 - val_accuracy: 0.5745\n",
      "Epoch 101/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.4031 - accuracy: 0.8608 - val_loss: 1.5343 - val_accuracy: 0.5673\n",
      "Epoch 102/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.4017 - accuracy: 0.8604 - val_loss: 1.5314 - val_accuracy: 0.5857\n",
      "Epoch 103/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.4028 - accuracy: 0.8601 - val_loss: 1.5297 - val_accuracy: 0.5724\n",
      "Epoch 104/10000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.4030 - accuracy: 0.8577 - val_loss: 1.5562 - val_accuracy: 0.5704\n",
      "Epoch 105/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.3992 - accuracy: 0.8611 - val_loss: 1.5591 - val_accuracy: 0.5714\n",
      "Epoch 106/10000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.4009 - accuracy: 0.8632 - val_loss: 1.5551 - val_accuracy: 0.5745\n",
      "Epoch 107/10000\n",
      "6/6 [==============================] - 0s 52ms/step - loss: 0.3938 - accuracy: 0.8659 - val_loss: 1.5633 - val_accuracy: 0.5776\n",
      "Epoch 108/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.3995 - accuracy: 0.8618 - val_loss: 1.5636 - val_accuracy: 0.5786\n",
      "Epoch 109/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.3929 - accuracy: 0.8659 - val_loss: 1.5779 - val_accuracy: 0.5694\n",
      "Epoch 110/10000\n",
      "6/6 [==============================] - 0s 52ms/step - loss: 0.3864 - accuracy: 0.8673 - val_loss: 1.5727 - val_accuracy: 0.5816\n",
      "Epoch 111/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.3807 - accuracy: 0.8700 - val_loss: 1.5750 - val_accuracy: 0.5837\n",
      "Epoch 112/10000\n",
      "6/6 [==============================] - 0s 53ms/step - loss: 0.3803 - accuracy: 0.8696 - val_loss: 1.5926 - val_accuracy: 0.5827\n",
      "Epoch 113/10000\n",
      "6/6 [==============================] - 0s 54ms/step - loss: 0.3784 - accuracy: 0.8700 - val_loss: 1.5922 - val_accuracy: 0.5765\n",
      "Epoch 114/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.3767 - accuracy: 0.8696 - val_loss: 1.5968 - val_accuracy: 0.5735\n",
      "Epoch 115/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 51ms/step - loss: 0.3712 - accuracy: 0.8775 - val_loss: 1.6128 - val_accuracy: 0.5755\n",
      "Epoch 116/10000\n",
      "6/6 [==============================] - 0s 52ms/step - loss: 0.3719 - accuracy: 0.8713 - val_loss: 1.6118 - val_accuracy: 0.5786\n",
      "Epoch 117/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.3705 - accuracy: 0.8764 - val_loss: 1.6069 - val_accuracy: 0.5786\n",
      "Epoch 118/10000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.3730 - accuracy: 0.8662 - val_loss: 1.6230 - val_accuracy: 0.5765\n",
      "Epoch 119/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.3696 - accuracy: 0.8730 - val_loss: 1.6389 - val_accuracy: 0.5735\n",
      "Epoch 120/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.3678 - accuracy: 0.8734 - val_loss: 1.6422 - val_accuracy: 0.5684\n",
      "Epoch 121/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.3651 - accuracy: 0.8720 - val_loss: 1.6560 - val_accuracy: 0.5776\n",
      "Epoch 122/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.3627 - accuracy: 0.8775 - val_loss: 1.6561 - val_accuracy: 0.5694\n",
      "Epoch 123/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.3576 - accuracy: 0.8819 - val_loss: 1.6584 - val_accuracy: 0.5755\n",
      "Epoch 124/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.3558 - accuracy: 0.8809 - val_loss: 1.6715 - val_accuracy: 0.5735\n",
      "Epoch 125/10000\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 0.3608 - accuracy: 0.8764 - val_loss: 1.6954 - val_accuracy: 0.5755\n",
      "Epoch 126/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.3551 - accuracy: 0.8843 - val_loss: 1.6685 - val_accuracy: 0.5765\n",
      "Epoch 127/10000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.3530 - accuracy: 0.8781 - val_loss: 1.6755 - val_accuracy: 0.5745\n",
      "Epoch 128/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.3487 - accuracy: 0.8812 - val_loss: 1.6701 - val_accuracy: 0.5704\n",
      "Epoch 129/10000\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.3458 - accuracy: 0.8819 - val_loss: 1.6904 - val_accuracy: 0.5745\n",
      "Epoch 130/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.3430 - accuracy: 0.8887 - val_loss: 1.7143 - val_accuracy: 0.5745\n",
      "Epoch 131/10000\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.3416 - accuracy: 0.8897 - val_loss: 1.7143 - val_accuracy: 0.5796\n",
      "Epoch 132/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.3397 - accuracy: 0.8880 - val_loss: 1.6983 - val_accuracy: 0.5796\n",
      "Epoch 133/10000\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.3390 - accuracy: 0.8870 - val_loss: 1.7056 - val_accuracy: 0.5765\n",
      "Epoch 134/10000\n",
      "6/6 [==============================] - 0s 55ms/step - loss: 0.3387 - accuracy: 0.8819 - val_loss: 1.7317 - val_accuracy: 0.5714\n",
      "Epoch 135/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.3398 - accuracy: 0.8860 - val_loss: 1.7413 - val_accuracy: 0.5786\n",
      "Epoch 136/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.3382 - accuracy: 0.8843 - val_loss: 1.7562 - val_accuracy: 0.5714\n",
      "Epoch 137/10000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.3352 - accuracy: 0.8867 - val_loss: 1.7308 - val_accuracy: 0.5776\n",
      "Epoch 138/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.3317 - accuracy: 0.8914 - val_loss: 1.7389 - val_accuracy: 0.5776\n",
      "Epoch 139/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.3277 - accuracy: 0.8918 - val_loss: 1.7342 - val_accuracy: 0.5796\n",
      "Epoch 140/10000\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.3290 - accuracy: 0.8873 - val_loss: 1.7502 - val_accuracy: 0.5827\n",
      "Epoch 141/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.3296 - accuracy: 0.8890 - val_loss: 1.7533 - val_accuracy: 0.5724\n",
      "Epoch 142/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.3225 - accuracy: 0.8935 - val_loss: 1.7670 - val_accuracy: 0.5745\n",
      "Epoch 143/10000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.3271 - accuracy: 0.8952 - val_loss: 1.7588 - val_accuracy: 0.5806\n",
      "Epoch 144/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.3232 - accuracy: 0.8972 - val_loss: 1.7863 - val_accuracy: 0.5735\n",
      "Epoch 145/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.3196 - accuracy: 0.8952 - val_loss: 1.7999 - val_accuracy: 0.5827\n",
      "Epoch 146/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.3146 - accuracy: 0.9003 - val_loss: 1.8113 - val_accuracy: 0.5735\n",
      "Epoch 147/10000\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.3164 - accuracy: 0.8993 - val_loss: 1.8124 - val_accuracy: 0.5806\n",
      "Epoch 148/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.3136 - accuracy: 0.8975 - val_loss: 1.8201 - val_accuracy: 0.5704\n",
      "Epoch 149/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.3126 - accuracy: 0.8982 - val_loss: 1.8430 - val_accuracy: 0.5806\n",
      "Epoch 150/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.3102 - accuracy: 0.8999 - val_loss: 1.8291 - val_accuracy: 0.5816\n",
      "Epoch 151/10000\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.3148 - accuracy: 0.8962 - val_loss: 1.8322 - val_accuracy: 0.5867\n",
      "Epoch 152/10000\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 0.3077 - accuracy: 0.9033 - val_loss: 1.8352 - val_accuracy: 0.5827\n",
      "Epoch 153/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.3040 - accuracy: 0.9013 - val_loss: 1.8505 - val_accuracy: 0.5786\n",
      "Epoch 154/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.3001 - accuracy: 0.9098 - val_loss: 1.8628 - val_accuracy: 0.5837\n",
      "Epoch 155/10000\n",
      "6/6 [==============================] - 0s 64ms/step - loss: 0.3046 - accuracy: 0.9033 - val_loss: 1.8608 - val_accuracy: 0.5806\n",
      "Epoch 156/10000\n",
      "6/6 [==============================] - 0s 57ms/step - loss: 0.3003 - accuracy: 0.9050 - val_loss: 1.8491 - val_accuracy: 0.5755\n",
      "Epoch 157/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.2993 - accuracy: 0.9027 - val_loss: 1.8660 - val_accuracy: 0.5724\n",
      "Epoch 158/10000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.2961 - accuracy: 0.9050 - val_loss: 1.8698 - val_accuracy: 0.5776\n",
      "Epoch 159/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.2981 - accuracy: 0.9057 - val_loss: 1.8788 - val_accuracy: 0.5776\n",
      "Epoch 160/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.2905 - accuracy: 0.9084 - val_loss: 1.8961 - val_accuracy: 0.5806\n",
      "Epoch 161/10000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.2864 - accuracy: 0.9108 - val_loss: 1.8957 - val_accuracy: 0.5827\n",
      "Epoch 162/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.2846 - accuracy: 0.9125 - val_loss: 1.9036 - val_accuracy: 0.5776\n",
      "Epoch 163/10000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.2817 - accuracy: 0.9163 - val_loss: 1.9104 - val_accuracy: 0.5806\n",
      "Epoch 164/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.2847 - accuracy: 0.9095 - val_loss: 1.9484 - val_accuracy: 0.5765\n",
      "Epoch 165/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.2888 - accuracy: 0.9084 - val_loss: 1.9512 - val_accuracy: 0.5867\n",
      "Epoch 166/10000\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 0.2895 - accuracy: 0.9044 - val_loss: 1.9552 - val_accuracy: 0.5745\n",
      "Epoch 167/10000\n",
      "6/6 [==============================] - 0s 52ms/step - loss: 0.2864 - accuracy: 0.9091 - val_loss: 1.9730 - val_accuracy: 0.5776\n",
      "Epoch 168/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.2841 - accuracy: 0.9067 - val_loss: 1.9628 - val_accuracy: 0.5755\n",
      "Epoch 169/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.2810 - accuracy: 0.9074 - val_loss: 1.9621 - val_accuracy: 0.5837\n",
      "Epoch 170/10000\n",
      "6/6 [==============================] - 0s 53ms/step - loss: 0.2752 - accuracy: 0.9183 - val_loss: 1.9768 - val_accuracy: 0.5878\n",
      "Epoch 171/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.2797 - accuracy: 0.9067 - val_loss: 1.9881 - val_accuracy: 0.5694\n",
      "Epoch 172/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 47ms/step - loss: 0.2751 - accuracy: 0.9183 - val_loss: 1.9710 - val_accuracy: 0.5878\n",
      "Epoch 173/10000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.2759 - accuracy: 0.9091 - val_loss: 2.0008 - val_accuracy: 0.5714\n",
      "Epoch 174/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.2734 - accuracy: 0.9180 - val_loss: 1.9920 - val_accuracy: 0.5867\n",
      "Epoch 175/10000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.2669 - accuracy: 0.9190 - val_loss: 2.0175 - val_accuracy: 0.5704\n",
      "Epoch 176/10000\n",
      "6/6 [==============================] - 0s 53ms/step - loss: 0.2662 - accuracy: 0.9197 - val_loss: 2.0045 - val_accuracy: 0.5888\n",
      "Epoch 177/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.2677 - accuracy: 0.9183 - val_loss: 2.0250 - val_accuracy: 0.5806\n",
      "Epoch 178/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.2617 - accuracy: 0.9200 - val_loss: 2.0505 - val_accuracy: 0.5857\n",
      "Epoch 179/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.2598 - accuracy: 0.9217 - val_loss: 2.0431 - val_accuracy: 0.5847\n",
      "Epoch 180/10000\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.2592 - accuracy: 0.9190 - val_loss: 2.0531 - val_accuracy: 0.5847\n",
      "Epoch 181/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.2563 - accuracy: 0.9224 - val_loss: 2.0763 - val_accuracy: 0.5816\n",
      "Epoch 182/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.2540 - accuracy: 0.9261 - val_loss: 2.0546 - val_accuracy: 0.5847\n",
      "Epoch 183/10000\n",
      "6/6 [==============================] - 0s 53ms/step - loss: 0.2497 - accuracy: 0.9251 - val_loss: 2.0757 - val_accuracy: 0.5806\n",
      "Epoch 184/10000\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.2480 - accuracy: 0.9258 - val_loss: 2.0467 - val_accuracy: 0.5806\n",
      "Epoch 185/10000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.2509 - accuracy: 0.9272 - val_loss: 2.0782 - val_accuracy: 0.5827\n",
      "Epoch 186/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.2469 - accuracy: 0.9265 - val_loss: 2.0867 - val_accuracy: 0.5847\n",
      "Epoch 187/10000\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.2512 - accuracy: 0.9238 - val_loss: 2.0884 - val_accuracy: 0.5898\n",
      "Epoch 188/10000\n",
      "6/6 [==============================] - 0s 53ms/step - loss: 0.2460 - accuracy: 0.9272 - val_loss: 2.1016 - val_accuracy: 0.5806\n",
      "Epoch 189/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.2425 - accuracy: 0.9275 - val_loss: 2.1125 - val_accuracy: 0.5847\n",
      "Epoch 190/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.2425 - accuracy: 0.9299 - val_loss: 2.1146 - val_accuracy: 0.5776\n",
      "Epoch 191/10000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.2425 - accuracy: 0.9231 - val_loss: 2.1054 - val_accuracy: 0.5837\n",
      "Epoch 192/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.2415 - accuracy: 0.9265 - val_loss: 2.1530 - val_accuracy: 0.5806\n",
      "Epoch 193/10000\n",
      "6/6 [==============================] - 0s 57ms/step - loss: 0.2398 - accuracy: 0.9323 - val_loss: 2.1295 - val_accuracy: 0.5837\n",
      "Epoch 194/10000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.2360 - accuracy: 0.9295 - val_loss: 2.1825 - val_accuracy: 0.5816\n",
      "Epoch 195/10000\n",
      "6/6 [==============================] - 0s 52ms/step - loss: 0.2359 - accuracy: 0.9299 - val_loss: 2.1562 - val_accuracy: 0.5847\n",
      "Epoch 196/10000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.2351 - accuracy: 0.9282 - val_loss: 2.1748 - val_accuracy: 0.5827\n",
      "Epoch 197/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.2309 - accuracy: 0.9323 - val_loss: 2.1829 - val_accuracy: 0.5857\n",
      "Epoch 198/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.2295 - accuracy: 0.9370 - val_loss: 2.2057 - val_accuracy: 0.5837\n",
      "Epoch 199/10000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.2337 - accuracy: 0.9295 - val_loss: 2.2089 - val_accuracy: 0.5755\n",
      "Epoch 200/10000\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.2324 - accuracy: 0.9295 - val_loss: 2.2089 - val_accuracy: 0.5867\n",
      "Epoch 201/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.2262 - accuracy: 0.9353 - val_loss: 2.2076 - val_accuracy: 0.5867\n",
      "Epoch 202/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.2233 - accuracy: 0.9343 - val_loss: 2.2284 - val_accuracy: 0.5857\n",
      "Epoch 203/10000\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.2203 - accuracy: 0.9374 - val_loss: 2.2445 - val_accuracy: 0.5878\n",
      "Epoch 204/10000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.2210 - accuracy: 0.9350 - val_loss: 2.2410 - val_accuracy: 0.5857\n",
      "Epoch 205/10000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.2193 - accuracy: 0.9364 - val_loss: 2.2621 - val_accuracy: 0.5816\n",
      "Epoch 206/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.2168 - accuracy: 0.9370 - val_loss: 2.2553 - val_accuracy: 0.5827\n",
      "Epoch 207/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.2144 - accuracy: 0.9387 - val_loss: 2.2900 - val_accuracy: 0.5857\n",
      "Epoch 208/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.2158 - accuracy: 0.9353 - val_loss: 2.3062 - val_accuracy: 0.5857\n",
      "Epoch 209/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.2178 - accuracy: 0.9340 - val_loss: 2.2916 - val_accuracy: 0.5888\n",
      "Epoch 210/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.2131 - accuracy: 0.9387 - val_loss: 2.3344 - val_accuracy: 0.5929\n",
      "Epoch 211/10000\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.2152 - accuracy: 0.9381 - val_loss: 2.2938 - val_accuracy: 0.5867\n",
      "Epoch 212/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.2120 - accuracy: 0.9387 - val_loss: 2.3136 - val_accuracy: 0.5837\n",
      "Epoch 213/10000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.2111 - accuracy: 0.9381 - val_loss: 2.3482 - val_accuracy: 0.5867\n",
      "Epoch 214/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.2080 - accuracy: 0.9391 - val_loss: 2.3377 - val_accuracy: 0.5878\n",
      "Epoch 215/10000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.2039 - accuracy: 0.9411 - val_loss: 2.3407 - val_accuracy: 0.5857\n",
      "Epoch 216/10000\n",
      "6/6 [==============================] - 0s 54ms/step - loss: 0.2064 - accuracy: 0.9384 - val_loss: 2.3495 - val_accuracy: 0.5827\n",
      "Epoch 217/10000\n",
      "6/6 [==============================] - 0s 54ms/step - loss: 0.2061 - accuracy: 0.9411 - val_loss: 2.3728 - val_accuracy: 0.5867\n",
      "Epoch 218/10000\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.2017 - accuracy: 0.9408 - val_loss: 2.3659 - val_accuracy: 0.5857\n",
      "Epoch 219/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.2022 - accuracy: 0.9404 - val_loss: 2.3656 - val_accuracy: 0.5878\n",
      "Epoch 220/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.1978 - accuracy: 0.9408 - val_loss: 2.3980 - val_accuracy: 0.5827\n",
      "Epoch 221/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.1962 - accuracy: 0.9459 - val_loss: 2.3790 - val_accuracy: 0.5847\n",
      "Epoch 222/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.1980 - accuracy: 0.9415 - val_loss: 2.3912 - val_accuracy: 0.5867\n",
      "Epoch 223/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.1962 - accuracy: 0.9421 - val_loss: 2.4084 - val_accuracy: 0.5908\n",
      "Epoch 224/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.1973 - accuracy: 0.9387 - val_loss: 2.4190 - val_accuracy: 0.5857\n",
      "Epoch 225/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.1950 - accuracy: 0.9432 - val_loss: 2.4255 - val_accuracy: 0.5847\n",
      "Epoch 226/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.1925 - accuracy: 0.9469 - val_loss: 2.4546 - val_accuracy: 0.5847\n",
      "Epoch 227/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.1976 - accuracy: 0.9391 - val_loss: 2.5036 - val_accuracy: 0.5888\n",
      "Epoch 228/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.1953 - accuracy: 0.9432 - val_loss: 2.4659 - val_accuracy: 0.5908\n",
      "Epoch 229/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 46ms/step - loss: 0.1979 - accuracy: 0.9418 - val_loss: 2.4489 - val_accuracy: 0.5888\n",
      "Epoch 230/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.1897 - accuracy: 0.9449 - val_loss: 2.4769 - val_accuracy: 0.5939\n",
      "Epoch 231/10000\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.1913 - accuracy: 0.9442 - val_loss: 2.4951 - val_accuracy: 0.5908\n",
      "Epoch 232/10000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.1921 - accuracy: 0.9438 - val_loss: 2.4813 - val_accuracy: 0.5878\n",
      "Epoch 233/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.1882 - accuracy: 0.9445 - val_loss: 2.4835 - val_accuracy: 0.5837\n",
      "Epoch 234/10000\n",
      "6/6 [==============================] - 0s 53ms/step - loss: 0.1846 - accuracy: 0.9489 - val_loss: 2.4790 - val_accuracy: 0.5888\n",
      "Epoch 235/10000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.1853 - accuracy: 0.9476 - val_loss: 2.5038 - val_accuracy: 0.5949\n",
      "Epoch 236/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.1815 - accuracy: 0.9466 - val_loss: 2.5262 - val_accuracy: 0.5908\n",
      "Epoch 237/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.1805 - accuracy: 0.9503 - val_loss: 2.5091 - val_accuracy: 0.5898\n",
      "Epoch 238/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.1804 - accuracy: 0.9506 - val_loss: 2.5476 - val_accuracy: 0.5878\n",
      "Epoch 239/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.1813 - accuracy: 0.9483 - val_loss: 2.5466 - val_accuracy: 0.5898\n",
      "Epoch 240/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.1837 - accuracy: 0.9513 - val_loss: 2.5616 - val_accuracy: 0.5857\n",
      "Epoch 241/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.1799 - accuracy: 0.9496 - val_loss: 2.5689 - val_accuracy: 0.5898\n",
      "Epoch 242/10000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.1778 - accuracy: 0.9513 - val_loss: 2.6061 - val_accuracy: 0.5918\n",
      "Epoch 243/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.1799 - accuracy: 0.9445 - val_loss: 2.5751 - val_accuracy: 0.5898\n",
      "Epoch 244/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.1742 - accuracy: 0.9520 - val_loss: 2.6079 - val_accuracy: 0.5878\n",
      "Epoch 245/10000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.1731 - accuracy: 0.9486 - val_loss: 2.6036 - val_accuracy: 0.5929\n",
      "Epoch 246/10000\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.1713 - accuracy: 0.9537 - val_loss: 2.6242 - val_accuracy: 0.5939\n",
      "Epoch 247/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.1671 - accuracy: 0.9551 - val_loss: 2.6247 - val_accuracy: 0.5918\n",
      "Epoch 248/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.1684 - accuracy: 0.9547 - val_loss: 2.6361 - val_accuracy: 0.5918\n",
      "Epoch 249/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.1674 - accuracy: 0.9537 - val_loss: 2.6698 - val_accuracy: 0.5878\n",
      "Epoch 250/10000\n",
      "6/6 [==============================] - 0s 54ms/step - loss: 0.1665 - accuracy: 0.9554 - val_loss: 2.6302 - val_accuracy: 0.5888\n",
      "Epoch 251/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.1634 - accuracy: 0.9558 - val_loss: 2.6489 - val_accuracy: 0.5959\n",
      "Epoch 252/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.1615 - accuracy: 0.9578 - val_loss: 2.6783 - val_accuracy: 0.5837\n",
      "Epoch 253/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.1639 - accuracy: 0.9564 - val_loss: 2.6850 - val_accuracy: 0.5908\n",
      "Epoch 254/10000\n",
      "6/6 [==============================] - 0s 53ms/step - loss: 0.1601 - accuracy: 0.9585 - val_loss: 2.7025 - val_accuracy: 0.5898\n",
      "Epoch 255/10000\n",
      "6/6 [==============================] - 0s 53ms/step - loss: 0.1613 - accuracy: 0.9588 - val_loss: 2.7010 - val_accuracy: 0.5918\n",
      "Epoch 256/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.1646 - accuracy: 0.9551 - val_loss: 2.6916 - val_accuracy: 0.5939\n",
      "Epoch 257/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.1602 - accuracy: 0.9571 - val_loss: 2.7090 - val_accuracy: 0.5929\n",
      "Epoch 258/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.1606 - accuracy: 0.9537 - val_loss: 2.7100 - val_accuracy: 0.5918\n",
      "Epoch 259/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.1567 - accuracy: 0.9605 - val_loss: 2.7497 - val_accuracy: 0.5918\n",
      "Epoch 260/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.1561 - accuracy: 0.9592 - val_loss: 2.7296 - val_accuracy: 0.5949\n",
      "Epoch 261/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.1564 - accuracy: 0.9578 - val_loss: 2.7822 - val_accuracy: 0.5816\n",
      "Epoch 262/10000\n",
      "6/6 [==============================] - 0s 52ms/step - loss: 0.1622 - accuracy: 0.9547 - val_loss: 2.7397 - val_accuracy: 0.5929\n",
      "Epoch 263/10000\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.1561 - accuracy: 0.9571 - val_loss: 2.7862 - val_accuracy: 0.5959\n",
      "Epoch 264/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.1527 - accuracy: 0.9595 - val_loss: 2.8014 - val_accuracy: 0.5929\n",
      "Epoch 265/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.1533 - accuracy: 0.9578 - val_loss: 2.8163 - val_accuracy: 0.5939\n",
      "Epoch 266/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.1537 - accuracy: 0.9605 - val_loss: 2.8447 - val_accuracy: 0.5939\n",
      "Epoch 267/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.1478 - accuracy: 0.9612 - val_loss: 2.8522 - val_accuracy: 0.5898\n",
      "Epoch 268/10000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.1467 - accuracy: 0.9632 - val_loss: 2.8310 - val_accuracy: 0.5908\n",
      "Epoch 269/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.1476 - accuracy: 0.9615 - val_loss: 2.8403 - val_accuracy: 0.5939\n",
      "Epoch 270/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.1425 - accuracy: 0.9636 - val_loss: 2.8599 - val_accuracy: 0.5918\n",
      "Epoch 271/10000\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.1414 - accuracy: 0.9670 - val_loss: 2.8998 - val_accuracy: 0.5939\n",
      "Epoch 272/10000\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.1417 - accuracy: 0.9656 - val_loss: 2.8877 - val_accuracy: 0.5969\n",
      "Epoch 273/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.1440 - accuracy: 0.9609 - val_loss: 2.9298 - val_accuracy: 0.5980\n",
      "Epoch 274/10000\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.1413 - accuracy: 0.9646 - val_loss: 2.9310 - val_accuracy: 0.5959\n",
      "Epoch 275/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.1428 - accuracy: 0.9578 - val_loss: 2.9182 - val_accuracy: 0.5929\n",
      "Epoch 276/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.1403 - accuracy: 0.9639 - val_loss: 2.9158 - val_accuracy: 0.5908\n",
      "Epoch 277/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.1381 - accuracy: 0.9653 - val_loss: 2.9280 - val_accuracy: 0.5908\n",
      "Epoch 278/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.1402 - accuracy: 0.9626 - val_loss: 2.9328 - val_accuracy: 0.5867\n",
      "Epoch 279/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.1443 - accuracy: 0.9595 - val_loss: 2.9726 - val_accuracy: 0.5888\n",
      "Epoch 280/10000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.1374 - accuracy: 0.9677 - val_loss: 2.9512 - val_accuracy: 0.5939\n",
      "Epoch 281/10000\n",
      "6/6 [==============================] - 0s 52ms/step - loss: 0.1378 - accuracy: 0.9636 - val_loss: 2.9502 - val_accuracy: 0.5878\n",
      "Epoch 282/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.1364 - accuracy: 0.9649 - val_loss: 2.9523 - val_accuracy: 0.5949\n",
      "Epoch 283/10000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.1372 - accuracy: 0.9670 - val_loss: 2.9544 - val_accuracy: 0.5939\n",
      "Epoch 284/10000\n",
      "6/6 [==============================] - 0s 53ms/step - loss: 0.1346 - accuracy: 0.9670 - val_loss: 2.9897 - val_accuracy: 0.5949\n",
      "Epoch 285/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.1305 - accuracy: 0.9680 - val_loss: 3.0174 - val_accuracy: 0.5949\n",
      "Epoch 286/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 49ms/step - loss: 0.1307 - accuracy: 0.9656 - val_loss: 3.0159 - val_accuracy: 0.5918\n",
      "Epoch 287/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.1259 - accuracy: 0.9697 - val_loss: 3.0116 - val_accuracy: 0.5888\n",
      "Epoch 288/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.1269 - accuracy: 0.9704 - val_loss: 3.0346 - val_accuracy: 0.5837\n",
      "Epoch 289/10000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.1347 - accuracy: 0.9629 - val_loss: 3.0262 - val_accuracy: 0.5867\n",
      "Epoch 290/10000\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 0.1387 - accuracy: 0.9636 - val_loss: 3.0635 - val_accuracy: 0.5898\n",
      "Epoch 291/10000\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.1320 - accuracy: 0.9660 - val_loss: 3.0543 - val_accuracy: 0.5857\n",
      "Epoch 292/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.1308 - accuracy: 0.9663 - val_loss: 3.1053 - val_accuracy: 0.5847\n",
      "Epoch 293/10000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.1297 - accuracy: 0.9680 - val_loss: 3.0622 - val_accuracy: 0.5929\n",
      "Epoch 294/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.1268 - accuracy: 0.9680 - val_loss: 3.0999 - val_accuracy: 0.5837\n",
      "Epoch 295/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.1316 - accuracy: 0.9632 - val_loss: 3.1145 - val_accuracy: 0.6010\n",
      "Epoch 296/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.1331 - accuracy: 0.9639 - val_loss: 3.1414 - val_accuracy: 0.5929\n",
      "Epoch 297/10000\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.1348 - accuracy: 0.9636 - val_loss: 3.1549 - val_accuracy: 0.6000\n",
      "Epoch 298/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.1371 - accuracy: 0.9622 - val_loss: 3.1260 - val_accuracy: 0.5980\n",
      "Epoch 299/10000\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.1414 - accuracy: 0.9602 - val_loss: 3.1765 - val_accuracy: 0.5857\n",
      "Epoch 300/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.1334 - accuracy: 0.9639 - val_loss: 3.1931 - val_accuracy: 0.5939\n",
      "Epoch 301/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.1229 - accuracy: 0.9694 - val_loss: 3.1659 - val_accuracy: 0.5888\n",
      "Epoch 302/10000\n",
      "6/6 [==============================] - 0s 54ms/step - loss: 0.1185 - accuracy: 0.9694 - val_loss: 3.1376 - val_accuracy: 0.5878\n",
      "Epoch 303/10000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.1161 - accuracy: 0.9724 - val_loss: 3.1796 - val_accuracy: 0.5827\n",
      "Epoch 304/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.1141 - accuracy: 0.9724 - val_loss: 3.1514 - val_accuracy: 0.5898\n",
      "Epoch 305/10000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.1152 - accuracy: 0.9721 - val_loss: 3.2080 - val_accuracy: 0.5939\n",
      "Epoch 306/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.1159 - accuracy: 0.9724 - val_loss: 3.2137 - val_accuracy: 0.5837\n",
      "Epoch 307/10000\n",
      "6/6 [==============================] - 0s 53ms/step - loss: 0.1108 - accuracy: 0.9735 - val_loss: 3.2072 - val_accuracy: 0.5908\n",
      "Epoch 308/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.1090 - accuracy: 0.9772 - val_loss: 3.2339 - val_accuracy: 0.5939\n",
      "Epoch 309/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.1098 - accuracy: 0.9769 - val_loss: 3.2589 - val_accuracy: 0.5918\n",
      "Epoch 310/10000\n",
      "6/6 [==============================] - 0s 54ms/step - loss: 0.1090 - accuracy: 0.9782 - val_loss: 3.2590 - val_accuracy: 0.5969\n",
      "Epoch 311/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.1071 - accuracy: 0.9762 - val_loss: 3.2943 - val_accuracy: 0.5918\n",
      "Epoch 312/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.1071 - accuracy: 0.9758 - val_loss: 3.3073 - val_accuracy: 0.5898\n",
      "Epoch 313/10000\n",
      "6/6 [==============================] - 0s 55ms/step - loss: 0.1079 - accuracy: 0.9762 - val_loss: 3.2914 - val_accuracy: 0.5918\n",
      "Epoch 314/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.1072 - accuracy: 0.9782 - val_loss: 3.3222 - val_accuracy: 0.5929\n",
      "Epoch 315/10000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.1078 - accuracy: 0.9741 - val_loss: 3.2984 - val_accuracy: 0.5888\n",
      "Epoch 316/10000\n",
      "6/6 [==============================] - 0s 53ms/step - loss: 0.1134 - accuracy: 0.9745 - val_loss: 3.2943 - val_accuracy: 0.5898\n",
      "Epoch 317/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.1137 - accuracy: 0.9735 - val_loss: 3.3134 - val_accuracy: 0.5908\n",
      "Epoch 318/10000\n",
      "6/6 [==============================] - 0s 53ms/step - loss: 0.1096 - accuracy: 0.9731 - val_loss: 3.3476 - val_accuracy: 0.5888\n",
      "Epoch 319/10000\n",
      "6/6 [==============================] - 0s 52ms/step - loss: 0.1091 - accuracy: 0.9748 - val_loss: 3.3599 - val_accuracy: 0.5918\n",
      "Epoch 320/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.1103 - accuracy: 0.9769 - val_loss: 3.3591 - val_accuracy: 0.5980\n",
      "Epoch 321/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.1082 - accuracy: 0.9741 - val_loss: 3.3923 - val_accuracy: 0.5949\n",
      "Epoch 322/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.1082 - accuracy: 0.9769 - val_loss: 3.3705 - val_accuracy: 0.5949\n",
      "Epoch 323/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.1037 - accuracy: 0.9765 - val_loss: 3.3861 - val_accuracy: 0.5939\n",
      "Epoch 324/10000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.1065 - accuracy: 0.9765 - val_loss: 3.4030 - val_accuracy: 0.5918\n",
      "Epoch 325/10000\n",
      "6/6 [==============================] - 0s 54ms/step - loss: 0.1030 - accuracy: 0.9765 - val_loss: 3.4347 - val_accuracy: 0.5939\n",
      "Epoch 326/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.0998 - accuracy: 0.9803 - val_loss: 3.4500 - val_accuracy: 0.5898\n",
      "Epoch 327/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.0972 - accuracy: 0.9806 - val_loss: 3.4365 - val_accuracy: 0.5908\n",
      "Epoch 328/10000\n",
      "6/6 [==============================] - 0s 52ms/step - loss: 0.1000 - accuracy: 0.9786 - val_loss: 3.4811 - val_accuracy: 0.5888\n",
      "Epoch 329/10000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.1029 - accuracy: 0.9748 - val_loss: 3.4956 - val_accuracy: 0.5939\n",
      "Epoch 330/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.1003 - accuracy: 0.9772 - val_loss: 3.5066 - val_accuracy: 0.5888\n",
      "Epoch 331/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0979 - accuracy: 0.9786 - val_loss: 3.4861 - val_accuracy: 0.5939\n",
      "Epoch 332/10000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.0927 - accuracy: 0.9813 - val_loss: 3.5114 - val_accuracy: 0.5939\n",
      "Epoch 333/10000\n",
      "6/6 [==============================] - 0s 80ms/step - loss: 0.0924 - accuracy: 0.9813 - val_loss: 3.5364 - val_accuracy: 0.5949\n",
      "Epoch 334/10000\n",
      "6/6 [==============================] - 0s 74ms/step - loss: 0.0907 - accuracy: 0.9806 - val_loss: 3.5237 - val_accuracy: 0.5949\n",
      "Epoch 335/10000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.0889 - accuracy: 0.9826 - val_loss: 3.5422 - val_accuracy: 0.5929\n",
      "Epoch 336/10000\n",
      "6/6 [==============================] - 0s 52ms/step - loss: 0.0883 - accuracy: 0.9813 - val_loss: 3.5454 - val_accuracy: 0.5929\n",
      "Epoch 337/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0918 - accuracy: 0.9796 - val_loss: 3.5506 - val_accuracy: 0.5929\n",
      "Epoch 338/10000\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.0877 - accuracy: 0.9816 - val_loss: 3.5772 - val_accuracy: 0.5959\n",
      "Epoch 339/10000\n",
      "6/6 [==============================] - 0s 56ms/step - loss: 0.0866 - accuracy: 0.9813 - val_loss: 3.5834 - val_accuracy: 0.5918\n",
      "Epoch 340/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0859 - accuracy: 0.9833 - val_loss: 3.5784 - val_accuracy: 0.5929\n",
      "Epoch 341/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.0851 - accuracy: 0.9823 - val_loss: 3.6148 - val_accuracy: 0.5908\n",
      "Epoch 342/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0834 - accuracy: 0.9847 - val_loss: 3.6043 - val_accuracy: 0.5929\n",
      "Epoch 343/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 47ms/step - loss: 0.0833 - accuracy: 0.9830 - val_loss: 3.6147 - val_accuracy: 0.5959\n",
      "Epoch 344/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0853 - accuracy: 0.9830 - val_loss: 3.6352 - val_accuracy: 0.5990\n",
      "Epoch 345/10000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.0842 - accuracy: 0.9840 - val_loss: 3.6378 - val_accuracy: 0.6000\n",
      "Epoch 346/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.0818 - accuracy: 0.9837 - val_loss: 3.6576 - val_accuracy: 0.5929\n",
      "Epoch 347/10000\n",
      "6/6 [==============================] - 0s 52ms/step - loss: 0.0816 - accuracy: 0.9816 - val_loss: 3.6955 - val_accuracy: 0.5939\n",
      "Epoch 348/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0821 - accuracy: 0.9806 - val_loss: 3.6917 - val_accuracy: 0.5969\n",
      "Epoch 349/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.0821 - accuracy: 0.9833 - val_loss: 3.6719 - val_accuracy: 0.5949\n",
      "Epoch 350/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.0822 - accuracy: 0.9816 - val_loss: 3.7037 - val_accuracy: 0.5969\n",
      "Epoch 351/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0856 - accuracy: 0.9830 - val_loss: 3.6864 - val_accuracy: 0.5878\n",
      "Epoch 352/10000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.0851 - accuracy: 0.9826 - val_loss: 3.6926 - val_accuracy: 0.5980\n",
      "Epoch 353/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.0871 - accuracy: 0.9806 - val_loss: 3.6982 - val_accuracy: 0.5949\n",
      "Epoch 354/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.0926 - accuracy: 0.9789 - val_loss: 3.6923 - val_accuracy: 0.5969\n",
      "Epoch 355/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.0908 - accuracy: 0.9789 - val_loss: 3.7001 - val_accuracy: 0.5939\n",
      "Epoch 356/10000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.0899 - accuracy: 0.9809 - val_loss: 3.7241 - val_accuracy: 0.5908\n",
      "Epoch 357/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0926 - accuracy: 0.9769 - val_loss: 3.7085 - val_accuracy: 0.5959\n",
      "Epoch 358/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.0860 - accuracy: 0.9813 - val_loss: 3.7486 - val_accuracy: 0.5888\n",
      "Epoch 359/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.0852 - accuracy: 0.9813 - val_loss: 3.7527 - val_accuracy: 0.5878\n",
      "Epoch 360/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.0868 - accuracy: 0.9789 - val_loss: 3.7681 - val_accuracy: 0.5980\n",
      "Epoch 361/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.0841 - accuracy: 0.9833 - val_loss: 3.8407 - val_accuracy: 0.5949\n",
      "Epoch 362/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.0853 - accuracy: 0.9803 - val_loss: 3.8684 - val_accuracy: 0.5878\n",
      "Epoch 363/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.0904 - accuracy: 0.9820 - val_loss: 3.8625 - val_accuracy: 0.5949\n",
      "Epoch 364/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.0895 - accuracy: 0.9758 - val_loss: 3.8416 - val_accuracy: 0.5918\n",
      "Epoch 365/10000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.0833 - accuracy: 0.9833 - val_loss: 3.8424 - val_accuracy: 0.5878\n",
      "Epoch 366/10000\n",
      "6/6 [==============================] - 0s 53ms/step - loss: 0.0798 - accuracy: 0.9830 - val_loss: 3.8324 - val_accuracy: 0.5908\n",
      "Epoch 367/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.0772 - accuracy: 0.9837 - val_loss: 3.8594 - val_accuracy: 0.5898\n",
      "Epoch 368/10000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.0773 - accuracy: 0.9833 - val_loss: 3.8572 - val_accuracy: 0.5949\n",
      "Epoch 369/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0760 - accuracy: 0.9850 - val_loss: 3.8703 - val_accuracy: 0.5929\n",
      "Epoch 370/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.0738 - accuracy: 0.9843 - val_loss: 3.8844 - val_accuracy: 0.5898\n",
      "Epoch 371/10000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.0723 - accuracy: 0.9850 - val_loss: 3.8756 - val_accuracy: 0.5929\n",
      "Epoch 372/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0730 - accuracy: 0.9857 - val_loss: 3.9333 - val_accuracy: 0.5908\n",
      "Epoch 373/10000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.0719 - accuracy: 0.9857 - val_loss: 3.9056 - val_accuracy: 0.5939\n",
      "Epoch 374/10000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.0713 - accuracy: 0.9860 - val_loss: 3.9042 - val_accuracy: 0.5929\n",
      "Epoch 375/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.0733 - accuracy: 0.9830 - val_loss: 3.9554 - val_accuracy: 0.5918\n",
      "Epoch 376/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.0748 - accuracy: 0.9871 - val_loss: 3.9636 - val_accuracy: 0.5949\n",
      "Epoch 377/10000\n",
      "6/6 [==============================] - 0s 55ms/step - loss: 0.0708 - accuracy: 0.9843 - val_loss: 3.9668 - val_accuracy: 0.5949\n",
      "Epoch 378/10000\n",
      "6/6 [==============================] - 0s 52ms/step - loss: 0.0725 - accuracy: 0.9864 - val_loss: 3.9865 - val_accuracy: 0.5980\n",
      "Epoch 379/10000\n",
      "6/6 [==============================] - 0s 56ms/step - loss: 0.0803 - accuracy: 0.9833 - val_loss: 3.9992 - val_accuracy: 0.5959\n",
      "Epoch 380/10000\n",
      "6/6 [==============================] - 0s 53ms/step - loss: 0.0772 - accuracy: 0.9823 - val_loss: 3.9957 - val_accuracy: 0.6010\n",
      "Epoch 381/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0747 - accuracy: 0.9830 - val_loss: 4.0360 - val_accuracy: 0.5959\n",
      "Epoch 382/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0711 - accuracy: 0.9843 - val_loss: 4.0234 - val_accuracy: 0.5949\n",
      "Epoch 383/10000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.0724 - accuracy: 0.9867 - val_loss: 4.0445 - val_accuracy: 0.5908\n",
      "Epoch 384/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.0706 - accuracy: 0.9854 - val_loss: 4.0543 - val_accuracy: 0.5878\n",
      "Epoch 385/10000\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.0685 - accuracy: 0.9871 - val_loss: 4.0803 - val_accuracy: 0.5949\n",
      "Epoch 386/10000\n",
      "6/6 [==============================] - 0s 52ms/step - loss: 0.0679 - accuracy: 0.9860 - val_loss: 4.0695 - val_accuracy: 0.5918\n",
      "Epoch 387/10000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.0691 - accuracy: 0.9857 - val_loss: 4.0587 - val_accuracy: 0.5969\n",
      "Epoch 388/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0712 - accuracy: 0.9840 - val_loss: 4.1290 - val_accuracy: 0.5980\n",
      "Epoch 389/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.0748 - accuracy: 0.9867 - val_loss: 4.0453 - val_accuracy: 0.5888\n",
      "Epoch 390/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0709 - accuracy: 0.9867 - val_loss: 4.1021 - val_accuracy: 0.5949\n",
      "Epoch 391/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.0670 - accuracy: 0.9860 - val_loss: 4.1571 - val_accuracy: 0.5929\n",
      "Epoch 392/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.0635 - accuracy: 0.9864 - val_loss: 4.1374 - val_accuracy: 0.5959\n",
      "Epoch 393/10000\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.0638 - accuracy: 0.9871 - val_loss: 4.1265 - val_accuracy: 0.6000\n",
      "Epoch 394/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.0615 - accuracy: 0.9874 - val_loss: 4.1599 - val_accuracy: 0.5918\n",
      "Epoch 395/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0619 - accuracy: 0.9891 - val_loss: 4.1824 - val_accuracy: 0.5959\n",
      "Epoch 396/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.0614 - accuracy: 0.9881 - val_loss: 4.1951 - val_accuracy: 0.5949\n",
      "Epoch 397/10000\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.0596 - accuracy: 0.9888 - val_loss: 4.1884 - val_accuracy: 0.5969\n",
      "Epoch 398/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.0586 - accuracy: 0.9894 - val_loss: 4.2235 - val_accuracy: 0.5939\n",
      "Epoch 399/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.0554 - accuracy: 0.9898 - val_loss: 4.2134 - val_accuracy: 0.5980\n",
      "Epoch 400/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 62ms/step - loss: 0.0564 - accuracy: 0.9894 - val_loss: 4.2673 - val_accuracy: 0.5939\n",
      "Epoch 401/10000\n",
      "6/6 [==============================] - 0s 57ms/step - loss: 0.0589 - accuracy: 0.9888 - val_loss: 4.3001 - val_accuracy: 0.5980\n",
      "Epoch 402/10000\n",
      "6/6 [==============================] - 0s 56ms/step - loss: 0.0586 - accuracy: 0.9894 - val_loss: 4.2624 - val_accuracy: 0.5918\n",
      "Epoch 403/10000\n",
      "6/6 [==============================] - 0s 81ms/step - loss: 0.0578 - accuracy: 0.9888 - val_loss: 4.2511 - val_accuracy: 0.5939\n",
      "Epoch 404/10000\n",
      "6/6 [==============================] - 0s 77ms/step - loss: 0.0590 - accuracy: 0.9884 - val_loss: 4.2776 - val_accuracy: 0.5929\n",
      "Epoch 405/10000\n",
      "6/6 [==============================] - 0s 55ms/step - loss: 0.0553 - accuracy: 0.9905 - val_loss: 4.2659 - val_accuracy: 0.5929\n",
      "Epoch 406/10000\n",
      "6/6 [==============================] - 0s 86ms/step - loss: 0.0557 - accuracy: 0.9894 - val_loss: 4.2932 - val_accuracy: 0.5939\n",
      "Epoch 407/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0539 - accuracy: 0.9905 - val_loss: 4.3141 - val_accuracy: 0.5969\n",
      "Epoch 408/10000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.0570 - accuracy: 0.9888 - val_loss: 4.3843 - val_accuracy: 0.5969\n",
      "Epoch 409/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.0598 - accuracy: 0.9877 - val_loss: 4.3959 - val_accuracy: 0.5969\n",
      "Epoch 410/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.0628 - accuracy: 0.9864 - val_loss: 4.3627 - val_accuracy: 0.5908\n",
      "Epoch 411/10000\n",
      "6/6 [==============================] - 0s 53ms/step - loss: 0.0624 - accuracy: 0.9867 - val_loss: 4.3512 - val_accuracy: 0.5969\n",
      "Epoch 412/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.0567 - accuracy: 0.9894 - val_loss: 4.3738 - val_accuracy: 0.5969\n",
      "Epoch 413/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.0585 - accuracy: 0.9877 - val_loss: 4.4122 - val_accuracy: 0.5939\n",
      "Epoch 414/10000\n",
      "6/6 [==============================] - 0s 78ms/step - loss: 0.0602 - accuracy: 0.9888 - val_loss: 4.3957 - val_accuracy: 0.5929\n",
      "Epoch 415/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0571 - accuracy: 0.9877 - val_loss: 4.4141 - val_accuracy: 0.5949\n",
      "Epoch 416/10000\n",
      "6/6 [==============================] - 0s 54ms/step - loss: 0.0558 - accuracy: 0.9898 - val_loss: 4.4164 - val_accuracy: 0.5918\n",
      "Epoch 417/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.0558 - accuracy: 0.9884 - val_loss: 4.3723 - val_accuracy: 0.5908\n",
      "Epoch 418/10000\n",
      "6/6 [==============================] - 0s 72ms/step - loss: 0.0535 - accuracy: 0.9881 - val_loss: 4.3828 - val_accuracy: 0.5959\n",
      "Epoch 419/10000\n",
      "6/6 [==============================] - 0s 91ms/step - loss: 0.0534 - accuracy: 0.9888 - val_loss: 4.3925 - val_accuracy: 0.5918\n",
      "Epoch 420/10000\n",
      "6/6 [==============================] - 0s 67ms/step - loss: 0.0519 - accuracy: 0.9905 - val_loss: 4.4113 - val_accuracy: 0.5959\n",
      "Epoch 421/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.0573 - accuracy: 0.9888 - val_loss: 4.4624 - val_accuracy: 0.5949\n",
      "Epoch 422/10000\n",
      "6/6 [==============================] - 0s 83ms/step - loss: 0.0550 - accuracy: 0.9888 - val_loss: 4.4539 - val_accuracy: 0.5980\n",
      "Epoch 423/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0568 - accuracy: 0.9888 - val_loss: 4.4323 - val_accuracy: 0.5888\n",
      "Epoch 424/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.0543 - accuracy: 0.9894 - val_loss: 4.4297 - val_accuracy: 0.5969\n",
      "Epoch 425/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.0515 - accuracy: 0.9898 - val_loss: 4.4384 - val_accuracy: 0.5908\n",
      "Epoch 426/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0502 - accuracy: 0.9905 - val_loss: 4.4883 - val_accuracy: 0.5959\n",
      "Epoch 427/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.0475 - accuracy: 0.9925 - val_loss: 4.5462 - val_accuracy: 0.5929\n",
      "Epoch 428/10000\n",
      "6/6 [==============================] - 0s 55ms/step - loss: 0.0483 - accuracy: 0.9905 - val_loss: 4.5251 - val_accuracy: 0.5939\n",
      "Epoch 429/10000\n",
      "6/6 [==============================] - 0s 54ms/step - loss: 0.0464 - accuracy: 0.9925 - val_loss: 4.5513 - val_accuracy: 0.5949\n",
      "Epoch 430/10000\n",
      "6/6 [==============================] - 0s 52ms/step - loss: 0.0475 - accuracy: 0.9912 - val_loss: 4.5553 - val_accuracy: 0.5898\n",
      "Epoch 431/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.0482 - accuracy: 0.9908 - val_loss: 4.5925 - val_accuracy: 0.5908\n",
      "Epoch 432/10000\n",
      "6/6 [==============================] - 0s 54ms/step - loss: 0.0471 - accuracy: 0.9912 - val_loss: 4.5355 - val_accuracy: 0.5939\n",
      "Epoch 433/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0447 - accuracy: 0.9915 - val_loss: 4.5881 - val_accuracy: 0.5918\n",
      "Epoch 434/10000\n",
      "6/6 [==============================] - 0s 56ms/step - loss: 0.0442 - accuracy: 0.9922 - val_loss: 4.5985 - val_accuracy: 0.5918\n",
      "Epoch 435/10000\n",
      "6/6 [==============================] - 0s 80ms/step - loss: 0.0433 - accuracy: 0.9922 - val_loss: 4.6022 - val_accuracy: 0.5969\n",
      "Epoch 436/10000\n",
      "6/6 [==============================] - 0s 55ms/step - loss: 0.0428 - accuracy: 0.9929 - val_loss: 4.6029 - val_accuracy: 0.5918\n",
      "Epoch 437/10000\n",
      "6/6 [==============================] - 0s 57ms/step - loss: 0.0426 - accuracy: 0.9922 - val_loss: 4.6203 - val_accuracy: 0.5918\n",
      "Epoch 438/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.0431 - accuracy: 0.9918 - val_loss: 4.6285 - val_accuracy: 0.5888\n",
      "Epoch 439/10000\n",
      "6/6 [==============================] - 0s 53ms/step - loss: 0.0453 - accuracy: 0.9908 - val_loss: 4.6580 - val_accuracy: 0.5939\n",
      "Epoch 440/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.0481 - accuracy: 0.9908 - val_loss: 4.6008 - val_accuracy: 0.5949\n",
      "Epoch 441/10000\n",
      "6/6 [==============================] - 0s 63ms/step - loss: 0.0504 - accuracy: 0.9901 - val_loss: 4.6680 - val_accuracy: 0.5949\n",
      "Epoch 442/10000\n",
      "6/6 [==============================] - 0s 52ms/step - loss: 0.0472 - accuracy: 0.9908 - val_loss: 4.6028 - val_accuracy: 0.5939\n",
      "Epoch 443/10000\n",
      "6/6 [==============================] - 0s 79ms/step - loss: 0.0478 - accuracy: 0.9915 - val_loss: 4.6868 - val_accuracy: 0.5918\n",
      "Epoch 444/10000\n",
      "6/6 [==============================] - 0s 78ms/step - loss: 0.0472 - accuracy: 0.9908 - val_loss: 4.6845 - val_accuracy: 0.5888\n",
      "Epoch 445/10000\n",
      "6/6 [==============================] - 0s 78ms/step - loss: 0.0471 - accuracy: 0.9908 - val_loss: 4.7205 - val_accuracy: 0.5939\n",
      "Epoch 446/10000\n",
      "6/6 [==============================] - 0s 80ms/step - loss: 0.0470 - accuracy: 0.9912 - val_loss: 4.7196 - val_accuracy: 0.5939\n",
      "Epoch 447/10000\n",
      "6/6 [==============================] - 0s 53ms/step - loss: 0.0451 - accuracy: 0.9918 - val_loss: 4.7237 - val_accuracy: 0.5990\n",
      "Epoch 448/10000\n",
      "6/6 [==============================] - 0s 58ms/step - loss: 0.0426 - accuracy: 0.9929 - val_loss: 4.7410 - val_accuracy: 0.5918\n",
      "Epoch 449/10000\n",
      "6/6 [==============================] - 0s 55ms/step - loss: 0.0422 - accuracy: 0.9929 - val_loss: 4.7618 - val_accuracy: 0.5949\n",
      "Epoch 450/10000\n",
      "6/6 [==============================] - 0s 56ms/step - loss: 0.0420 - accuracy: 0.9925 - val_loss: 4.7581 - val_accuracy: 0.5980\n",
      "Epoch 451/10000\n",
      "6/6 [==============================] - 0s 54ms/step - loss: 0.0415 - accuracy: 0.9922 - val_loss: 4.7817 - val_accuracy: 0.5959\n",
      "Epoch 452/10000\n",
      "6/6 [==============================] - 0s 53ms/step - loss: 0.0416 - accuracy: 0.9932 - val_loss: 4.7458 - val_accuracy: 0.5969\n",
      "Epoch 453/10000\n",
      "6/6 [==============================] - 0s 57ms/step - loss: 0.0424 - accuracy: 0.9922 - val_loss: 4.8074 - val_accuracy: 0.5929\n",
      "Epoch 454/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.0412 - accuracy: 0.9912 - val_loss: 4.7982 - val_accuracy: 0.6010\n",
      "Epoch 455/10000\n",
      "6/6 [==============================] - 0s 57ms/step - loss: 0.0432 - accuracy: 0.9915 - val_loss: 4.8475 - val_accuracy: 0.5929\n",
      "Epoch 456/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.0455 - accuracy: 0.9908 - val_loss: 4.8298 - val_accuracy: 0.5969\n",
      "Epoch 457/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0448 - accuracy: 0.9918 - val_loss: 4.8663 - val_accuracy: 0.5959\n",
      "Epoch 458/10000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.0456 - accuracy: 0.9915 - val_loss: 4.9075 - val_accuracy: 0.5969\n",
      "Epoch 459/10000\n",
      "6/6 [==============================] - 0s 55ms/step - loss: 0.0525 - accuracy: 0.9891 - val_loss: 4.8521 - val_accuracy: 0.5929\n",
      "Epoch 460/10000\n",
      "6/6 [==============================] - 0s 55ms/step - loss: 0.0477 - accuracy: 0.9912 - val_loss: 4.8502 - val_accuracy: 0.6020\n",
      "Epoch 461/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.0467 - accuracy: 0.9901 - val_loss: 4.8796 - val_accuracy: 0.5929\n",
      "Epoch 462/10000\n",
      "6/6 [==============================] - 0s 52ms/step - loss: 0.0409 - accuracy: 0.9942 - val_loss: 4.9165 - val_accuracy: 0.5959\n",
      "Epoch 463/10000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.0435 - accuracy: 0.9918 - val_loss: 4.9134 - val_accuracy: 0.5939\n",
      "Epoch 464/10000\n",
      "6/6 [==============================] - 0s 62ms/step - loss: 0.0380 - accuracy: 0.9929 - val_loss: 4.9217 - val_accuracy: 0.6000\n",
      "Epoch 465/10000\n",
      "6/6 [==============================] - 0s 58ms/step - loss: 0.0396 - accuracy: 0.9922 - val_loss: 4.9441 - val_accuracy: 0.5949\n",
      "Epoch 466/10000\n",
      "6/6 [==============================] - 0s 53ms/step - loss: 0.0375 - accuracy: 0.9939 - val_loss: 4.8783 - val_accuracy: 0.5969\n",
      "Epoch 467/10000\n",
      "6/6 [==============================] - 0s 65ms/step - loss: 0.0369 - accuracy: 0.9925 - val_loss: 4.9490 - val_accuracy: 0.5959\n",
      "Epoch 468/10000\n",
      "6/6 [==============================] - 0s 57ms/step - loss: 0.0356 - accuracy: 0.9935 - val_loss: 4.9603 - val_accuracy: 0.5969\n",
      "Epoch 469/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.0351 - accuracy: 0.9925 - val_loss: 4.9572 - val_accuracy: 0.5949\n",
      "Epoch 470/10000\n",
      "6/6 [==============================] - 0s 57ms/step - loss: 0.0348 - accuracy: 0.9932 - val_loss: 5.0297 - val_accuracy: 0.5949\n",
      "Epoch 471/10000\n",
      "6/6 [==============================] - 0s 62ms/step - loss: 0.0343 - accuracy: 0.9942 - val_loss: 5.0392 - val_accuracy: 0.5949\n",
      "Epoch 472/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.0351 - accuracy: 0.9925 - val_loss: 5.0259 - val_accuracy: 0.5959\n",
      "Epoch 473/10000\n",
      "6/6 [==============================] - 0s 60ms/step - loss: 0.0353 - accuracy: 0.9915 - val_loss: 5.0567 - val_accuracy: 0.5918\n",
      "Epoch 474/10000\n",
      "6/6 [==============================] - 0s 58ms/step - loss: 0.0354 - accuracy: 0.9939 - val_loss: 5.0799 - val_accuracy: 0.5939\n",
      "Epoch 475/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.0337 - accuracy: 0.9935 - val_loss: 5.0163 - val_accuracy: 0.5959\n",
      "Epoch 476/10000\n",
      "6/6 [==============================] - 0s 56ms/step - loss: 0.0335 - accuracy: 0.9935 - val_loss: 5.0343 - val_accuracy: 0.5980\n",
      "Epoch 477/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.0344 - accuracy: 0.9935 - val_loss: 5.0954 - val_accuracy: 0.5939\n",
      "Epoch 478/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.0331 - accuracy: 0.9946 - val_loss: 5.0318 - val_accuracy: 0.5959\n",
      "Epoch 479/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.0356 - accuracy: 0.9932 - val_loss: 5.0539 - val_accuracy: 0.5980\n",
      "Epoch 480/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.0494 - accuracy: 0.9908 - val_loss: 5.0311 - val_accuracy: 0.5908\n",
      "Epoch 481/10000\n",
      "6/6 [==============================] - 0s 56ms/step - loss: 0.0519 - accuracy: 0.9884 - val_loss: 5.0039 - val_accuracy: 0.5867\n",
      "Epoch 482/10000\n",
      "6/6 [==============================] - 0s 73ms/step - loss: 0.0660 - accuracy: 0.9837 - val_loss: 5.0843 - val_accuracy: 0.5827\n",
      "Epoch 483/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.0713 - accuracy: 0.9813 - val_loss: 5.0823 - val_accuracy: 0.5918\n",
      "Epoch 484/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.0634 - accuracy: 0.9816 - val_loss: 4.9946 - val_accuracy: 0.5908\n",
      "Epoch 485/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0701 - accuracy: 0.9789 - val_loss: 5.1018 - val_accuracy: 0.5929\n",
      "Epoch 486/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.0735 - accuracy: 0.9786 - val_loss: 5.0142 - val_accuracy: 0.5918\n",
      "Epoch 487/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0796 - accuracy: 0.9775 - val_loss: 5.1721 - val_accuracy: 0.5806\n",
      "Epoch 488/10000\n",
      "6/6 [==============================] - 0s 69ms/step - loss: 0.0994 - accuracy: 0.9687 - val_loss: 5.0211 - val_accuracy: 0.5806\n",
      "Epoch 489/10000\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.0789 - accuracy: 0.9762 - val_loss: 4.9739 - val_accuracy: 0.5857\n",
      "Epoch 490/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.0864 - accuracy: 0.9731 - val_loss: 5.0865 - val_accuracy: 0.5857\n",
      "Epoch 491/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.0698 - accuracy: 0.9803 - val_loss: 5.1050 - val_accuracy: 0.5888\n",
      "Epoch 492/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.0759 - accuracy: 0.9755 - val_loss: 5.1528 - val_accuracy: 0.5837\n",
      "Epoch 493/10000\n",
      "6/6 [==============================] - 0s 60ms/step - loss: 0.0762 - accuracy: 0.9779 - val_loss: 5.2123 - val_accuracy: 0.5857\n",
      "Epoch 494/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.0668 - accuracy: 0.9799 - val_loss: 5.2373 - val_accuracy: 0.5847\n",
      "Epoch 495/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0617 - accuracy: 0.9850 - val_loss: 5.1445 - val_accuracy: 0.5837\n",
      "Epoch 496/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0540 - accuracy: 0.9871 - val_loss: 5.0927 - val_accuracy: 0.5959\n",
      "Epoch 497/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0491 - accuracy: 0.9905 - val_loss: 5.1251 - val_accuracy: 0.5888\n",
      "Epoch 498/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.0474 - accuracy: 0.9877 - val_loss: 5.1041 - val_accuracy: 0.5990\n",
      "Epoch 499/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.0465 - accuracy: 0.9888 - val_loss: 5.0952 - val_accuracy: 0.5888\n",
      "Epoch 500/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.0445 - accuracy: 0.9912 - val_loss: 5.1238 - val_accuracy: 0.5929\n",
      "Epoch 501/10000\n",
      "6/6 [==============================] - 0s 57ms/step - loss: 0.0393 - accuracy: 0.9932 - val_loss: 5.2207 - val_accuracy: 0.5949\n",
      "Epoch 502/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.0351 - accuracy: 0.9949 - val_loss: 5.1722 - val_accuracy: 0.5990\n",
      "Epoch 503/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.0349 - accuracy: 0.9939 - val_loss: 5.1573 - val_accuracy: 0.6000\n",
      "Epoch 504/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.0332 - accuracy: 0.9932 - val_loss: 5.1775 - val_accuracy: 0.5959\n",
      "Epoch 505/10000\n",
      "6/6 [==============================] - 0s 52ms/step - loss: 0.0328 - accuracy: 0.9942 - val_loss: 5.2321 - val_accuracy: 0.5918\n",
      "Epoch 506/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0326 - accuracy: 0.9935 - val_loss: 5.2670 - val_accuracy: 0.5949\n",
      "Epoch 507/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.0323 - accuracy: 0.9939 - val_loss: 5.3442 - val_accuracy: 0.5908\n",
      "Epoch 508/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0398 - accuracy: 0.9925 - val_loss: 5.2821 - val_accuracy: 0.5969\n",
      "Epoch 509/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.0399 - accuracy: 0.9915 - val_loss: 5.2367 - val_accuracy: 0.5939\n",
      "Epoch 510/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.0353 - accuracy: 0.9925 - val_loss: 5.2133 - val_accuracy: 0.5949\n",
      "Epoch 511/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.0339 - accuracy: 0.9939 - val_loss: 5.2152 - val_accuracy: 0.5939\n",
      "Epoch 512/10000\n",
      "6/6 [==============================] - 0s 52ms/step - loss: 0.0329 - accuracy: 0.9939 - val_loss: 5.3016 - val_accuracy: 0.5918\n",
      "Epoch 513/10000\n",
      "6/6 [==============================] - 0s 70ms/step - loss: 0.0295 - accuracy: 0.9946 - val_loss: 5.3050 - val_accuracy: 0.5959\n",
      "Epoch 514/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 50ms/step - loss: 0.0285 - accuracy: 0.9946 - val_loss: 5.3216 - val_accuracy: 0.5939\n",
      "Epoch 515/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.0289 - accuracy: 0.9949 - val_loss: 5.2984 - val_accuracy: 0.6020\n",
      "Epoch 516/10000\n",
      "6/6 [==============================] - 0s 52ms/step - loss: 0.0300 - accuracy: 0.9935 - val_loss: 5.3174 - val_accuracy: 0.5949\n",
      "Epoch 517/10000\n",
      "6/6 [==============================] - 0s 52ms/step - loss: 0.0296 - accuracy: 0.9946 - val_loss: 5.3697 - val_accuracy: 0.5980\n",
      "Epoch 518/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.0276 - accuracy: 0.9946 - val_loss: 5.3823 - val_accuracy: 0.5908\n",
      "Epoch 519/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.0291 - accuracy: 0.9952 - val_loss: 5.3465 - val_accuracy: 0.5980\n",
      "Epoch 520/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.0268 - accuracy: 0.9956 - val_loss: 5.3838 - val_accuracy: 0.5939\n",
      "Epoch 521/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.0241 - accuracy: 0.9952 - val_loss: 5.3883 - val_accuracy: 0.5980\n",
      "Epoch 522/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.0243 - accuracy: 0.9946 - val_loss: 5.3674 - val_accuracy: 0.5949\n",
      "Epoch 523/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.0250 - accuracy: 0.9949 - val_loss: 5.4149 - val_accuracy: 0.5949\n",
      "Epoch 524/10000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.0238 - accuracy: 0.9956 - val_loss: 5.3926 - val_accuracy: 0.5990\n",
      "Epoch 525/10000\n",
      "6/6 [==============================] - 0s 65ms/step - loss: 0.0236 - accuracy: 0.9949 - val_loss: 5.4105 - val_accuracy: 0.6000\n",
      "Epoch 526/10000\n",
      "6/6 [==============================] - 0s 84ms/step - loss: 0.0246 - accuracy: 0.9942 - val_loss: 5.4304 - val_accuracy: 0.5939\n",
      "Epoch 527/10000\n",
      "6/6 [==============================] - 0s 67ms/step - loss: 0.0247 - accuracy: 0.9956 - val_loss: 5.4132 - val_accuracy: 0.5969\n",
      "Epoch 528/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0261 - accuracy: 0.9949 - val_loss: 5.4936 - val_accuracy: 0.5939\n",
      "Epoch 529/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.0252 - accuracy: 0.9952 - val_loss: 5.4556 - val_accuracy: 0.5939\n",
      "Epoch 530/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0248 - accuracy: 0.9956 - val_loss: 5.4363 - val_accuracy: 0.5949\n",
      "Epoch 531/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.0237 - accuracy: 0.9946 - val_loss: 5.4783 - val_accuracy: 0.5949\n",
      "Epoch 532/10000\n",
      "6/6 [==============================] - 0s 52ms/step - loss: 0.0252 - accuracy: 0.9946 - val_loss: 5.4683 - val_accuracy: 0.5949\n",
      "Epoch 533/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.0231 - accuracy: 0.9963 - val_loss: 5.4475 - val_accuracy: 0.5929\n",
      "Epoch 534/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.0259 - accuracy: 0.9949 - val_loss: 5.4490 - val_accuracy: 0.5969\n",
      "Epoch 535/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.0349 - accuracy: 0.9929 - val_loss: 5.4804 - val_accuracy: 0.5959\n",
      "Epoch 536/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0549 - accuracy: 0.9860 - val_loss: 5.3952 - val_accuracy: 0.5867\n",
      "Epoch 537/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.0630 - accuracy: 0.9826 - val_loss: 5.4638 - val_accuracy: 0.5837\n",
      "Epoch 538/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.1087 - accuracy: 0.9649 - val_loss: 5.5518 - val_accuracy: 0.5827\n",
      "Epoch 539/10000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.0809 - accuracy: 0.9741 - val_loss: 5.3632 - val_accuracy: 0.5959\n",
      "Epoch 540/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.0609 - accuracy: 0.9830 - val_loss: 5.4404 - val_accuracy: 0.5888\n",
      "Epoch 541/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.0585 - accuracy: 0.9847 - val_loss: 5.4331 - val_accuracy: 0.5949\n",
      "Epoch 542/10000\n",
      "6/6 [==============================] - 0s 55ms/step - loss: 0.0536 - accuracy: 0.9850 - val_loss: 5.3521 - val_accuracy: 0.5929\n",
      "Epoch 543/10000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.0440 - accuracy: 0.9881 - val_loss: 5.3907 - val_accuracy: 0.5837\n",
      "Epoch 544/10000\n",
      "6/6 [==============================] - 0s 63ms/step - loss: 0.0440 - accuracy: 0.9901 - val_loss: 5.3598 - val_accuracy: 0.5878\n",
      "Epoch 545/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.0322 - accuracy: 0.9929 - val_loss: 5.4913 - val_accuracy: 0.5918\n",
      "Epoch 546/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.0296 - accuracy: 0.9949 - val_loss: 5.5015 - val_accuracy: 0.5898\n",
      "Epoch 547/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0258 - accuracy: 0.9966 - val_loss: 5.4891 - val_accuracy: 0.5929\n",
      "Epoch 548/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.0248 - accuracy: 0.9956 - val_loss: 5.5464 - val_accuracy: 0.5990\n",
      "Epoch 549/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.0235 - accuracy: 0.9966 - val_loss: 5.5113 - val_accuracy: 0.5939\n",
      "Epoch 550/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.0221 - accuracy: 0.9959 - val_loss: 5.5534 - val_accuracy: 0.5929\n",
      "Epoch 551/10000\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.0225 - accuracy: 0.9946 - val_loss: 5.5664 - val_accuracy: 0.5959\n",
      "Epoch 552/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0241 - accuracy: 0.9956 - val_loss: 5.5513 - val_accuracy: 0.5980\n",
      "Epoch 553/10000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.0226 - accuracy: 0.9959 - val_loss: 5.5663 - val_accuracy: 0.5949\n",
      "Epoch 554/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0221 - accuracy: 0.9946 - val_loss: 5.5927 - val_accuracy: 0.5929\n",
      "Epoch 555/10000\n",
      "6/6 [==============================] - 0s 56ms/step - loss: 0.0249 - accuracy: 0.9949 - val_loss: 5.6127 - val_accuracy: 0.5918\n",
      "Epoch 556/10000\n",
      "6/6 [==============================] - 0s 60ms/step - loss: 0.0220 - accuracy: 0.9963 - val_loss: 5.5630 - val_accuracy: 0.5969\n",
      "Epoch 557/10000\n",
      "6/6 [==============================] - 0s 55ms/step - loss: 0.0238 - accuracy: 0.9949 - val_loss: 5.6577 - val_accuracy: 0.5959\n",
      "Epoch 558/10000\n",
      "6/6 [==============================] - 0s 59ms/step - loss: 0.0216 - accuracy: 0.9963 - val_loss: 5.5791 - val_accuracy: 0.5939\n",
      "Epoch 559/10000\n",
      "6/6 [==============================] - 0s 52ms/step - loss: 0.0209 - accuracy: 0.9966 - val_loss: 5.6015 - val_accuracy: 0.5980\n",
      "Epoch 560/10000\n",
      "6/6 [==============================] - 0s 55ms/step - loss: 0.0226 - accuracy: 0.9942 - val_loss: 5.6274 - val_accuracy: 0.5980\n",
      "Epoch 561/10000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.0203 - accuracy: 0.9959 - val_loss: 5.6313 - val_accuracy: 0.6000\n",
      "Epoch 562/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.0196 - accuracy: 0.9963 - val_loss: 5.6261 - val_accuracy: 0.5959\n",
      "Epoch 563/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.0197 - accuracy: 0.9963 - val_loss: 5.6738 - val_accuracy: 0.5929\n",
      "Epoch 564/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.0198 - accuracy: 0.9963 - val_loss: 5.6606 - val_accuracy: 0.5980\n",
      "Epoch 565/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.0197 - accuracy: 0.9969 - val_loss: 5.6922 - val_accuracy: 0.5959\n",
      "Epoch 566/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0231 - accuracy: 0.9956 - val_loss: 5.6285 - val_accuracy: 0.5929\n",
      "Epoch 567/10000\n",
      "6/6 [==============================] - 0s 65ms/step - loss: 0.0221 - accuracy: 0.9963 - val_loss: 5.7111 - val_accuracy: 0.5929\n",
      "Epoch 568/10000\n",
      "6/6 [==============================] - 0s 59ms/step - loss: 0.0202 - accuracy: 0.9956 - val_loss: 5.6935 - val_accuracy: 0.5939\n",
      "Epoch 569/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0202 - accuracy: 0.9959 - val_loss: 5.6871 - val_accuracy: 0.5980\n",
      "Epoch 570/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.0205 - accuracy: 0.9952 - val_loss: 5.7153 - val_accuracy: 0.5959\n",
      "Epoch 571/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 47ms/step - loss: 0.0197 - accuracy: 0.9956 - val_loss: 5.7020 - val_accuracy: 0.5929\n",
      "Epoch 572/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.0210 - accuracy: 0.9959 - val_loss: 5.7194 - val_accuracy: 0.5959\n",
      "Epoch 573/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.0215 - accuracy: 0.9963 - val_loss: 5.7395 - val_accuracy: 0.5929\n",
      "Epoch 574/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.0228 - accuracy: 0.9949 - val_loss: 5.7470 - val_accuracy: 0.5929\n",
      "Epoch 575/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0197 - accuracy: 0.9966 - val_loss: 5.7246 - val_accuracy: 0.5969\n",
      "Epoch 576/10000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.0195 - accuracy: 0.9959 - val_loss: 5.7421 - val_accuracy: 0.5959\n",
      "Epoch 577/10000\n",
      "6/6 [==============================] - 0s 53ms/step - loss: 0.0211 - accuracy: 0.9956 - val_loss: 5.7712 - val_accuracy: 0.5918\n",
      "Epoch 578/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0188 - accuracy: 0.9966 - val_loss: 5.7849 - val_accuracy: 0.5959\n",
      "Epoch 579/10000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.0190 - accuracy: 0.9952 - val_loss: 5.7517 - val_accuracy: 0.5939\n",
      "Epoch 580/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.0197 - accuracy: 0.9956 - val_loss: 5.8198 - val_accuracy: 0.5939\n",
      "Epoch 581/10000\n",
      "6/6 [==============================] - 0s 52ms/step - loss: 0.0216 - accuracy: 0.9963 - val_loss: 5.7636 - val_accuracy: 0.5918\n",
      "Epoch 582/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0222 - accuracy: 0.9963 - val_loss: 5.7377 - val_accuracy: 0.5918\n",
      "Epoch 583/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.0240 - accuracy: 0.9946 - val_loss: 5.7797 - val_accuracy: 0.5898\n",
      "Epoch 584/10000\n",
      "6/6 [==============================] - 0s 54ms/step - loss: 0.0187 - accuracy: 0.9966 - val_loss: 5.7506 - val_accuracy: 0.5918\n",
      "Epoch 585/10000\n",
      "6/6 [==============================] - 0s 58ms/step - loss: 0.0191 - accuracy: 0.9959 - val_loss: 5.7972 - val_accuracy: 0.5918\n",
      "Epoch 586/10000\n",
      "6/6 [==============================] - 0s 70ms/step - loss: 0.0178 - accuracy: 0.9963 - val_loss: 5.8246 - val_accuracy: 0.5929\n",
      "Epoch 587/10000\n",
      "6/6 [==============================] - 0s 77ms/step - loss: 0.0167 - accuracy: 0.9969 - val_loss: 5.8074 - val_accuracy: 0.5949\n",
      "Epoch 588/10000\n",
      "6/6 [==============================] - 0s 61ms/step - loss: 0.0182 - accuracy: 0.9959 - val_loss: 5.8648 - val_accuracy: 0.5949\n",
      "Epoch 589/10000\n",
      "6/6 [==============================] - 0s 81ms/step - loss: 0.0184 - accuracy: 0.9969 - val_loss: 5.8010 - val_accuracy: 0.5888\n",
      "Epoch 590/10000\n",
      "6/6 [==============================] - 0s 63ms/step - loss: 0.0190 - accuracy: 0.9956 - val_loss: 5.8160 - val_accuracy: 0.5929\n",
      "Epoch 591/10000\n",
      "6/6 [==============================] - 0s 53ms/step - loss: 0.0213 - accuracy: 0.9956 - val_loss: 5.8873 - val_accuracy: 0.5918\n",
      "Epoch 592/10000\n",
      "6/6 [==============================] - 0s 52ms/step - loss: 0.0214 - accuracy: 0.9959 - val_loss: 5.7829 - val_accuracy: 0.5969\n",
      "Epoch 593/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0210 - accuracy: 0.9956 - val_loss: 5.8580 - val_accuracy: 0.5939\n",
      "Epoch 594/10000\n",
      "6/6 [==============================] - 0s 59ms/step - loss: 0.0181 - accuracy: 0.9966 - val_loss: 5.8881 - val_accuracy: 0.5969\n",
      "Epoch 595/10000\n",
      "6/6 [==============================] - 0s 89ms/step - loss: 0.0193 - accuracy: 0.9969 - val_loss: 5.7959 - val_accuracy: 0.5980\n",
      "Epoch 596/10000\n",
      "6/6 [==============================] - 0s 89ms/step - loss: 0.0220 - accuracy: 0.9952 - val_loss: 5.8189 - val_accuracy: 0.5969\n",
      "Epoch 597/10000\n",
      "6/6 [==============================] - 0s 91ms/step - loss: 0.0195 - accuracy: 0.9963 - val_loss: 5.9251 - val_accuracy: 0.5918\n",
      "Epoch 598/10000\n",
      "6/6 [==============================] - 0s 55ms/step - loss: 0.0187 - accuracy: 0.9963 - val_loss: 5.8737 - val_accuracy: 0.5980\n",
      "Epoch 599/10000\n",
      "6/6 [==============================] - 0s 52ms/step - loss: 0.0179 - accuracy: 0.9963 - val_loss: 5.8925 - val_accuracy: 0.5959\n",
      "Epoch 600/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.0205 - accuracy: 0.9963 - val_loss: 5.9422 - val_accuracy: 0.5929\n",
      "Epoch 601/10000\n",
      "6/6 [==============================] - 0s 94ms/step - loss: 0.0200 - accuracy: 0.9973 - val_loss: 5.8759 - val_accuracy: 0.5929\n",
      "Epoch 602/10000\n",
      "6/6 [==============================] - 1s 102ms/step - loss: 0.0206 - accuracy: 0.9963 - val_loss: 5.9038 - val_accuracy: 0.5929\n",
      "Epoch 603/10000\n",
      "6/6 [==============================] - 1s 101ms/step - loss: 0.0208 - accuracy: 0.9952 - val_loss: 5.8848 - val_accuracy: 0.5959\n",
      "Epoch 604/10000\n",
      "6/6 [==============================] - 0s 68ms/step - loss: 0.0172 - accuracy: 0.9976 - val_loss: 5.9472 - val_accuracy: 0.5959\n",
      "Epoch 605/10000\n",
      "6/6 [==============================] - 0s 58ms/step - loss: 0.0231 - accuracy: 0.9946 - val_loss: 5.9378 - val_accuracy: 0.5969\n",
      "Epoch 606/10000\n",
      "6/6 [==============================] - 0s 53ms/step - loss: 0.0223 - accuracy: 0.9952 - val_loss: 5.9304 - val_accuracy: 0.5898\n",
      "Epoch 607/10000\n",
      "6/6 [==============================] - 0s 57ms/step - loss: 0.0260 - accuracy: 0.9959 - val_loss: 5.9289 - val_accuracy: 0.5908\n",
      "Epoch 608/10000\n",
      "6/6 [==============================] - 0s 52ms/step - loss: 0.0215 - accuracy: 0.9963 - val_loss: 5.8715 - val_accuracy: 0.5959\n",
      "Epoch 609/10000\n",
      "6/6 [==============================] - 0s 59ms/step - loss: 0.0225 - accuracy: 0.9959 - val_loss: 5.9557 - val_accuracy: 0.5918\n",
      "Epoch 610/10000\n",
      "6/6 [==============================] - 0s 81ms/step - loss: 0.0182 - accuracy: 0.9966 - val_loss: 5.9551 - val_accuracy: 0.5959\n",
      "Epoch 611/10000\n",
      "6/6 [==============================] - 0s 55ms/step - loss: 0.0178 - accuracy: 0.9966 - val_loss: 5.9204 - val_accuracy: 0.5980\n",
      "Epoch 612/10000\n",
      "6/6 [==============================] - 0s 54ms/step - loss: 0.0188 - accuracy: 0.9966 - val_loss: 5.9700 - val_accuracy: 0.5959\n",
      "Epoch 613/10000\n",
      "6/6 [==============================] - 0s 72ms/step - loss: 0.0172 - accuracy: 0.9963 - val_loss: 5.9481 - val_accuracy: 0.5929\n",
      "Epoch 614/10000\n",
      "6/6 [==============================] - 0s 58ms/step - loss: 0.0199 - accuracy: 0.9959 - val_loss: 5.9600 - val_accuracy: 0.5878\n",
      "Epoch 615/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.0185 - accuracy: 0.9963 - val_loss: 6.0520 - val_accuracy: 0.5949\n",
      "Epoch 616/10000\n",
      "6/6 [==============================] - 0s 52ms/step - loss: 0.0179 - accuracy: 0.9969 - val_loss: 5.9892 - val_accuracy: 0.5949\n",
      "Epoch 617/10000\n",
      "6/6 [==============================] - 0s 52ms/step - loss: 0.0159 - accuracy: 0.9969 - val_loss: 5.9977 - val_accuracy: 0.5918\n",
      "Epoch 618/10000\n",
      "6/6 [==============================] - 0s 56ms/step - loss: 0.0171 - accuracy: 0.9973 - val_loss: 6.0429 - val_accuracy: 0.5898\n",
      "Epoch 619/10000\n",
      "6/6 [==============================] - 0s 60ms/step - loss: 0.0168 - accuracy: 0.9966 - val_loss: 6.0585 - val_accuracy: 0.5969\n",
      "Epoch 620/10000\n",
      "6/6 [==============================] - 0s 58ms/step - loss: 0.0167 - accuracy: 0.9973 - val_loss: 5.9890 - val_accuracy: 0.5949\n",
      "Epoch 621/10000\n",
      "6/6 [==============================] - 0s 61ms/step - loss: 0.0234 - accuracy: 0.9956 - val_loss: 6.0685 - val_accuracy: 0.5918\n",
      "Epoch 622/10000\n",
      "6/6 [==============================] - 0s 53ms/step - loss: 0.0189 - accuracy: 0.9966 - val_loss: 6.0283 - val_accuracy: 0.5929\n",
      "Epoch 623/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0190 - accuracy: 0.9963 - val_loss: 5.9697 - val_accuracy: 0.5980\n",
      "Epoch 624/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.0197 - accuracy: 0.9980 - val_loss: 6.0831 - val_accuracy: 0.5949\n",
      "Epoch 625/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.0179 - accuracy: 0.9963 - val_loss: 6.1129 - val_accuracy: 0.5980\n",
      "Epoch 626/10000\n",
      "6/6 [==============================] - 0s 53ms/step - loss: 0.0191 - accuracy: 0.9963 - val_loss: 6.0113 - val_accuracy: 0.5949\n",
      "Epoch 627/10000\n",
      "6/6 [==============================] - 0s 58ms/step - loss: 0.0172 - accuracy: 0.9963 - val_loss: 6.0674 - val_accuracy: 0.5929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 628/10000\n",
      "6/6 [==============================] - 0s 64ms/step - loss: 0.0185 - accuracy: 0.9966 - val_loss: 6.0786 - val_accuracy: 0.5929\n",
      "Epoch 629/10000\n",
      "6/6 [==============================] - 0s 84ms/step - loss: 0.0192 - accuracy: 0.9959 - val_loss: 6.1194 - val_accuracy: 0.5898\n",
      "Epoch 630/10000\n",
      "6/6 [==============================] - 0s 89ms/step - loss: 0.0173 - accuracy: 0.9969 - val_loss: 6.0696 - val_accuracy: 0.5898\n",
      "Epoch 631/10000\n",
      "6/6 [==============================] - 0s 60ms/step - loss: 0.0207 - accuracy: 0.9956 - val_loss: 6.0152 - val_accuracy: 0.5969\n",
      "Epoch 632/10000\n",
      "6/6 [==============================] - 0s 84ms/step - loss: 0.0209 - accuracy: 0.9959 - val_loss: 6.0785 - val_accuracy: 0.5969\n",
      "Epoch 633/10000\n",
      "6/6 [==============================] - 0s 54ms/step - loss: 0.0191 - accuracy: 0.9963 - val_loss: 6.1293 - val_accuracy: 0.5929\n",
      "Epoch 634/10000\n",
      "6/6 [==============================] - 0s 94ms/step - loss: 0.0171 - accuracy: 0.9963 - val_loss: 6.0777 - val_accuracy: 0.5929\n",
      "Epoch 635/10000\n",
      "6/6 [==============================] - 0s 76ms/step - loss: 0.0191 - accuracy: 0.9969 - val_loss: 6.1064 - val_accuracy: 0.5929\n",
      "Epoch 636/10000\n",
      "6/6 [==============================] - 0s 80ms/step - loss: 0.0186 - accuracy: 0.9963 - val_loss: 6.1408 - val_accuracy: 0.5990\n",
      "Epoch 637/10000\n",
      "6/6 [==============================] - 0s 64ms/step - loss: 0.0194 - accuracy: 0.9959 - val_loss: 6.1525 - val_accuracy: 0.5939\n",
      "Epoch 638/10000\n",
      "6/6 [==============================] - 0s 61ms/step - loss: 0.0179 - accuracy: 0.9976 - val_loss: 6.1757 - val_accuracy: 0.5939\n",
      "Epoch 639/10000\n",
      "6/6 [==============================] - 0s 53ms/step - loss: 0.0193 - accuracy: 0.9973 - val_loss: 6.1068 - val_accuracy: 0.5939\n",
      "Epoch 640/10000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.0209 - accuracy: 0.9956 - val_loss: 6.1408 - val_accuracy: 0.5949\n",
      "Epoch 641/10000\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 0.0203 - accuracy: 0.9952 - val_loss: 6.0559 - val_accuracy: 0.5929\n",
      "Epoch 642/10000\n",
      "6/6 [==============================] - 0s 62ms/step - loss: 0.0325 - accuracy: 0.9942 - val_loss: 6.1397 - val_accuracy: 0.5949\n",
      "Epoch 643/10000\n",
      "6/6 [==============================] - 0s 64ms/step - loss: 0.0367 - accuracy: 0.9905 - val_loss: 6.1452 - val_accuracy: 0.6031\n",
      "Epoch 644/10000\n",
      "6/6 [==============================] - 0s 53ms/step - loss: 0.0491 - accuracy: 0.9847 - val_loss: 6.1611 - val_accuracy: 0.5806\n",
      "Epoch 645/10000\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.0450 - accuracy: 0.9898 - val_loss: 6.1178 - val_accuracy: 0.5949\n",
      "Epoch 646/10000\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 0.0489 - accuracy: 0.9854 - val_loss: 6.1446 - val_accuracy: 0.5827\n",
      "Epoch 647/10000\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.0667 - accuracy: 0.9813 - val_loss: 6.0026 - val_accuracy: 0.5929\n",
      "Epoch 648/10000\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 0.1183 - accuracy: 0.9609 - val_loss: 6.2842 - val_accuracy: 0.5867\n",
      "Epoch 649/10000\n",
      "6/6 [==============================] - 0s 75ms/step - loss: 0.1165 - accuracy: 0.9636 - val_loss: 6.2312 - val_accuracy: 0.5653\n",
      "Epoch 650/10000\n",
      "6/6 [==============================] - 0s 74ms/step - loss: 0.0885 - accuracy: 0.9707 - val_loss: 6.2810 - val_accuracy: 0.5929\n",
      "Epoch 651/10000\n",
      "6/6 [==============================] - 0s 91ms/step - loss: 0.0767 - accuracy: 0.9758 - val_loss: 6.0639 - val_accuracy: 0.5888\n",
      "Epoch 652/10000\n",
      "6/6 [==============================] - 1s 95ms/step - loss: 0.0810 - accuracy: 0.9735 - val_loss: 6.1465 - val_accuracy: 0.5929\n",
      "Epoch 653/10000\n",
      "6/6 [==============================] - 0s 76ms/step - loss: 0.0929 - accuracy: 0.9639 - val_loss: 5.9334 - val_accuracy: 0.5745\n",
      "Epoch 654/10000\n",
      "6/6 [==============================] - 0s 74ms/step - loss: 0.0774 - accuracy: 0.9704 - val_loss: 5.9732 - val_accuracy: 0.5878\n",
      "Epoch 655/10000\n",
      "6/6 [==============================] - 1s 98ms/step - loss: 0.0648 - accuracy: 0.9809 - val_loss: 5.9395 - val_accuracy: 0.5908\n",
      "Epoch 656/10000\n",
      "6/6 [==============================] - 1s 100ms/step - loss: 0.0416 - accuracy: 0.9884 - val_loss: 6.0177 - val_accuracy: 0.5816\n",
      "Epoch 657/10000\n",
      "6/6 [==============================] - 1s 108ms/step - loss: 0.0400 - accuracy: 0.9867 - val_loss: 6.1407 - val_accuracy: 0.5959\n",
      "Epoch 658/10000\n",
      "6/6 [==============================] - 0s 87ms/step - loss: 0.0306 - accuracy: 0.9949 - val_loss: 5.9930 - val_accuracy: 0.5918\n",
      "Epoch 659/10000\n",
      "6/6 [==============================] - 0s 85ms/step - loss: 0.0312 - accuracy: 0.9925 - val_loss: 6.0210 - val_accuracy: 0.5929\n",
      "Epoch 660/10000\n",
      "6/6 [==============================] - 0s 75ms/step - loss: 0.0286 - accuracy: 0.9935 - val_loss: 6.0726 - val_accuracy: 0.6010\n",
      "Epoch 661/10000\n",
      "6/6 [==============================] - 0s 55ms/step - loss: 0.0278 - accuracy: 0.9949 - val_loss: 6.1440 - val_accuracy: 0.5888\n",
      "Epoch 662/10000\n",
      "6/6 [==============================] - 0s 58ms/step - loss: 0.0240 - accuracy: 0.9956 - val_loss: 6.0968 - val_accuracy: 0.5888\n",
      "Epoch 663/10000\n",
      "6/6 [==============================] - 0s 77ms/step - loss: 0.0222 - accuracy: 0.9959 - val_loss: 6.1178 - val_accuracy: 0.5908\n",
      "Epoch 664/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.0209 - accuracy: 0.9963 - val_loss: 6.1636 - val_accuracy: 0.5898\n",
      "Epoch 665/10000\n",
      "6/6 [==============================] - 0s 58ms/step - loss: 0.0193 - accuracy: 0.9963 - val_loss: 6.1225 - val_accuracy: 0.5980\n",
      "Epoch 666/10000\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 0.0182 - accuracy: 0.9976 - val_loss: 6.1271 - val_accuracy: 0.5949\n",
      "Epoch 667/10000\n",
      "6/6 [==============================] - 0s 70ms/step - loss: 0.0183 - accuracy: 0.9973 - val_loss: 6.1392 - val_accuracy: 0.5949\n",
      "Epoch 668/10000\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.0173 - accuracy: 0.9966 - val_loss: 6.1772 - val_accuracy: 0.5969\n",
      "Epoch 669/10000\n",
      "6/6 [==============================] - 0s 70ms/step - loss: 0.0159 - accuracy: 0.9973 - val_loss: 6.1914 - val_accuracy: 0.5949\n",
      "Epoch 670/10000\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 0.0172 - accuracy: 0.9963 - val_loss: 6.1401 - val_accuracy: 0.5949\n",
      "Epoch 671/10000\n",
      "6/6 [==============================] - 0s 73ms/step - loss: 0.0152 - accuracy: 0.9973 - val_loss: 6.2369 - val_accuracy: 0.5918\n",
      "Epoch 672/10000\n",
      "6/6 [==============================] - 0s 67ms/step - loss: 0.0154 - accuracy: 0.9976 - val_loss: 6.1597 - val_accuracy: 0.5939\n",
      "Epoch 673/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0167 - accuracy: 0.9966 - val_loss: 6.1845 - val_accuracy: 0.5990\n",
      "Epoch 674/10000\n",
      "6/6 [==============================] - 0s 63ms/step - loss: 0.0158 - accuracy: 0.9969 - val_loss: 6.2219 - val_accuracy: 0.5949\n",
      "Epoch 675/10000\n",
      "6/6 [==============================] - 0s 71ms/step - loss: 0.0179 - accuracy: 0.9969 - val_loss: 6.1733 - val_accuracy: 0.5929\n",
      "Epoch 676/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.0177 - accuracy: 0.9966 - val_loss: 6.2222 - val_accuracy: 0.5929\n",
      "Epoch 677/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.0146 - accuracy: 0.9973 - val_loss: 6.1750 - val_accuracy: 0.5929\n",
      "Epoch 678/10000\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 0.0153 - accuracy: 0.9973 - val_loss: 6.2296 - val_accuracy: 0.5959\n",
      "Epoch 679/10000\n",
      "6/6 [==============================] - 1s 99ms/step - loss: 0.0143 - accuracy: 0.9973 - val_loss: 6.2283 - val_accuracy: 0.5939\n",
      "Epoch 680/10000\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 0.0123 - accuracy: 0.9986 - val_loss: 6.2438 - val_accuracy: 0.5929\n",
      "Epoch 681/10000\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.0125 - accuracy: 0.9983 - val_loss: 6.2646 - val_accuracy: 0.5949\n",
      "Epoch 682/10000\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.0148 - accuracy: 0.9966 - val_loss: 6.2672 - val_accuracy: 0.5929\n",
      "Epoch 683/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.0145 - accuracy: 0.9976 - val_loss: 6.3132 - val_accuracy: 0.5929\n",
      "Epoch 684/10000\n",
      "6/6 [==============================] - 0s 53ms/step - loss: 0.0149 - accuracy: 0.9969 - val_loss: 6.2214 - val_accuracy: 0.5949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 685/10000\n",
      "6/6 [==============================] - 0s 67ms/step - loss: 0.0182 - accuracy: 0.9959 - val_loss: 6.3296 - val_accuracy: 0.5949\n",
      "Epoch 686/10000\n",
      "6/6 [==============================] - 0s 73ms/step - loss: 0.0144 - accuracy: 0.9976 - val_loss: 6.2318 - val_accuracy: 0.5969\n",
      "Epoch 687/10000\n",
      "6/6 [==============================] - 0s 74ms/step - loss: 0.0141 - accuracy: 0.9976 - val_loss: 6.2687 - val_accuracy: 0.5959\n",
      "Epoch 688/10000\n",
      "6/6 [==============================] - 0s 60ms/step - loss: 0.0138 - accuracy: 0.9983 - val_loss: 6.3293 - val_accuracy: 0.5939\n",
      "Epoch 689/10000\n",
      "6/6 [==============================] - 0s 53ms/step - loss: 0.0142 - accuracy: 0.9976 - val_loss: 6.2018 - val_accuracy: 0.5878\n",
      "Epoch 690/10000\n",
      "6/6 [==============================] - 0s 82ms/step - loss: 0.0186 - accuracy: 0.9969 - val_loss: 6.3459 - val_accuracy: 0.5949\n",
      "Epoch 691/10000\n",
      "6/6 [==============================] - 0s 66ms/step - loss: 0.0162 - accuracy: 0.9976 - val_loss: 6.2805 - val_accuracy: 0.5969\n",
      "Epoch 692/10000\n",
      "6/6 [==============================] - 0s 71ms/step - loss: 0.0146 - accuracy: 0.9973 - val_loss: 6.2704 - val_accuracy: 0.5949\n",
      "Epoch 693/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.0140 - accuracy: 0.9976 - val_loss: 6.4091 - val_accuracy: 0.5898\n",
      "Epoch 694/10000\n",
      "6/6 [==============================] - 0s 61ms/step - loss: 0.0161 - accuracy: 0.9963 - val_loss: 6.2582 - val_accuracy: 0.5949\n",
      "Epoch 695/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.0153 - accuracy: 0.9973 - val_loss: 6.3465 - val_accuracy: 0.5969\n",
      "Epoch 696/10000\n",
      "6/6 [==============================] - 0s 58ms/step - loss: 0.0130 - accuracy: 0.9969 - val_loss: 6.3241 - val_accuracy: 0.5918\n",
      "Epoch 697/10000\n",
      "6/6 [==============================] - 0s 60ms/step - loss: 0.0134 - accuracy: 0.9973 - val_loss: 6.3278 - val_accuracy: 0.5959\n",
      "Epoch 698/10000\n",
      "6/6 [==============================] - 0s 61ms/step - loss: 0.0129 - accuracy: 0.9969 - val_loss: 6.3317 - val_accuracy: 0.5969\n",
      "Epoch 699/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.0131 - accuracy: 0.9980 - val_loss: 6.3041 - val_accuracy: 0.5949\n",
      "Epoch 700/10000\n",
      "6/6 [==============================] - 0s 53ms/step - loss: 0.0149 - accuracy: 0.9976 - val_loss: 6.4130 - val_accuracy: 0.5929\n",
      "Epoch 701/10000\n",
      "6/6 [==============================] - 0s 65ms/step - loss: 0.0150 - accuracy: 0.9973 - val_loss: 6.2856 - val_accuracy: 0.5929\n",
      "Epoch 702/10000\n",
      "6/6 [==============================] - 0s 59ms/step - loss: 0.0157 - accuracy: 0.9973 - val_loss: 6.3441 - val_accuracy: 0.5929\n",
      "Epoch 703/10000\n",
      "6/6 [==============================] - 0s 87ms/step - loss: 0.0176 - accuracy: 0.9973 - val_loss: 6.4176 - val_accuracy: 0.5949\n",
      "Epoch 704/10000\n",
      "6/6 [==============================] - 0s 53ms/step - loss: 0.0180 - accuracy: 0.9966 - val_loss: 6.2718 - val_accuracy: 0.5908\n",
      "Epoch 705/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.0155 - accuracy: 0.9973 - val_loss: 6.4048 - val_accuracy: 0.5888\n",
      "Epoch 706/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.0128 - accuracy: 0.9966 - val_loss: 6.3843 - val_accuracy: 0.5959\n",
      "Epoch 707/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.0122 - accuracy: 0.9980 - val_loss: 6.4006 - val_accuracy: 0.5898\n",
      "Epoch 708/10000\n",
      "6/6 [==============================] - 0s 53ms/step - loss: 0.0121 - accuracy: 0.9980 - val_loss: 6.3592 - val_accuracy: 0.5990\n",
      "Epoch 709/10000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.0136 - accuracy: 0.9973 - val_loss: 6.4155 - val_accuracy: 0.5939\n",
      "Epoch 710/10000\n",
      "6/6 [==============================] - 0s 83ms/step - loss: 0.0118 - accuracy: 0.9973 - val_loss: 6.4017 - val_accuracy: 0.5959\n",
      "Epoch 711/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.0136 - accuracy: 0.9966 - val_loss: 6.4411 - val_accuracy: 0.5949\n",
      "Epoch 712/10000\n",
      "6/6 [==============================] - 0s 53ms/step - loss: 0.0148 - accuracy: 0.9963 - val_loss: 6.3601 - val_accuracy: 0.5959\n",
      "Epoch 713/10000\n",
      "6/6 [==============================] - 0s 55ms/step - loss: 0.0129 - accuracy: 0.9973 - val_loss: 6.4619 - val_accuracy: 0.5908\n",
      "Epoch 714/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.0124 - accuracy: 0.9976 - val_loss: 6.3643 - val_accuracy: 0.5939\n",
      "Epoch 715/10000\n",
      "6/6 [==============================] - 0s 53ms/step - loss: 0.0150 - accuracy: 0.9973 - val_loss: 6.4943 - val_accuracy: 0.5939\n",
      "Epoch 716/10000\n",
      "6/6 [==============================] - 0s 59ms/step - loss: 0.0152 - accuracy: 0.9973 - val_loss: 6.4122 - val_accuracy: 0.5990\n",
      "Epoch 717/10000\n",
      "6/6 [==============================] - 0s 58ms/step - loss: 0.0135 - accuracy: 0.9973 - val_loss: 6.4687 - val_accuracy: 0.5959\n",
      "Epoch 718/10000\n",
      "6/6 [==============================] - 0s 59ms/step - loss: 0.0142 - accuracy: 0.9976 - val_loss: 6.4621 - val_accuracy: 0.5929\n",
      "Epoch 719/10000\n",
      "6/6 [==============================] - 0s 55ms/step - loss: 0.0147 - accuracy: 0.9969 - val_loss: 6.3717 - val_accuracy: 0.5949\n",
      "Epoch 720/10000\n",
      "6/6 [==============================] - 0s 52ms/step - loss: 0.0143 - accuracy: 0.9976 - val_loss: 6.4523 - val_accuracy: 0.5959\n",
      "Epoch 721/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.0126 - accuracy: 0.9980 - val_loss: 6.4598 - val_accuracy: 0.5949\n",
      "Epoch 722/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.0139 - accuracy: 0.9976 - val_loss: 6.4452 - val_accuracy: 0.5949\n",
      "Epoch 723/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.0134 - accuracy: 0.9973 - val_loss: 6.5246 - val_accuracy: 0.5980\n",
      "Epoch 724/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.0151 - accuracy: 0.9969 - val_loss: 6.4472 - val_accuracy: 0.6000\n",
      "Epoch 725/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.0151 - accuracy: 0.9963 - val_loss: 6.4915 - val_accuracy: 0.5939\n",
      "Epoch 726/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.0162 - accuracy: 0.9959 - val_loss: 6.4600 - val_accuracy: 0.5949\n",
      "Epoch 727/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.0130 - accuracy: 0.9980 - val_loss: 6.4580 - val_accuracy: 0.5939\n",
      "Epoch 728/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0171 - accuracy: 0.9973 - val_loss: 6.5311 - val_accuracy: 0.5888\n",
      "Epoch 729/10000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.0182 - accuracy: 0.9959 - val_loss: 6.5078 - val_accuracy: 0.5918\n",
      "Epoch 730/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.0170 - accuracy: 0.9966 - val_loss: 6.5196 - val_accuracy: 0.5949\n",
      "Epoch 731/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.0183 - accuracy: 0.9963 - val_loss: 6.4563 - val_accuracy: 0.5949\n",
      "Epoch 732/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0189 - accuracy: 0.9956 - val_loss: 6.5374 - val_accuracy: 0.5918\n",
      "Epoch 733/10000\n",
      "6/6 [==============================] - 0s 71ms/step - loss: 0.0197 - accuracy: 0.9973 - val_loss: 6.5185 - val_accuracy: 0.5878\n",
      "Epoch 734/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.0199 - accuracy: 0.9963 - val_loss: 6.4893 - val_accuracy: 0.5898\n",
      "Epoch 735/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.0171 - accuracy: 0.9963 - val_loss: 6.4516 - val_accuracy: 0.5888\n",
      "Epoch 736/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.0159 - accuracy: 0.9969 - val_loss: 6.6244 - val_accuracy: 0.5918\n",
      "Epoch 737/10000\n",
      "6/6 [==============================] - 0s 53ms/step - loss: 0.0164 - accuracy: 0.9973 - val_loss: 6.4983 - val_accuracy: 0.5929\n",
      "Epoch 738/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.0161 - accuracy: 0.9973 - val_loss: 6.4883 - val_accuracy: 0.5929\n",
      "Epoch 739/10000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.0244 - accuracy: 0.9956 - val_loss: 6.6781 - val_accuracy: 0.5878\n",
      "Epoch 740/10000\n",
      "6/6 [==============================] - 0s 52ms/step - loss: 0.0221 - accuracy: 0.9952 - val_loss: 6.6730 - val_accuracy: 0.5878\n",
      "Epoch 741/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0235 - accuracy: 0.9956 - val_loss: 6.5487 - val_accuracy: 0.5918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 742/10000\n",
      "6/6 [==============================] - 0s 53ms/step - loss: 0.0154 - accuracy: 0.9976 - val_loss: 6.4385 - val_accuracy: 0.5867\n",
      "Epoch 743/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0153 - accuracy: 0.9973 - val_loss: 6.5367 - val_accuracy: 0.5949\n",
      "Epoch 744/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.0149 - accuracy: 0.9973 - val_loss: 6.4887 - val_accuracy: 0.5939\n",
      "Epoch 745/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0137 - accuracy: 0.9966 - val_loss: 6.5214 - val_accuracy: 0.5888\n",
      "Epoch 746/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.0156 - accuracy: 0.9963 - val_loss: 6.6450 - val_accuracy: 0.5908\n",
      "Epoch 747/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.0145 - accuracy: 0.9980 - val_loss: 6.5177 - val_accuracy: 0.5929\n",
      "Epoch 748/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.0177 - accuracy: 0.9952 - val_loss: 6.5726 - val_accuracy: 0.5898\n",
      "Epoch 749/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.0156 - accuracy: 0.9983 - val_loss: 6.6062 - val_accuracy: 0.5969\n",
      "Epoch 750/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0149 - accuracy: 0.9966 - val_loss: 6.6092 - val_accuracy: 0.5857\n",
      "Epoch 751/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.0168 - accuracy: 0.9969 - val_loss: 6.5358 - val_accuracy: 0.5969\n",
      "Epoch 752/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.0126 - accuracy: 0.9976 - val_loss: 6.4819 - val_accuracy: 0.5980\n",
      "Epoch 753/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0130 - accuracy: 0.9976 - val_loss: 6.6025 - val_accuracy: 0.5888\n",
      "Epoch 754/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.0138 - accuracy: 0.9973 - val_loss: 6.5471 - val_accuracy: 0.5908\n",
      "Epoch 755/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.0151 - accuracy: 0.9969 - val_loss: 6.6123 - val_accuracy: 0.5959\n",
      "Epoch 756/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.0164 - accuracy: 0.9966 - val_loss: 6.7230 - val_accuracy: 0.5898\n",
      "Epoch 757/10000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.0186 - accuracy: 0.9976 - val_loss: 6.5461 - val_accuracy: 0.5939\n",
      "Epoch 758/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.0136 - accuracy: 0.9980 - val_loss: 6.6269 - val_accuracy: 0.5867\n",
      "Epoch 759/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0129 - accuracy: 0.9973 - val_loss: 6.6381 - val_accuracy: 0.6010\n",
      "Epoch 760/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.0133 - accuracy: 0.9976 - val_loss: 6.6872 - val_accuracy: 0.5969\n",
      "Epoch 761/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0121 - accuracy: 0.9980 - val_loss: 6.5924 - val_accuracy: 0.5888\n",
      "Epoch 762/10000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.0114 - accuracy: 0.9983 - val_loss: 6.6203 - val_accuracy: 0.5980\n",
      "Epoch 763/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.0111 - accuracy: 0.9980 - val_loss: 6.6691 - val_accuracy: 0.5990\n",
      "Epoch 764/10000\n",
      "6/6 [==============================] - 0s 53ms/step - loss: 0.0106 - accuracy: 0.9969 - val_loss: 6.6915 - val_accuracy: 0.5888\n",
      "Epoch 765/10000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.0105 - accuracy: 0.9973 - val_loss: 6.6600 - val_accuracy: 0.5990\n",
      "Epoch 766/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.0106 - accuracy: 0.9973 - val_loss: 6.6807 - val_accuracy: 0.5959\n",
      "Epoch 767/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.0103 - accuracy: 0.9973 - val_loss: 6.6951 - val_accuracy: 0.5898\n",
      "Epoch 768/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.0111 - accuracy: 0.9976 - val_loss: 6.7153 - val_accuracy: 0.5959\n",
      "Epoch 769/10000\n",
      "6/6 [==============================] - 0s 52ms/step - loss: 0.0100 - accuracy: 0.9973 - val_loss: 6.7027 - val_accuracy: 0.5929\n",
      "Epoch 770/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.0127 - accuracy: 0.9980 - val_loss: 6.7491 - val_accuracy: 0.5939\n",
      "Epoch 771/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.0106 - accuracy: 0.9976 - val_loss: 6.7147 - val_accuracy: 0.5969\n",
      "Epoch 772/10000\n",
      "6/6 [==============================] - 0s 53ms/step - loss: 0.0104 - accuracy: 0.9980 - val_loss: 6.6973 - val_accuracy: 0.5939\n",
      "Epoch 773/10000\n",
      "6/6 [==============================] - 0s 56ms/step - loss: 0.0114 - accuracy: 0.9976 - val_loss: 6.7162 - val_accuracy: 0.5918\n",
      "Epoch 774/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.0104 - accuracy: 0.9980 - val_loss: 6.7387 - val_accuracy: 0.5949\n",
      "Epoch 775/10000\n",
      "6/6 [==============================] - 0s 55ms/step - loss: 0.0124 - accuracy: 0.9980 - val_loss: 6.6995 - val_accuracy: 0.5918\n",
      "Epoch 776/10000\n",
      "6/6 [==============================] - 0s 52ms/step - loss: 0.0111 - accuracy: 0.9980 - val_loss: 6.7865 - val_accuracy: 0.5990\n",
      "Epoch 777/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.0118 - accuracy: 0.9973 - val_loss: 6.7389 - val_accuracy: 0.6010\n",
      "Epoch 778/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.0094 - accuracy: 0.9986 - val_loss: 6.7608 - val_accuracy: 0.5929\n",
      "Epoch 779/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.0106 - accuracy: 0.9980 - val_loss: 6.7626 - val_accuracy: 0.5990\n",
      "Epoch 780/10000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.0101 - accuracy: 0.9986 - val_loss: 6.7538 - val_accuracy: 0.5908\n",
      "Epoch 781/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.0117 - accuracy: 0.9976 - val_loss: 6.7977 - val_accuracy: 0.5908\n",
      "Epoch 782/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.0132 - accuracy: 0.9973 - val_loss: 6.8542 - val_accuracy: 0.5918\n",
      "Epoch 783/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0119 - accuracy: 0.9976 - val_loss: 6.7249 - val_accuracy: 0.5939\n",
      "Epoch 784/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.0129 - accuracy: 0.9969 - val_loss: 6.7770 - val_accuracy: 0.5878\n",
      "Epoch 785/10000\n",
      "6/6 [==============================] - 0s 53ms/step - loss: 0.0159 - accuracy: 0.9963 - val_loss: 6.8749 - val_accuracy: 0.5959\n",
      "Epoch 786/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0136 - accuracy: 0.9969 - val_loss: 6.7056 - val_accuracy: 0.5959\n",
      "Epoch 787/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.0118 - accuracy: 0.9976 - val_loss: 6.7647 - val_accuracy: 0.5929\n",
      "Epoch 788/10000\n",
      "6/6 [==============================] - 0s 53ms/step - loss: 0.0085 - accuracy: 0.9986 - val_loss: 6.7655 - val_accuracy: 0.5949\n",
      "Epoch 789/10000\n",
      "6/6 [==============================] - 0s 53ms/step - loss: 0.0111 - accuracy: 0.9973 - val_loss: 6.7888 - val_accuracy: 0.5918\n",
      "Epoch 790/10000\n",
      "6/6 [==============================] - 0s 55ms/step - loss: 0.0102 - accuracy: 0.9980 - val_loss: 6.7942 - val_accuracy: 0.5949\n",
      "Epoch 791/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.0129 - accuracy: 0.9980 - val_loss: 6.8311 - val_accuracy: 0.5888\n",
      "Epoch 792/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.0110 - accuracy: 0.9983 - val_loss: 6.8560 - val_accuracy: 0.5898\n",
      "Epoch 793/10000\n",
      "6/6 [==============================] - 0s 52ms/step - loss: 0.0131 - accuracy: 0.9980 - val_loss: 6.7765 - val_accuracy: 0.5888\n",
      "Epoch 794/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.0149 - accuracy: 0.9973 - val_loss: 6.7696 - val_accuracy: 0.5898\n",
      "Epoch 795/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.0119 - accuracy: 0.9983 - val_loss: 6.8965 - val_accuracy: 0.5898\n",
      "Epoch 796/10000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.0119 - accuracy: 0.9983 - val_loss: 6.7931 - val_accuracy: 0.5949\n",
      "Epoch 797/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.0143 - accuracy: 0.9973 - val_loss: 6.8564 - val_accuracy: 0.5959\n",
      "Epoch 798/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.0155 - accuracy: 0.9966 - val_loss: 6.8579 - val_accuracy: 0.5898\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 799/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.0153 - accuracy: 0.9966 - val_loss: 6.7942 - val_accuracy: 0.5867\n",
      "Epoch 800/10000\n",
      "6/6 [==============================] - 0s 61ms/step - loss: 0.0177 - accuracy: 0.9969 - val_loss: 6.8127 - val_accuracy: 0.5908\n",
      "Epoch 801/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0128 - accuracy: 0.9966 - val_loss: 6.9291 - val_accuracy: 0.5908\n",
      "Epoch 802/10000\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.0122 - accuracy: 0.9983 - val_loss: 6.7815 - val_accuracy: 0.5959\n",
      "Epoch 803/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.0108 - accuracy: 0.9980 - val_loss: 6.8269 - val_accuracy: 0.5929\n",
      "Epoch 804/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.0122 - accuracy: 0.9973 - val_loss: 6.8664 - val_accuracy: 0.5898\n",
      "Epoch 805/10000\n",
      "6/6 [==============================] - 0s 54ms/step - loss: 0.0124 - accuracy: 0.9976 - val_loss: 6.8435 - val_accuracy: 0.5939\n",
      "Epoch 806/10000\n",
      "6/6 [==============================] - 0s 53ms/step - loss: 0.0101 - accuracy: 0.9986 - val_loss: 6.8624 - val_accuracy: 0.5949\n",
      "Epoch 807/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.0092 - accuracy: 0.9983 - val_loss: 6.8721 - val_accuracy: 0.5969\n",
      "Epoch 808/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.0106 - accuracy: 0.9980 - val_loss: 6.8375 - val_accuracy: 0.5959\n",
      "Epoch 809/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.0124 - accuracy: 0.9980 - val_loss: 6.9814 - val_accuracy: 0.5959\n",
      "Epoch 810/10000\n",
      "6/6 [==============================] - 0s 64ms/step - loss: 0.0091 - accuracy: 0.9980 - val_loss: 6.8851 - val_accuracy: 0.5898\n",
      "Epoch 811/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.0095 - accuracy: 0.9980 - val_loss: 6.9332 - val_accuracy: 0.5939\n",
      "Epoch 812/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.0101 - accuracy: 0.9983 - val_loss: 6.8675 - val_accuracy: 0.5908\n",
      "Epoch 813/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0102 - accuracy: 0.9973 - val_loss: 6.9409 - val_accuracy: 0.5939\n",
      "Epoch 814/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0077 - accuracy: 0.9993 - val_loss: 6.9314 - val_accuracy: 0.5908\n",
      "Epoch 815/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.0090 - accuracy: 0.9983 - val_loss: 6.9513 - val_accuracy: 0.5949\n",
      "Epoch 816/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.0075 - accuracy: 0.9983 - val_loss: 6.9402 - val_accuracy: 0.5918\n",
      "Epoch 817/10000\n",
      "6/6 [==============================] - 0s 62ms/step - loss: 0.0077 - accuracy: 0.9983 - val_loss: 6.8915 - val_accuracy: 0.5908\n",
      "Epoch 818/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.0103 - accuracy: 0.9980 - val_loss: 6.9739 - val_accuracy: 0.5898\n",
      "Epoch 819/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.0128 - accuracy: 0.9973 - val_loss: 6.9155 - val_accuracy: 0.5867\n",
      "Epoch 820/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.0146 - accuracy: 0.9966 - val_loss: 6.9799 - val_accuracy: 0.5898\n",
      "Epoch 821/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.0098 - accuracy: 0.9976 - val_loss: 6.9941 - val_accuracy: 0.5908\n",
      "Epoch 822/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.0093 - accuracy: 0.9976 - val_loss: 6.9557 - val_accuracy: 0.5908\n",
      "Epoch 823/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.0086 - accuracy: 0.9980 - val_loss: 6.9349 - val_accuracy: 0.5918\n",
      "Epoch 824/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0082 - accuracy: 0.9976 - val_loss: 6.9519 - val_accuracy: 0.5908\n",
      "Epoch 825/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.0098 - accuracy: 0.9969 - val_loss: 6.9671 - val_accuracy: 0.5918\n",
      "Epoch 826/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.0087 - accuracy: 0.9973 - val_loss: 7.0017 - val_accuracy: 0.5949\n",
      "Epoch 827/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.0073 - accuracy: 0.9990 - val_loss: 6.9973 - val_accuracy: 0.5888\n",
      "Epoch 828/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.0082 - accuracy: 0.9980 - val_loss: 7.0113 - val_accuracy: 0.5929\n",
      "Epoch 829/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0091 - accuracy: 0.9980 - val_loss: 6.9765 - val_accuracy: 0.5949\n",
      "Epoch 830/10000\n",
      "6/6 [==============================] - 0s 53ms/step - loss: 0.0078 - accuracy: 0.9980 - val_loss: 6.9581 - val_accuracy: 0.5847\n",
      "Epoch 831/10000\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 0.0083 - accuracy: 0.9980 - val_loss: 7.0182 - val_accuracy: 0.5949\n",
      "Epoch 832/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.0083 - accuracy: 0.9976 - val_loss: 6.9581 - val_accuracy: 0.5908\n",
      "Epoch 833/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.0097 - accuracy: 0.9980 - val_loss: 7.0325 - val_accuracy: 0.5918\n",
      "Epoch 834/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.0079 - accuracy: 0.9983 - val_loss: 6.9912 - val_accuracy: 0.5878\n",
      "Epoch 835/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.0081 - accuracy: 0.9980 - val_loss: 7.0110 - val_accuracy: 0.5908\n",
      "Epoch 836/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0081 - accuracy: 0.9980 - val_loss: 7.0653 - val_accuracy: 0.5939\n",
      "Epoch 837/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.0100 - accuracy: 0.9976 - val_loss: 7.0097 - val_accuracy: 0.5867\n",
      "Epoch 838/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.0109 - accuracy: 0.9969 - val_loss: 6.9849 - val_accuracy: 0.5898\n",
      "Epoch 839/10000\n",
      "6/6 [==============================] - 0s 52ms/step - loss: 0.0122 - accuracy: 0.9973 - val_loss: 7.1334 - val_accuracy: 0.5939\n",
      "Epoch 840/10000\n",
      "6/6 [==============================] - 0s 52ms/step - loss: 0.0133 - accuracy: 0.9963 - val_loss: 7.0219 - val_accuracy: 0.5857\n",
      "Epoch 841/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0136 - accuracy: 0.9973 - val_loss: 7.0031 - val_accuracy: 0.5898\n",
      "Epoch 842/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.0261 - accuracy: 0.9925 - val_loss: 7.0740 - val_accuracy: 0.5918\n",
      "Epoch 843/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0918 - accuracy: 0.9738 - val_loss: 7.0369 - val_accuracy: 0.5867\n",
      "Epoch 844/10000\n",
      "6/6 [==============================] - 0s 52ms/step - loss: 0.0879 - accuracy: 0.9714 - val_loss: 6.8768 - val_accuracy: 0.5755\n",
      "Epoch 845/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.1225 - accuracy: 0.9585 - val_loss: 7.2106 - val_accuracy: 0.5827\n",
      "Epoch 846/10000\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.1830 - accuracy: 0.9493 - val_loss: 6.9116 - val_accuracy: 0.5673\n",
      "Epoch 847/10000\n",
      "6/6 [==============================] - 0s 52ms/step - loss: 0.3342 - accuracy: 0.9101 - val_loss: 6.7655 - val_accuracy: 0.5786\n",
      "Epoch 848/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.2603 - accuracy: 0.9224 - val_loss: 6.8695 - val_accuracy: 0.5602\n",
      "Epoch 849/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.1637 - accuracy: 0.9462 - val_loss: 6.5674 - val_accuracy: 0.5847\n",
      "Epoch 850/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.1066 - accuracy: 0.9615 - val_loss: 6.3568 - val_accuracy: 0.5949\n",
      "Epoch 851/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.0655 - accuracy: 0.9803 - val_loss: 6.4664 - val_accuracy: 0.5816\n",
      "Epoch 852/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.0493 - accuracy: 0.9860 - val_loss: 6.6975 - val_accuracy: 0.5847\n",
      "Epoch 853/10000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.0433 - accuracy: 0.9847 - val_loss: 6.5250 - val_accuracy: 0.5847\n",
      "Epoch 854/10000\n",
      "6/6 [==============================] - 0s 53ms/step - loss: 0.0361 - accuracy: 0.9881 - val_loss: 6.6536 - val_accuracy: 0.5847\n",
      "Epoch 855/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.0262 - accuracy: 0.9932 - val_loss: 6.6409 - val_accuracy: 0.5837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 856/10000\n",
      "6/6 [==============================] - 0s 54ms/step - loss: 0.0196 - accuracy: 0.9966 - val_loss: 6.5252 - val_accuracy: 0.5959\n",
      "Epoch 857/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.0165 - accuracy: 0.9973 - val_loss: 6.6752 - val_accuracy: 0.5898\n",
      "Epoch 858/10000\n",
      "6/6 [==============================] - 0s 55ms/step - loss: 0.0172 - accuracy: 0.9966 - val_loss: 6.5243 - val_accuracy: 0.5939\n",
      "Epoch 859/10000\n",
      "6/6 [==============================] - 0s 54ms/step - loss: 0.0138 - accuracy: 0.9980 - val_loss: 6.6866 - val_accuracy: 0.5847\n",
      "Epoch 860/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.0123 - accuracy: 0.9980 - val_loss: 6.6210 - val_accuracy: 0.5939\n",
      "Epoch 861/10000\n",
      "6/6 [==============================] - 0s 53ms/step - loss: 0.0125 - accuracy: 0.9969 - val_loss: 6.6663 - val_accuracy: 0.5939\n",
      "Epoch 862/10000\n",
      "6/6 [==============================] - 0s 56ms/step - loss: 0.0106 - accuracy: 0.9980 - val_loss: 6.6418 - val_accuracy: 0.5898\n",
      "Epoch 863/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.0100 - accuracy: 0.9976 - val_loss: 6.7140 - val_accuracy: 0.5949\n",
      "Epoch 864/10000\n",
      "6/6 [==============================] - 0s 53ms/step - loss: 0.0100 - accuracy: 0.9980 - val_loss: 6.7033 - val_accuracy: 0.5939\n",
      "Epoch 865/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.0103 - accuracy: 0.9973 - val_loss: 6.7479 - val_accuracy: 0.5949\n",
      "Epoch 866/10000\n",
      "6/6 [==============================] - 0s 53ms/step - loss: 0.0102 - accuracy: 0.9980 - val_loss: 6.7159 - val_accuracy: 0.5918\n",
      "Epoch 867/10000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.0094 - accuracy: 0.9983 - val_loss: 6.7553 - val_accuracy: 0.5969\n",
      "Epoch 868/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0090 - accuracy: 0.9986 - val_loss: 6.7176 - val_accuracy: 0.5929\n",
      "Epoch 869/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.0092 - accuracy: 0.9983 - val_loss: 6.7782 - val_accuracy: 0.5939\n",
      "Epoch 870/10000\n",
      "6/6 [==============================] - 0s 53ms/step - loss: 0.0101 - accuracy: 0.9980 - val_loss: 6.7525 - val_accuracy: 0.5959\n",
      "Epoch 871/10000\n",
      "6/6 [==============================] - 0s 53ms/step - loss: 0.0094 - accuracy: 0.9983 - val_loss: 6.8005 - val_accuracy: 0.5918\n",
      "Epoch 872/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0098 - accuracy: 0.9986 - val_loss: 6.7721 - val_accuracy: 0.5949\n",
      "Epoch 873/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0086 - accuracy: 0.9983 - val_loss: 6.7679 - val_accuracy: 0.5949\n",
      "Epoch 874/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.0093 - accuracy: 0.9983 - val_loss: 6.8146 - val_accuracy: 0.5918\n",
      "Epoch 875/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.0079 - accuracy: 0.9986 - val_loss: 6.7828 - val_accuracy: 0.5949\n",
      "Epoch 876/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.0084 - accuracy: 0.9983 - val_loss: 6.8270 - val_accuracy: 0.5929\n",
      "Epoch 877/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0082 - accuracy: 0.9983 - val_loss: 6.8104 - val_accuracy: 0.5918\n",
      "Epoch 878/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.0082 - accuracy: 0.9986 - val_loss: 6.8327 - val_accuracy: 0.5918\n",
      "Epoch 879/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0080 - accuracy: 0.9980 - val_loss: 6.8419 - val_accuracy: 0.5908\n",
      "Epoch 880/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.0078 - accuracy: 0.9986 - val_loss: 6.8492 - val_accuracy: 0.5908\n",
      "Epoch 881/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0073 - accuracy: 0.9990 - val_loss: 6.8584 - val_accuracy: 0.5918\n",
      "Epoch 882/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0077 - accuracy: 0.9986 - val_loss: 6.8471 - val_accuracy: 0.5918\n",
      "Epoch 883/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0089 - accuracy: 0.9969 - val_loss: 6.8964 - val_accuracy: 0.5908\n",
      "Epoch 884/10000\n",
      "6/6 [==============================] - 0s 52ms/step - loss: 0.0091 - accuracy: 0.9983 - val_loss: 6.8471 - val_accuracy: 0.5918\n",
      "Epoch 885/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0102 - accuracy: 0.9980 - val_loss: 6.8967 - val_accuracy: 0.5918\n",
      "Epoch 886/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.0079 - accuracy: 0.9976 - val_loss: 6.8709 - val_accuracy: 0.5878\n",
      "Epoch 887/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.0081 - accuracy: 0.9980 - val_loss: 6.8828 - val_accuracy: 0.5898\n",
      "Epoch 888/10000\n",
      "6/6 [==============================] - 0s 52ms/step - loss: 0.0076 - accuracy: 0.9980 - val_loss: 6.9002 - val_accuracy: 0.5929\n",
      "Epoch 889/10000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.0078 - accuracy: 0.9980 - val_loss: 6.9089 - val_accuracy: 0.5908\n",
      "Epoch 890/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.0072 - accuracy: 0.9983 - val_loss: 6.9356 - val_accuracy: 0.5908\n",
      "Epoch 891/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0083 - accuracy: 0.9973 - val_loss: 6.8992 - val_accuracy: 0.5898\n",
      "Epoch 892/10000\n",
      "6/6 [==============================] - 0s 56ms/step - loss: 0.0084 - accuracy: 0.9980 - val_loss: 6.9361 - val_accuracy: 0.5908\n",
      "Epoch 893/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.0087 - accuracy: 0.9980 - val_loss: 6.8910 - val_accuracy: 0.5908\n",
      "Epoch 894/10000\n",
      "6/6 [==============================] - 0s 52ms/step - loss: 0.0101 - accuracy: 0.9980 - val_loss: 6.9669 - val_accuracy: 0.5918\n",
      "Epoch 895/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.0118 - accuracy: 0.9963 - val_loss: 6.8756 - val_accuracy: 0.5929\n",
      "Epoch 896/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.0092 - accuracy: 0.9973 - val_loss: 6.9536 - val_accuracy: 0.5888\n",
      "Epoch 897/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.0092 - accuracy: 0.9976 - val_loss: 6.8986 - val_accuracy: 0.5878\n",
      "Epoch 898/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.0084 - accuracy: 0.9983 - val_loss: 6.9698 - val_accuracy: 0.5878\n",
      "Epoch 899/10000\n",
      "6/6 [==============================] - 0s 52ms/step - loss: 0.0077 - accuracy: 0.9990 - val_loss: 6.9071 - val_accuracy: 0.5908\n",
      "Epoch 900/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.0124 - accuracy: 0.9969 - val_loss: 6.9426 - val_accuracy: 0.5939\n",
      "Epoch 901/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.0156 - accuracy: 0.9963 - val_loss: 6.8546 - val_accuracy: 0.5898\n",
      "Epoch 902/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.0386 - accuracy: 0.9912 - val_loss: 6.9184 - val_accuracy: 0.5929\n",
      "Epoch 903/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.0264 - accuracy: 0.9918 - val_loss: 7.0922 - val_accuracy: 0.5867\n",
      "Epoch 904/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.0218 - accuracy: 0.9956 - val_loss: 6.8238 - val_accuracy: 0.5959\n",
      "Epoch 905/10000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.0125 - accuracy: 0.9976 - val_loss: 6.8707 - val_accuracy: 0.5898\n",
      "Epoch 906/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.0109 - accuracy: 0.9983 - val_loss: 6.8159 - val_accuracy: 0.5867\n",
      "Epoch 907/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0094 - accuracy: 0.9983 - val_loss: 6.8636 - val_accuracy: 0.5878\n",
      "Epoch 908/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.0092 - accuracy: 0.9980 - val_loss: 6.9022 - val_accuracy: 0.5878\n",
      "Epoch 909/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.0111 - accuracy: 0.9980 - val_loss: 6.8958 - val_accuracy: 0.5959\n",
      "Epoch 910/10000\n",
      "6/6 [==============================] - 0s 55ms/step - loss: 0.0096 - accuracy: 0.9980 - val_loss: 6.9612 - val_accuracy: 0.5867\n",
      "Epoch 911/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0096 - accuracy: 0.9980 - val_loss: 6.8872 - val_accuracy: 0.5898\n",
      "Epoch 912/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.0079 - accuracy: 0.9986 - val_loss: 6.9394 - val_accuracy: 0.5888\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 913/10000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.0080 - accuracy: 0.9980 - val_loss: 6.9283 - val_accuracy: 0.5918\n",
      "Epoch 914/10000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.0082 - accuracy: 0.9983 - val_loss: 6.9797 - val_accuracy: 0.5918\n",
      "Epoch 915/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.0080 - accuracy: 0.9983 - val_loss: 6.9663 - val_accuracy: 0.5908\n",
      "Epoch 916/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0068 - accuracy: 0.9990 - val_loss: 7.0047 - val_accuracy: 0.5918\n",
      "Epoch 917/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.0075 - accuracy: 0.9973 - val_loss: 6.9707 - val_accuracy: 0.5888\n",
      "Epoch 918/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0066 - accuracy: 0.9986 - val_loss: 7.0108 - val_accuracy: 0.5908\n",
      "Epoch 919/10000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.0088 - accuracy: 0.9976 - val_loss: 6.9969 - val_accuracy: 0.5929\n",
      "Epoch 920/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0103 - accuracy: 0.9973 - val_loss: 6.9935 - val_accuracy: 0.5898\n",
      "Epoch 921/10000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.0085 - accuracy: 0.9973 - val_loss: 7.0578 - val_accuracy: 0.5888\n",
      "Epoch 922/10000\n",
      "6/6 [==============================] - 0s 55ms/step - loss: 0.0113 - accuracy: 0.9973 - val_loss: 6.9868 - val_accuracy: 0.5908\n",
      "Epoch 923/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.0083 - accuracy: 0.9976 - val_loss: 6.9732 - val_accuracy: 0.5918\n",
      "Epoch 924/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.0081 - accuracy: 0.9980 - val_loss: 7.0216 - val_accuracy: 0.5867\n",
      "Epoch 925/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.0069 - accuracy: 0.9983 - val_loss: 6.9920 - val_accuracy: 0.5888\n",
      "Epoch 926/10000\n",
      "6/6 [==============================] - 0s 52ms/step - loss: 0.0081 - accuracy: 0.9980 - val_loss: 7.0126 - val_accuracy: 0.5898\n",
      "Epoch 927/10000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.0104 - accuracy: 0.9983 - val_loss: 7.0685 - val_accuracy: 0.5939\n",
      "Epoch 928/10000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.0085 - accuracy: 0.9976 - val_loss: 6.9882 - val_accuracy: 0.5949\n",
      "Epoch 929/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.0073 - accuracy: 0.9986 - val_loss: 7.0917 - val_accuracy: 0.5888\n",
      "Epoch 930/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.0087 - accuracy: 0.9980 - val_loss: 7.0311 - val_accuracy: 0.5908\n",
      "Epoch 931/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.0093 - accuracy: 0.9980 - val_loss: 7.0784 - val_accuracy: 0.5908\n",
      "Epoch 932/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.0122 - accuracy: 0.9966 - val_loss: 7.0554 - val_accuracy: 0.5888\n",
      "Epoch 933/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0124 - accuracy: 0.9969 - val_loss: 7.0555 - val_accuracy: 0.5908\n",
      "Epoch 934/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0150 - accuracy: 0.9969 - val_loss: 6.9662 - val_accuracy: 0.5908\n",
      "Epoch 935/10000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.0111 - accuracy: 0.9980 - val_loss: 7.2015 - val_accuracy: 0.5847\n",
      "Epoch 936/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.0155 - accuracy: 0.9959 - val_loss: 6.9619 - val_accuracy: 0.5908\n",
      "Epoch 937/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.0108 - accuracy: 0.9966 - val_loss: 7.0487 - val_accuracy: 0.5867\n",
      "Epoch 938/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0094 - accuracy: 0.9976 - val_loss: 7.0728 - val_accuracy: 0.5867\n",
      "Epoch 939/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0083 - accuracy: 0.9976 - val_loss: 7.0420 - val_accuracy: 0.5908\n",
      "Epoch 940/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0093 - accuracy: 0.9976 - val_loss: 7.0715 - val_accuracy: 0.5949\n",
      "Epoch 941/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0088 - accuracy: 0.9980 - val_loss: 7.0259 - val_accuracy: 0.5908\n",
      "Epoch 942/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.0073 - accuracy: 0.9980 - val_loss: 7.0722 - val_accuracy: 0.5898\n",
      "Epoch 943/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.0075 - accuracy: 0.9973 - val_loss: 7.1058 - val_accuracy: 0.5908\n",
      "Epoch 944/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.0069 - accuracy: 0.9980 - val_loss: 7.0700 - val_accuracy: 0.5878\n",
      "Epoch 945/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0063 - accuracy: 0.9983 - val_loss: 7.0814 - val_accuracy: 0.5878\n",
      "Epoch 946/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0068 - accuracy: 0.9980 - val_loss: 7.1033 - val_accuracy: 0.5888\n",
      "Epoch 947/10000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.0071 - accuracy: 0.9983 - val_loss: 7.1114 - val_accuracy: 0.5898\n",
      "Epoch 948/10000\n",
      "6/6 [==============================] - 0s 52ms/step - loss: 0.0081 - accuracy: 0.9983 - val_loss: 7.0717 - val_accuracy: 0.5918\n",
      "Epoch 949/10000\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.0081 - accuracy: 0.9983 - val_loss: 7.1539 - val_accuracy: 0.5878\n",
      "Epoch 950/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.0081 - accuracy: 0.9973 - val_loss: 7.0409 - val_accuracy: 0.5857\n",
      "Epoch 951/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.0087 - accuracy: 0.9976 - val_loss: 7.1108 - val_accuracy: 0.5898\n",
      "Epoch 952/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.0073 - accuracy: 0.9976 - val_loss: 7.1349 - val_accuracy: 0.5888\n",
      "Epoch 953/10000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.0070 - accuracy: 0.9976 - val_loss: 7.1211 - val_accuracy: 0.5857\n",
      "Epoch 954/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.0070 - accuracy: 0.9983 - val_loss: 7.1401 - val_accuracy: 0.5908\n",
      "Epoch 955/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.0087 - accuracy: 0.9980 - val_loss: 7.1463 - val_accuracy: 0.5878\n",
      "Epoch 956/10000\n",
      "6/6 [==============================] - 0s 55ms/step - loss: 0.0074 - accuracy: 0.9973 - val_loss: 7.1415 - val_accuracy: 0.5857\n",
      "Epoch 957/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.0104 - accuracy: 0.9976 - val_loss: 7.1301 - val_accuracy: 0.5878\n",
      "Epoch 958/10000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.0097 - accuracy: 0.9973 - val_loss: 7.1887 - val_accuracy: 0.5898\n",
      "Epoch 959/10000\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.0084 - accuracy: 0.9973 - val_loss: 7.1565 - val_accuracy: 0.5908\n",
      "Epoch 960/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0099 - accuracy: 0.9973 - val_loss: 7.1950 - val_accuracy: 0.5908\n",
      "Epoch 961/10000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.0087 - accuracy: 0.9983 - val_loss: 7.1839 - val_accuracy: 0.5908\n",
      "Epoch 962/10000\n",
      "6/6 [==============================] - 0s 53ms/step - loss: 0.0084 - accuracy: 0.9976 - val_loss: 7.1290 - val_accuracy: 0.5888\n",
      "Epoch 963/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.0086 - accuracy: 0.9976 - val_loss: 7.1633 - val_accuracy: 0.5898\n",
      "Epoch 964/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0082 - accuracy: 0.9980 - val_loss: 7.1587 - val_accuracy: 0.5888\n",
      "Epoch 965/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.0080 - accuracy: 0.9983 - val_loss: 7.1779 - val_accuracy: 0.5908\n",
      "Epoch 966/10000\n",
      "6/6 [==============================] - 0s 53ms/step - loss: 0.0066 - accuracy: 0.9986 - val_loss: 7.1655 - val_accuracy: 0.5878\n",
      "Epoch 967/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.0076 - accuracy: 0.9980 - val_loss: 7.2191 - val_accuracy: 0.5898\n",
      "Epoch 968/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0069 - accuracy: 0.9983 - val_loss: 7.1635 - val_accuracy: 0.5867\n",
      "Epoch 969/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.0066 - accuracy: 0.9976 - val_loss: 7.2128 - val_accuracy: 0.5918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 970/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.0067 - accuracy: 0.9980 - val_loss: 7.2117 - val_accuracy: 0.5878\n",
      "Epoch 971/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.0069 - accuracy: 0.9980 - val_loss: 7.1579 - val_accuracy: 0.5867\n",
      "Epoch 972/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.0084 - accuracy: 0.9976 - val_loss: 7.2488 - val_accuracy: 0.5908\n",
      "Epoch 973/10000\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.0065 - accuracy: 0.9986 - val_loss: 7.1844 - val_accuracy: 0.5878\n",
      "Epoch 974/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.0083 - accuracy: 0.9983 - val_loss: 7.2408 - val_accuracy: 0.5898\n",
      "Epoch 975/10000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.0059 - accuracy: 0.9990 - val_loss: 7.2466 - val_accuracy: 0.5878\n",
      "Epoch 976/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.0072 - accuracy: 0.9980 - val_loss: 7.2015 - val_accuracy: 0.5847\n",
      "Epoch 977/10000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.0078 - accuracy: 0.9983 - val_loss: 7.2334 - val_accuracy: 0.5888\n",
      "Epoch 978/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.0079 - accuracy: 0.9980 - val_loss: 7.2197 - val_accuracy: 0.5898\n",
      "Epoch 979/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0118 - accuracy: 0.9980 - val_loss: 7.2476 - val_accuracy: 0.5929\n",
      "Epoch 980/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0127 - accuracy: 0.9966 - val_loss: 7.1533 - val_accuracy: 0.5888\n",
      "Epoch 981/10000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.0143 - accuracy: 0.9973 - val_loss: 7.3019 - val_accuracy: 0.5878\n",
      "Epoch 982/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.0126 - accuracy: 0.9973 - val_loss: 7.1411 - val_accuracy: 0.5837\n",
      "Epoch 983/10000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.0133 - accuracy: 0.9969 - val_loss: 7.1722 - val_accuracy: 0.5878\n",
      "Epoch 984/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.0077 - accuracy: 0.9983 - val_loss: 7.2098 - val_accuracy: 0.5898\n",
      "Epoch 985/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0079 - accuracy: 0.9983 - val_loss: 7.2165 - val_accuracy: 0.5857\n",
      "Epoch 986/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0069 - accuracy: 0.9986 - val_loss: 7.2357 - val_accuracy: 0.5908\n",
      "Epoch 987/10000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.0075 - accuracy: 0.9969 - val_loss: 7.2065 - val_accuracy: 0.5867\n",
      "Epoch 988/10000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.0069 - accuracy: 0.9983 - val_loss: 7.2537 - val_accuracy: 0.5878\n",
      "Epoch 989/10000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.0071 - accuracy: 0.9976 - val_loss: 7.2204 - val_accuracy: 0.5878\n",
      "Epoch 990/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.0062 - accuracy: 0.9983 - val_loss: 7.2385 - val_accuracy: 0.5867\n",
      "Epoch 991/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0082 - accuracy: 0.9976 - val_loss: 7.2166 - val_accuracy: 0.5847\n",
      "Epoch 992/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.0099 - accuracy: 0.9973 - val_loss: 7.3264 - val_accuracy: 0.5898\n",
      "Epoch 993/10000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.0093 - accuracy: 0.9973 - val_loss: 7.1642 - val_accuracy: 0.5939\n",
      "Epoch 994/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.0069 - accuracy: 0.9990 - val_loss: 7.3495 - val_accuracy: 0.5878\n",
      "Epoch 995/10000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.0095 - accuracy: 0.9969 - val_loss: 7.1912 - val_accuracy: 0.5908\n",
      "Epoch 996/10000\n",
      "6/6 [==============================] - 0s 53ms/step - loss: 0.0093 - accuracy: 0.9976 - val_loss: 7.3980 - val_accuracy: 0.5898\n",
      "Epoch 997/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0094 - accuracy: 0.9969 - val_loss: 7.1949 - val_accuracy: 0.5857\n",
      "Epoch 998/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0064 - accuracy: 0.9986 - val_loss: 7.2917 - val_accuracy: 0.5898\n",
      "Epoch 999/10000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0083 - accuracy: 0.9976 - val_loss: 7.2576 - val_accuracy: 0.5878\n",
      "Epoch 1000/10000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.0079 - accuracy: 0.9983 - val_loss: 7.3430 - val_accuracy: 0.5908\n",
      "Epoch 1001/10000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.0072 - accuracy: 0.9983 - val_loss: 7.2654 - val_accuracy: 0.5867\n"
     ]
    }
   ],
   "source": [
    "model1.compile(loss=\"categorical_crossentropy\", optimizer='adam', metrics=['accuracy'])\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=1000)\n",
    "modelpath = \"./model/wine_model{epoch:0003d}__{val_loss:.4f}.keras\"\n",
    "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=0, save_best_only=True)\n",
    "history = model1.fit(X_train, y_train, epochs=10000, batch_size=500, validation_data=(X_valid, y_valid), callbacks=[early_stop, checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6010fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_best_model = load_model(\"./model/wine_model019__1.0356.keras\")\n",
    "pred = wine_best_model.predict(X_test)\n",
    "pred = pd.DataFrame(pred)\n",
    "pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d18cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 행에서 확률이 가장 높은 클래스의 인덱스를 찾기\n",
    "predicted_classes = pred.idxmax(axis=1)\n",
    "\n",
    "# 결과 출력\n",
    "print(predicted_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b9f624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 행에서 확률이 가장 높은 클래스의 인덱스를 찾기\n",
    "y_classes = y_test.idxmax(axis=1)\n",
    "\n",
    "# 결과 출력\n",
    "print(y_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "dbaa8b1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1815</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4590</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3761</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3899</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1731</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4609</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2708</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>980 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          3      4      5      6      7      8      9\n",
       "1815  False  False  False   True  False  False  False\n",
       "4590  False  False  False   True  False  False  False\n",
       "452   False  False  False  False   True  False  False\n",
       "3761  False  False  False  False   True  False  False\n",
       "3899  False  False   True  False  False  False  False\n",
       "...     ...    ...    ...    ...    ...    ...    ...\n",
       "1731  False  False  False   True  False  False  False\n",
       "4609  False   True  False  False  False  False  False\n",
       "460   False  False   True  False  False  False  False\n",
       "301   False  False  False   True  False  False  False\n",
       "2708  False  False  False   True  False  False  False\n",
       "\n",
       "[980 rows x 7 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f8cea310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.01      0.75      0.01         4\n",
      "           4       0.01      0.03      0.01        33\n",
      "           5       0.00      0.00      0.00       291\n",
      "           6       0.00      0.00      0.00       440\n",
      "           7       0.00      0.00      0.00       176\n",
      "           8       0.00      0.00      0.00        35\n",
      "           9       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.00       980\n",
      "   macro avg       0.00      0.09      0.00       980\n",
      "weighted avg       0.00      0.00      0.00       980\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniforge3/envs/dml/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/user/miniforge3/envs/dml/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/user/miniforge3/envs/dml/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/user/miniforge3/envs/dml/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/user/miniforge3/envs/dml/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/user/miniforge3/envs/dml/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_classes, predicted_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "295c4bd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['train', 'val'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3651c3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8aa24902",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 3, ..., 3, 4, 3])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "y_labeled = le.fit_transform(y2)\n",
    "y_labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258a6142",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "131bd93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2, X_valid2, y_train2, y_valid2 = train_test_split(X_scaled, y_labeled, test_size=0.4, stratify=y_labeled ,random_state=10)\n",
    "X_valid2, X_test2, y_valid2, y_test2 = train_test_split(X_valid2, y_valid2, test_size=0.5, stratify=y_valid2, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f101f8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "86c20e76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b80df151",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 6, 5, 4, 6, 6, 7, 5, 6, 6, 6, 6, 7, 6, 6, 7, 6, 5, 7, 6, 5, 6,\n",
       "       6, 5, 5, 4, 7, 6, 6, 6, 6, 5, 5, 6, 7, 6, 5, 5, 6, 7, 7, 6, 5, 7,\n",
       "       5, 6, 7, 5, 6, 5, 6, 6, 6, 5, 6, 6, 7, 5, 5, 7, 6, 6, 6, 6, 5, 6,\n",
       "       5, 6, 6, 5, 6, 6, 5, 5, 7, 7, 5, 6, 6, 6, 7, 7, 5, 8, 7, 5, 6, 7,\n",
       "       7, 5, 7, 7, 5, 6, 6, 5, 6, 7, 7, 5, 6, 6, 5, 5, 4, 5, 5, 5, 6, 5,\n",
       "       5, 5, 6, 5, 7, 5, 7, 6, 6, 5, 6, 7, 5, 7, 6, 6, 7, 7, 7, 4, 6, 6,\n",
       "       6, 6, 5, 4, 7, 5, 5, 7, 7, 6, 6, 7, 5, 7, 7, 5, 6, 6, 5, 7, 7, 6,\n",
       "       6, 8, 6, 6, 5, 7, 6, 6, 6, 8, 5, 7, 6, 5, 6, 6, 5, 6, 6, 6, 7, 6,\n",
       "       6, 5, 7, 7, 6, 6, 5, 7, 7, 6, 6, 7, 5, 6, 6, 6, 6, 6, 6, 6, 8, 6,\n",
       "       6, 7, 5, 8, 7, 6, 7, 5, 6, 5, 6, 5, 6, 6, 6, 6, 8, 6, 6, 7, 6, 6,\n",
       "       6, 5, 6, 7, 6, 5, 7, 7, 6, 8, 7, 8, 5, 3, 5, 5, 7, 7, 5, 7, 6, 5,\n",
       "       6, 6, 8, 7, 5, 6, 5, 5, 6, 7, 6, 6, 6, 6, 3, 5, 6, 6, 6, 6, 5, 7,\n",
       "       6, 6, 4, 5, 7, 6, 6, 6, 6, 4, 7, 5, 7, 7, 5, 6, 6, 5, 6, 7, 7, 6,\n",
       "       6, 6, 5, 7, 6, 6, 6, 6, 5, 6, 6, 7, 5, 7, 6, 6, 7, 6, 7, 5, 6, 7,\n",
       "       6, 6, 6, 5, 7, 6, 6, 6, 5, 7, 6, 5, 6, 6, 4, 6, 6, 6, 5, 5, 5, 6,\n",
       "       6, 6, 6, 6, 7, 7, 5, 7, 5, 5, 6, 8, 6, 7, 6, 7, 4, 6, 6, 6, 5, 6,\n",
       "       6, 6, 7, 8, 7, 5, 8, 6, 6, 6, 6, 6, 6, 6, 5, 6, 5, 5, 5, 6, 5, 8,\n",
       "       6, 6, 6, 7, 5, 7, 7, 6, 7, 5, 6, 7, 6, 5, 6, 5, 6, 5, 7, 7, 7, 5,\n",
       "       6, 6, 3, 4, 5, 8, 6, 6, 6, 5, 6, 5, 5, 6, 6, 6, 6, 6, 7, 6, 5, 5,\n",
       "       6, 5, 7, 6, 6, 6, 5, 6, 6, 5, 7, 6, 5, 6, 7, 6, 6, 5, 5, 6, 6, 6,\n",
       "       5, 6, 5, 5, 6, 5, 6, 5, 5, 7, 5, 6, 5, 5, 6, 6, 7, 5, 4, 7, 7, 6,\n",
       "       7, 6, 6, 7, 8, 7, 6, 6, 6, 7, 4, 4, 4, 6, 5, 6, 5, 6, 6, 6, 5, 6,\n",
       "       6, 5, 6, 6, 6, 5, 8, 8, 5, 7, 5, 6, 5, 5, 5, 5, 5, 6, 6, 6, 6, 5,\n",
       "       5, 7, 5, 5, 6, 6, 9, 6, 6, 6, 6, 5, 5, 7, 4, 6, 7, 4, 7, 4, 5, 6,\n",
       "       6, 6, 5, 7, 6, 6, 5, 6, 5, 6, 7, 5, 5, 6, 5, 7, 5, 7, 5, 6, 5, 6,\n",
       "       6, 6, 5, 7, 7, 5, 5, 7, 7, 6, 6, 5, 6, 4, 7, 5, 6, 8, 5, 7, 6, 5,\n",
       "       4, 5, 7, 7, 7, 5, 5, 7, 5, 5, 6, 5, 5, 6, 7, 6, 5, 6, 5, 5, 7, 6,\n",
       "       6, 6, 7, 6, 6, 6, 6, 5, 6, 7, 5, 7, 6, 7, 7, 6, 6, 5, 5, 6, 7, 6,\n",
       "       5, 6, 4, 5, 6, 5, 6, 4, 6, 5, 5, 7, 6, 5, 5, 6, 7, 8, 5, 7, 6, 6,\n",
       "       6, 6, 7, 6, 6, 6, 5, 8, 7, 6, 5, 6, 7, 5, 5, 8, 7, 5, 5, 5, 5, 6,\n",
       "       6, 5, 6, 5, 6, 5, 6, 6, 8, 5, 7, 6, 5, 5, 5, 6, 6, 7, 5, 7, 5, 6,\n",
       "       5, 5, 5, 7, 6, 6, 6, 4, 4, 5, 6, 5, 5, 7, 5, 5, 5, 6, 6, 6, 6, 5,\n",
       "       6, 7, 5, 6, 5, 6, 5, 5, 6, 6, 6, 6, 5, 6, 5, 7, 6, 6, 6, 6, 6, 6,\n",
       "       6, 6, 6, 7, 6, 6, 5, 5, 6, 6, 4, 4, 6, 5, 5, 5, 8, 4, 6, 5, 6, 6,\n",
       "       5, 5, 5, 6, 6, 5, 5, 8, 5, 7, 5, 8, 5, 6, 5, 5, 6, 8, 6, 6, 6, 5,\n",
       "       6, 5, 5, 6, 5, 6, 6, 5, 6, 6, 6, 6, 6, 7, 5, 6, 6, 6, 5, 5, 7, 6,\n",
       "       6, 7, 6, 5, 5, 6, 6, 5, 6, 5, 7, 5, 5, 6, 6, 6, 5, 6, 7, 6, 6, 7,\n",
       "       6, 8, 7, 6, 6, 5, 6, 7, 6, 6, 6, 5, 5, 6, 5, 4, 7, 6, 5, 6, 5, 5,\n",
       "       5, 7, 6, 4, 6, 5, 7, 6, 6, 6, 6, 6, 7, 5, 6, 5, 5, 6, 5, 5, 6, 3,\n",
       "       5, 6, 8, 7, 5, 7, 6, 6, 5, 6, 5, 5, 5, 6, 6, 6, 6, 5, 7, 5, 7, 6,\n",
       "       5, 5, 7, 8, 6, 8, 6, 5, 6, 5, 6, 8, 6, 5, 5, 5, 7, 5, 6, 7, 6, 5,\n",
       "       7, 6, 6, 6, 6, 6, 6, 5, 6, 5, 5, 6, 5, 7, 5, 8, 6, 6, 6, 4, 7, 6,\n",
       "       7, 7, 6, 5, 5, 6, 7, 6, 6, 6, 6, 7, 5, 6, 8, 6, 8, 6, 4, 5, 6, 7,\n",
       "       6, 7, 5, 5, 8, 6, 6, 6, 7, 6, 6, 6, 5, 6, 6, 5, 6, 5, 5, 6, 6, 7,\n",
       "       6, 5, 6, 7, 6, 6, 7, 5, 6, 4, 4, 5])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "398565c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         4\n",
      "           4       0.00      0.00      0.00        32\n",
      "           5       0.32      0.30      0.31       292\n",
      "           6       0.47      0.51      0.49       440\n",
      "           7       0.21      0.21      0.21       176\n",
      "           8       0.10      0.06      0.07        35\n",
      "           9       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.36       980\n",
      "   macro avg       0.16      0.16      0.16       980\n",
      "weighted avg       0.35      0.36      0.35       980\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniforge3/envs/dml/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/user/miniforge3/envs/dml/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/user/miniforge3/envs/dml/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(max_depth=5, n_estimators=1000, n_jobs=-1, random_state=10)\n",
    "xgb.fit(X_train2, y_train2)\n",
    "xgb_pred = xgb.predict(X_valid2)\n",
    "print(classification_report(le.inverse_transform(y_test2), le.inverse_transform(xgb_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221865d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7528f23d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
