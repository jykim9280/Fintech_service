{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0324d294",
   "metadata": {},
   "source": [
    "# 스테이블디퓨전으로_이미지_생성_서비스_만들기\n",
    "* 간단한 스케치를 기반으로 이미지 생성\n",
    "* 스케치가 되어있는 이미지를 업로드해서 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f84d25b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install diffusers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f09e8096",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import IO\n",
    "import gradio as gr\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from diffusers import StableDiffusionImg2ImgPipeline\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2eac8a",
   "metadata": {},
   "source": [
    "# 스케치 투 이미지 생성 UI 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "265e25e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPORTANT: You are using gradio version 3.40.0, however version 4.29.0 is available, please upgrade.\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "WIDTH = 512\n",
    "HEIGHT = 512\n",
    "\n",
    "with gr.Blocks() as app:\n",
    "    gr.Markdown(\"## 프롬프트 입력\")\n",
    "    with gr.Row():\n",
    "        prompt = gr.Textbox(label=\"Prompt\")\n",
    "    with gr.Row():\n",
    "        n_prompt = gr.Textbox(label=\"Nagative Prompt\")\n",
    "        \n",
    "    gr.Markdown(\"## 스케치 to 이미지 생성\")\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            with gr.Tab(\"Canvas\"):\n",
    "                with gr.Row():\n",
    "                    canvas = gr.Image(\n",
    "                        label=\"Draw\",\n",
    "                        source= 'canvas',\n",
    "                        image_mode='RGB',\n",
    "                        tool='color-sketch',\n",
    "                        interactive=True,\n",
    "                        width=WIDTH,\n",
    "                        height=HEIGHT,\n",
    "                        shape=(WIDTH, HEIGHT),\n",
    "                        brush_radius=20,\n",
    "                        type='pil'\n",
    "                    )\n",
    "\n",
    "                with gr.Row():\n",
    "                    canvas_run_btn = gr.Button(value=\"Generate\")\n",
    "            \n",
    "            with gr.Tab(\"File\"):\n",
    "                with gr.Row():\n",
    "                    file = gr.Image(\n",
    "                        label=\"Upload\",\n",
    "                        source= 'upload',\n",
    "                        image_mode='RGB',\n",
    "                        tool='color-sketch',\n",
    "                        interactive=True,\n",
    "                        width=WIDTH,\n",
    "                        height=HEIGHT,\n",
    "                        shape=(WIDTH, HEIGHT),\n",
    "                        type='pil'\n",
    "                    )\n",
    "                with gr.Row():\n",
    "                    file_run_btn = gr.Button(value=\"Generate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41a858bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7862\n",
      "Running on public URL: https://3bf79cb5c3a24fa1fc.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.launch(inline=False, share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd32b717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7862\n"
     ]
    }
   ],
   "source": [
    "app.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9ae94b",
   "metadata": {},
   "source": [
    "# 모델 다운로드 UI 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3030dd78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPORTANT: You are using gradio version 3.40.0, however version 4.29.0 is available, please upgrade.\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "with gr.Blocks() as app:\n",
    "    gr.Markdown(\"## 모델 다운로드\")\n",
    "    with gr.Row():\n",
    "        model_url = gr.Textbox(label=\"모델 URL\", placeholder=\"https://civitai.com/\")\n",
    "        download_model_btn = gr.Button(value=\"모델 다운로드\")\n",
    "    with gr.Row():\n",
    "        model_file = gr.File(label=\"모델 파일\")\n",
    "        \n",
    "    download_model_btn.click(\n",
    "        download_model,\n",
    "        [model_url],\n",
    "        [model_file]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f83a528e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7881\n",
      "Running on public URL: https://3a24f6182200acf1b7.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.launch(inline=False, share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7fd5f160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7862\n"
     ]
    }
   ],
   "source": [
    "app.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e978bf",
   "metadata": {},
   "source": [
    "# 모델 다운로드 기능 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b557b7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "# 전역 변수로 모델 경로와 파일명을 저장\n",
    "MODEL_PATH = None\n",
    "\n",
    "# URL로부터 파일 다운로드 함수\n",
    "def download_from_url(url, file_path, chunk_size=1024):\n",
    "    try:\n",
    "        resp = requests.get(url, stream=True)\n",
    "        resp.raise_for_status()\n",
    "    except Exception as e:\n",
    "        print(f\"[Error] {e}\")\n",
    "        raise e\n",
    "    \n",
    "    total = int(resp.headers.get('content-length', 0)) # 파일 크기 추출\n",
    "    with open(file_path, 'wb') as file, tqdm(desc=file_path, total=total, unit='iB', unit_scale=True,\n",
    "                                            unit_divisor=1024) as bar:\n",
    "        for data in resp.iter_content(chunk_size=chunk_size):\n",
    "            size = file.write(data)\n",
    "            bar.update(size)\n",
    "            \n",
    "\n",
    "# 모델을 다운로드하고 경로를 기억하는 함수\n",
    "def download_model(url: str) -> str: \n",
    "    global MODEL_PATH # 전역 변수를 사용해서 경로를 기억\n",
    "    \n",
    "    model_id = url.replace(\"https://civitai.com/models/\", \"\").split(\"/\")[0]\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(f\"https://civitai.com/api/v1/models/{model_id}\", timeout=6000)\n",
    "    except Exception as e:\n",
    "        print(f\"[Error] {e}\")\n",
    "        raise e\n",
    "        \n",
    "    download_url = response.json()['modelVersions'][0]['downloadUrl']\n",
    "    filename = response.json()['modelVersions'][0]['files'][0]['name']\n",
    "    \n",
    "    file_path = f\"models/{filename}\"\n",
    "    if os.path.exists(file_path):\n",
    "        print(f\"[INFO] File already exists: {file_path}\")\n",
    "        MODEL_PATH = file_path # 모델 경로 기억\n",
    "        return file_path\n",
    "    \n",
    "    os.makedirs(\"models\", exist_ok=True)\n",
    "    download_from_url(download_url, file_path)\n",
    "    print(f\"[INFO] File downloaded: {file_path}\")\n",
    "    \n",
    "    # 모델 경로 기억\n",
    "    MODEL_PATH = file_path\n",
    "    return file_path\n",
    "    \n",
    "# ./models 폴더에서 가장 최근에 수정된 모델 파일 찾기\n",
    "def find_latest_model_in_directory(directory):\n",
    "    model_files = glob.glob(f\"{directory}/*.safetensors\")\n",
    "    if not model_files:\n",
    "        return None\n",
    "    \n",
    "    # 가장 최근에 수정된 모델 파일 선택\n",
    "    latest_model = max(model_files, key=os.path.getmtime)\n",
    "    return latest_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58dc4df8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "87e670b7",
   "metadata": {},
   "source": [
    "# 다운로드한 모델 불러와서 초기화하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ff6b801c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_pipeline():\n",
    "    global MODEL_PATH\n",
    "    \n",
    "    if MODEL_PATH is None:\n",
    "        MODEL_PATH = find_latest_model_in_directory(\"./models\")\n",
    "    if MODEL_PATH is None:\n",
    "        return \"Erorr: No Model found in ./models\"\n",
    "    \n",
    "    global PIPELINE\n",
    "    \n",
    "    try:\n",
    "        PIPELINE = StableDiffusionImg2ImgPipeline.from_single_file(\n",
    "            MODEL_PATH,\n",
    "            torch_dtype=torch.float16,\n",
    "            variant=\"fp16\",\n",
    "            use_safetensors=True,\n",
    "        ).to('cpu') #Gpu로 모델을 보내기 위함\n",
    "        print(\"[INFO] Initialized pipeline\")\n",
    "        return \"Model Loaded!\"\n",
    "    except Exception as e:\n",
    "        print(f\"[Error] {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8218a99d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPORTANT: You are using gradio version 3.40.0, however version 4.29.0 is available, please upgrade.\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "with gr.Blocks() as app:\n",
    "    gr.Markdown(\"## 모델 불러오기\")\n",
    "    with gr.Row():\n",
    "        load_model_btn = gr.Button(value=\"모델 불러오기\")\n",
    "    with gr.Row():\n",
    "        is_model_check = gr.Textbox(label=\"Model Load Check\", value=\"Model Not Loaded\")\n",
    "    load_model_btn.click(\n",
    "        init_pipeline,\n",
    "        None,\n",
    "        [is_model_check])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "06ec510d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7880\n",
      "Running on public URL: https://6e52617a1df36f7d3e.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 11 files: 100%|██████████████████████████████████████████████████████████| 11/11 [00:01<00:00, 10.68it/s]\n",
      "Loading pipeline components...:   0%|                                                       | 0/6 [00:00<?, ?it/s]/home/user/miniforge3/envs/torch/lib/python3.11/site-packages/transformers/models/clip/feature_extraction_clip.py:28: FutureWarning: The class CLIPFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use CLIPImageProcessor instead.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint were not used when initializing CLIPTextModel: \n",
      " ['text_model.embeddings.position_ids']\n",
      "Loading pipeline components...: 100%|███████████████████████████████████████████████| 6/6 [00:30<00:00,  5.02s/it]\n",
      "You have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion_img2img.StableDiffusionImg2ImgPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n",
      "Pipelines loaded with `dtype=torch.float16` cannot run with `cpu` device. It is not recommended to move them to `cpu` as running them will fail. Please make sure to use an accelerator to run the pipeline in inference, due to the lack of support for`float16` operations on this device in PyTorch. Please, remove the `torch_dtype=torch.float16` argument, or use another device for inference.\n",
      "Pipelines loaded with `dtype=torch.float16` cannot run with `cpu` device. It is not recommended to move them to `cpu` as running them will fail. Please make sure to use an accelerator to run the pipeline in inference, due to the lack of support for`float16` operations on this device in PyTorch. Please, remove the `torch_dtype=torch.float16` argument, or use another device for inference.\n",
      "Pipelines loaded with `dtype=torch.float16` cannot run with `cpu` device. It is not recommended to move them to `cpu` as running them will fail. Please make sure to use an accelerator to run the pipeline in inference, due to the lack of support for`float16` operations on this device in PyTorch. Please, remove the `torch_dtype=torch.float16` argument, or use another device for inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Initialized pipeline\n"
     ]
    }
   ],
   "source": [
    "app.queue().launch(inline=False, share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "78d2a010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7881\n"
     ]
    }
   ],
   "source": [
    "app.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9adc21",
   "metadata": {},
   "source": [
    "# 스케치 투 이미지 생성 기능 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "36cc6bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sketch_to_image(sketch, prompt, negative_prompt):\n",
    "    global PIPELINE\n",
    "    if PIPELINE is None:\n",
    "        return \"Error\"\n",
    "    \n",
    "    prompt = [prompt]\n",
    "    negative_prompt = [negative_prompt]\n",
    "    \n",
    "    images = [sketch] * len(prompt)\n",
    "    \n",
    "    try: #이미지 생성\n",
    "        result = PIPELINE(\n",
    "            image = images,\n",
    "            prompt = prompt,\n",
    "            negative_prompt = negative_prompt,\n",
    "            height = height,\n",
    "            width = width,\n",
    "            num_images_per_prompt = 4,\n",
    "            num_inference_steps = 20,\n",
    "            strength = 0.7\n",
    "        ).images\n",
    "    except Exception as e:\n",
    "        print(f\"[Error] {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afa8bd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
